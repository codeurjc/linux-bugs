commit 70dd2d169d08f059ff25a41278ab7c658b1d2af8
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Mon Jun 6 08:42:45 2022 +0200

    Linux 5.10.120
    
    Link: https://lore.kernel.org/r/20220603173818.716010877@linuxfoundation.org
    Tested-by: Sudip Mukherjee <sudip.mukherjee@codethink.co.uk>
    Tested-by: Linux Kernel Functional Testing <lkft@linaro.org>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Tested-by: Salvatore Bonaccorso <carnil@debian.org>
    Tested-by: Fox Chen <foxhlchen@gmail.com>
    Tested-by: Hulk Robot <hulkrobot@huawei.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 886eeb046096fec4f7e43ed8fc94974564b868d4
Author: Liu Jian <liujian56@huawei.com>
Date:   Sat Apr 16 18:57:59 2022 +0800

    bpf: Enlarge offset check value to INT_MAX in bpf_skb_{load,store}_bytes
    
    commit 45969b4152c1752089351cd6836a42a566d49bcf upstream.
    
    The data length of skb frags + frag_list may be greater than 0xffff, and
    skb_header_pointer can not handle negative offset. So, here INT_MAX is used
    to check the validity of offset. Add the same change to the related function
    skb_store_bytes.
    
    Fixes: 05c74e5e53f6 ("bpf: add bpf_skb_load_bytes helper")
    Signed-off-by: Liu Jian <liujian56@huawei.com>
    Signed-off-by: Daniel Borkmann <daniel@iogearbox.net>
    Acked-by: Song Liu <songliubraving@fb.com>
    Link: https://lore.kernel.org/bpf/20220416105801.88708-2-liujian56@huawei.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7f845de2863334bed4f362e95853f5e7bc323737
Author: Yuntao Wang <ytcoode@gmail.com>
Date:   Sat Apr 30 21:08:03 2022 +0800

    bpf: Fix potential array overflow in bpf_trampoline_get_progs()
    
    commit a2aa95b71c9bbec793b5c5fa50f0a80d882b3e8d upstream.
    
    The cnt value in the 'cnt >= BPF_MAX_TRAMP_PROGS' check does not
    include BPF_TRAMP_MODIFY_RETURN bpf programs, so the number of
    the attached BPF_TRAMP_MODIFY_RETURN bpf programs in a trampoline
    can exceed BPF_MAX_TRAMP_PROGS.
    
    When this happens, the assignment '*progs++ = aux->prog' in
    bpf_trampoline_get_progs() will cause progs array overflow as the
    progs field in the bpf_tramp_progs struct can only hold at most
    BPF_MAX_TRAMP_PROGS bpf programs.
    
    Fixes: 88fd9e5352fe ("bpf: Refactor trampoline update code")
    Signed-off-by: Yuntao Wang <ytcoode@gmail.com>
    Link: https://lore.kernel.org/r/20220430130803.210624-1-ytcoode@gmail.com
    Signed-off-by: Alexei Starovoitov <ast@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3097f38e91266c7132c3fdb7e778fac858c00670
Author: Chuck Lever <chuck.lever@oracle.com>
Date:   Sat May 21 19:06:13 2022 -0400

    NFSD: Fix possible sleep during nfsd4_release_lockowner()
    
    commit ce3c4ad7f4ce5db7b4f08a1e237d8dd94b39180b upstream.
    
    nfsd4_release_lockowner() holds clp->cl_lock when it calls
    check_for_locks(). However, check_for_locks() calls nfsd_file_get()
    / nfsd_file_put() to access the backing inode's flc_posix list, and
    nfsd_file_put() can sleep if the inode was recently removed.
    
    Let's instead rely on the stateowner's reference count to gate
    whether the release is permitted. This should be a reliable
    indication of locks-in-use since file lock operations and
    ->lm_get_owner take appropriate references, which are released
    appropriately when file locks are removed.
    
    Reported-by: Dai Ngo <dai.ngo@oracle.com>
    Signed-off-by: Chuck Lever <chuck.lever@oracle.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 78a62e09d88537150ffb31451d07efdc8a1c9b78
Author: Trond Myklebust <trond.myklebust@hammerspace.com>
Date:   Sat May 14 10:08:10 2022 -0400

    NFS: Memory allocation failures are not server fatal errors
    
    commit 452284407c18d8a522c3039339b1860afa0025a8 upstream.
    
    We need to filter out ENOMEM in nfs_error_is_fatal_on_server(), because
    running out of memory on our client is not a server error.
    
    Reported-by: Olga Kornievskaia <aglo@umich.edu>
    Fixes: 2dc23afffbca ("NFS: ENOMEM should also be a fatal error.")
    Cc: stable@vger.kernel.org
    Signed-off-by: Trond Myklebust <trond.myklebust@hammerspace.com>
    Signed-off-by: Anna Schumaker <Anna.Schumaker@Netapp.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1d100fcc1da7a5baaf29d81d1bfb8e106fc3c297
Author: Akira Yokosawa <akiyks@gmail.com>
Date:   Wed Apr 27 18:28:39 2022 +0900

    docs: submitting-patches: Fix crossref to 'The canonical patch format'
    
    commit 6d5aa418b3bd42cdccc36e94ee199af423ef7c84 upstream.
    
    The reference to `explicit_in_reply_to` is pointless as when the
    reference was added in the form of "#15" [1], Section 15) was "The
    canonical patch format".
    The reference of "#15" had not been properly updated in a couple of
    reorganizations during the plain-text SubmittingPatches era.
    
    Fix it by using `the_canonical_patch_format`.
    
    [1]: 2ae19acaa50a ("Documentation: Add "how to write a good patch summary" to SubmittingPatches")
    
    Signed-off-by: Akira Yokosawa <akiyks@gmail.com>
    Fixes: 5903019b2a5e ("Documentation/SubmittingPatches: convert it to ReST markup")
    Fixes: 9b2c76777acc ("Documentation/SubmittingPatches: enrich the Sphinx output")
    Cc: Jonathan Corbet <corbet@lwn.net>
    Cc: Mauro Carvalho Chehab <mchehab@kernel.org>
    Cc: stable@vger.kernel.org # v4.9+
    Link: https://lore.kernel.org/r/64e105a5-50be-23f2-6cae-903a2ea98e18@gmail.com
    Signed-off-by: Jonathan Corbet <corbet@lwn.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ebbbffae71e2e0f322bf9e3fadb62d2bee0c33b3
Author: Xiu Jianfeng <xiujianfeng@huawei.com>
Date:   Fri Mar 18 14:02:01 2022 +0800

    tpm: ibmvtpm: Correct the return value in tpm_ibmvtpm_probe()
    
    commit d0dc1a7100f19121f6e7450f9cdda11926aa3838 upstream.
    
    Currently it returns zero when CRQ response timed out, it should return
    an error code instead.
    
    Fixes: d8d74ea3c002 ("tpm: ibmvtpm: Wait for buffer to be set before proceeding")
    Signed-off-by: Xiu Jianfeng <xiujianfeng@huawei.com>
    Reviewed-by: Stefan Berger <stefanb@linux.ibm.com>
    Acked-by: Jarkko Sakkinen <jarkko@kernel.org>
    Signed-off-by: Jarkko Sakkinen <jarkko@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5933a191ac3d6724833d87bd99bda1d1904cb800
Author: Stefan Mahnke-Hartmann <stefan.mahnke-hartmann@infineon.com>
Date:   Fri May 13 15:41:51 2022 +0200

    tpm: Fix buffer access in tpm2_get_tpm_pt()
    
    commit e57b2523bd37e6434f4e64c7a685e3715ad21e9a upstream.
    
    Under certain conditions uninitialized memory will be accessed.
    As described by TCG Trusted Platform Module Library Specification,
    rev. 1.59 (Part 3: Commands), if a TPM2_GetCapability is received,
    requesting a capability, the TPM in field upgrade mode may return a
    zero length list.
    Check the property count in tpm2_get_tpm_pt().
    
    Fixes: 2ab3241161b3 ("tpm: migrate tpm2_get_tpm_pt() to use struct tpm_buf")
    Cc: stable@vger.kernel.org
    Signed-off-by: Stefan Mahnke-Hartmann <stefan.mahnke-hartmann@infineon.com>
    Reviewed-by: Jarkko Sakkinen <jarkko@kernel.org>
    Signed-off-by: Jarkko Sakkinen <jarkko@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0c56e5d0e65531747c437c608d610a2fa8ecd9fe
Author: Tao Jin <tao-j@outlook.com>
Date:   Sun Apr 3 12:57:44 2022 -0400

    HID: multitouch: add quirks to enable Lenovo X12 trackpoint
    
    commit 95cd2cdc88c755dcd0a58b951faeb77742c733a4 upstream.
    
    This applies the similar quirks used by previous generation devices
    such as X1 tablet for X12 tablet, so that the trackpoint and buttons
    can work.
    
    This patch was applied and tested working on 5.17.1 .
    
    Cc: stable@vger.kernel.org # 5.8+ given that it relies on 40d5bb87377a
    Signed-off-by: Tao Jin <tao-j@outlook.com>
    Signed-off-by: Benjamin Tissoires <benjamin.tissoires@redhat.com>
    Link: https://lore.kernel.org/r/CO6PR03MB6241CB276FCDC7F4CEDC34F6E1E29@CO6PR03MB6241.namprd03.prod.outlook.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d6822d82c0e8d025fbc157755cab17252ad7092b
Author: Marek Ma≈õlanka <mm@semihalf.com>
Date:   Tue Apr 5 17:04:07 2022 +0200

    HID: multitouch: Add support for Google Whiskers Touchpad
    
    commit 1d07cef7fd7599450b3d03e1915efc2a96e1f03f upstream.
    
    The Google Whiskers touchpad does not work properly with the default
    multitouch configuration. Instead, use the same configuration as Google
    Rose.
    
    Signed-off-by: Marek Maslanka <mm@semihalf.com>
    Acked-by: Benjamin Tissoires <benjamin.tissoires@redhat.com>
    Signed-off-by: Jiri Kosina <jkosina@suse.cz>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0f03885059c1f2a5fb690d21578d0cad55a98b1f
Author: Mariusz Tkaczyk <mariusz.tkaczyk@linux.intel.com>
Date:   Tue Mar 22 16:23:39 2022 +0100

    raid5: introduce MD_BROKEN
    
    commit 57668f0a4cc4083a120cc8c517ca0055c4543b59 upstream.
    
    Raid456 module had allowed to achieve failed state. It was fixed by
    fb73b357fb9 ("raid5: block failing device if raid will be failed").
    This fix introduces a bug, now if raid5 fails during IO, it may result
    with a hung task without completion. Faulty flag on the device is
    necessary to process all requests and is checked many times, mainly in
    analyze_stripe().
    Allow to set faulty on drive again and set MD_BROKEN if raid is failed.
    
    As a result, this level is allowed to achieve failed state again, but
    communication with userspace (via -EBUSY status) will be preserved.
    
    This restores possibility to fail array via #mdadm --set-faulty command
    and will be fixed by additional verification on mdadm side.
    
    Reproduction steps:
     mdadm -CR imsm -e imsm -n 3 /dev/nvme[0-2]n1
     mdadm -CR r5 -e imsm -l5 -n3 /dev/nvme[0-2]n1 --assume-clean
     mkfs.xfs /dev/md126 -f
     mount /dev/md126 /mnt/root/
    
     fio --filename=/mnt/root/file --size=5GB --direct=1 --rw=randrw
    --bs=64k --ioengine=libaio --iodepth=64 --runtime=240 --numjobs=4
    --time_based --group_reporting --name=throughput-test-job
    --eta-newline=1 &
    
     echo 1 > /sys/block/nvme2n1/device/device/remove
     echo 1 > /sys/block/nvme1n1/device/device/remove
    
     [ 1475.787779] Call Trace:
     [ 1475.793111] __schedule+0x2a6/0x700
     [ 1475.799460] schedule+0x38/0xa0
     [ 1475.805454] raid5_get_active_stripe+0x469/0x5f0 [raid456]
     [ 1475.813856] ? finish_wait+0x80/0x80
     [ 1475.820332] raid5_make_request+0x180/0xb40 [raid456]
     [ 1475.828281] ? finish_wait+0x80/0x80
     [ 1475.834727] ? finish_wait+0x80/0x80
     [ 1475.841127] ? finish_wait+0x80/0x80
     [ 1475.847480] md_handle_request+0x119/0x190
     [ 1475.854390] md_make_request+0x8a/0x190
     [ 1475.861041] generic_make_request+0xcf/0x310
     [ 1475.868145] submit_bio+0x3c/0x160
     [ 1475.874355] iomap_dio_submit_bio.isra.20+0x51/0x60
     [ 1475.882070] iomap_dio_bio_actor+0x175/0x390
     [ 1475.889149] iomap_apply+0xff/0x310
     [ 1475.895447] ? iomap_dio_bio_actor+0x390/0x390
     [ 1475.902736] ? iomap_dio_bio_actor+0x390/0x390
     [ 1475.909974] iomap_dio_rw+0x2f2/0x490
     [ 1475.916415] ? iomap_dio_bio_actor+0x390/0x390
     [ 1475.923680] ? atime_needs_update+0x77/0xe0
     [ 1475.930674] ? xfs_file_dio_aio_read+0x6b/0xe0 [xfs]
     [ 1475.938455] xfs_file_dio_aio_read+0x6b/0xe0 [xfs]
     [ 1475.946084] xfs_file_read_iter+0xba/0xd0 [xfs]
     [ 1475.953403] aio_read+0xd5/0x180
     [ 1475.959395] ? _cond_resched+0x15/0x30
     [ 1475.965907] io_submit_one+0x20b/0x3c0
     [ 1475.972398] __x64_sys_io_submit+0xa2/0x180
     [ 1475.979335] ? do_io_getevents+0x7c/0xc0
     [ 1475.986009] do_syscall_64+0x5b/0x1a0
     [ 1475.992419] entry_SYSCALL_64_after_hwframe+0x65/0xca
     [ 1476.000255] RIP: 0033:0x7f11fc27978d
     [ 1476.006631] Code: Bad RIP value.
     [ 1476.073251] INFO: task fio:3877 blocked for more than 120 seconds.
    
    Cc: stable@vger.kernel.org
    Fixes: fb73b357fb9 ("raid5: block failing device if raid will be failed")
    Reviewd-by: Xiao Ni <xni@redhat.com>
    Signed-off-by: Mariusz Tkaczyk <mariusz.tkaczyk@linux.intel.com>
    Signed-off-by: Song Liu <song@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8df42bcd364cc3b41105215d841792aea787b133
Author: Sarthak Kukreti <sarthakkukreti@google.com>
Date:   Tue May 31 15:56:40 2022 -0400

    dm verity: set DM_TARGET_IMMUTABLE feature flag
    
    commit 4caae58406f8ceb741603eee460d79bacca9b1b5 upstream.
    
    The device-mapper framework provides a mechanism to mark targets as
    immutable (and hence fail table reloads that try to change the target
    type). Add the DM_TARGET_IMMUTABLE flag to the dm-verity target's
    feature flags to prevent switching the verity target with a different
    target type.
    
    Fixes: a4ffc152198e ("dm: add verity target")
    Cc: stable@vger.kernel.org
    Signed-off-by: Sarthak Kukreti <sarthakkukreti@google.com>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Signed-off-by: Mike Snitzer <snitzer@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e39b536d70edc5f622187cf787db94287e389c50
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Sun Apr 24 16:43:00 2022 -0400

    dm stats: add cond_resched when looping over entries
    
    commit bfe2b0146c4d0230b68f5c71a64380ff8d361f8b upstream.
    
    dm-stats can be used with a very large number of entries (it is only
    limited by 1/4 of total system memory), so add rescheduling points to
    the loops that iterate over the entries.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4617778417d0a8c59f309b5eea21d943877f3c74
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Mon Apr 25 08:53:29 2022 -0400

    dm crypt: make printing of the key constant-time
    
    commit 567dd8f34560fa221a6343729474536aa7ede4fd upstream.
    
    The device mapper dm-crypt target is using scnprintf("%02x", cc->key[i]) to
    report the current key to userspace. However, this is not a constant-time
    operation and it may leak information about the key via timing, via cache
    access patterns or via the branch predictor.
    
    Change dm-crypt's key printing to use "%c" instead of "%02x". Also
    introduce hex2asc() that carefully avoids any branching or memory
    accesses when converting a number in the range 0 ... 15 to an ascii
    character.
    
    Cc: stable@vger.kernel.org
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    Tested-by: Milan Broz <gmazyland@gmail.com>
    Signed-off-by: Mike Snitzer <snitzer@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bb64957c472adc90eb7dbb45db95019d7a574088
Author: Dan Carpenter <dan.carpenter@oracle.com>
Date:   Mon Apr 25 14:56:48 2022 +0300

    dm integrity: fix error code in dm_integrity_ctr()
    
    commit d3f2a14b8906df913cb04a706367b012db94a6e8 upstream.
    
    The "r" variable shadows an earlier "r" that has function scope.  It
    means that we accidentally return success instead of an error code.
    Smatch has a warning for this:
    
            drivers/md/dm-integrity.c:4503 dm_integrity_ctr()
            warn: missing error code 'r'
    
    Fixes: 7eada909bfd7 ("dm: add integrity target")
    Cc: stable@vger.kernel.org
    Signed-off-by: Dan Carpenter <dan.carpenter@oracle.com>
    Reviewed-by: Mikulas Patocka <mpatocka@redhat.com>
    Signed-off-by: Mike Snitzer <snitzer@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8845027e55fc8b977607b4576ca6efd5d8d4566d
Author: Jonathan Bakker <xc-racer2@live.ca>
Date:   Sun Mar 27 11:08:51 2022 -0700

    ARM: dts: s5pv210: Correct interrupt name for bluetooth in Aries
    
    commit 3f5e3d3a8b895c8a11da8b0063ba2022dd9e2045 upstream.
    
    Correct the name of the bluetooth interrupt from host-wake to
    host-wakeup.
    
    Fixes: 1c65b6184441b ("ARM: dts: s5pv210: Correct BCM4329 bluetooth node")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Jonathan Bakker <xc-racer2@live.ca>
    Link: https://lore.kernel.org/r/CY4PR04MB0567495CFCBDC8D408D44199CB1C9@CY4PR04MB0567.namprd04.prod.outlook.com
    Signed-off-by: Krzysztof Kozlowski <krzysztof.kozlowski@linaro.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4989bb03342941f2b730b37dfa38bce27b543661
Author: Steven Rostedt <rostedt@goodmis.org>
Date:   Tue Apr 5 10:02:00 2022 -0400

    Bluetooth: hci_qca: Use del_timer_sync() before freeing
    
    commit 72ef98445aca568a81c2da050532500a8345ad3a upstream.
    
    While looking at a crash report on a timer list being corrupted, which
    usually happens when a timer is freed while still active. This is
    commonly triggered by code calling del_timer() instead of
    del_timer_sync() just before freeing.
    
    One possible culprit is the hci_qca driver, which does exactly that.
    
    Eric mentioned that wake_retrans_timer could be rearmed via the work
    queue, so also move the destruction of the work queue before
    del_timer_sync().
    
    Cc: Eric Dumazet <eric.dumazet@gmail.com>
    Cc: stable@vger.kernel.org
    Fixes: 0ff252c1976da ("Bluetooth: hciuart: Add support QCA chipset for UART")
    Signed-off-by: Steven Rostedt (Google) <rostedt@goodmis.org>
    Signed-off-by: Marcel Holtmann <marcel@holtmann.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fae05b2314b147a78fbed1dc4c645d9a66313758
Author: Sultan Alsawaf <sultan@kerneltoast.com>
Date:   Fri May 13 15:11:26 2022 -0700

    zsmalloc: fix races between asynchronous zspage free and page migration
    
    commit 2505a981114dcb715f8977b8433f7540854851d8 upstream.
    
    The asynchronous zspage free worker tries to lock a zspage's entire page
    list without defending against page migration.  Since pages which haven't
    yet been locked can concurrently migrate off the zspage page list while
    lock_zspage() churns away, lock_zspage() can suffer from a few different
    lethal races.
    
    It can lock a page which no longer belongs to the zspage and unsafely
    dereference page_private(), it can unsafely dereference a torn pointer to
    the next page (since there's a data race), and it can observe a spurious
    NULL pointer to the next page and thus not lock all of the zspage's pages
    (since a single page migration will reconstruct the entire page list, and
    create_page_chain() unconditionally zeroes out each list pointer in the
    process).
    
    Fix the races by using migrate_read_lock() in lock_zspage() to synchronize
    with page migration.
    
    Link: https://lkml.kernel.org/r/20220509024703.243847-1-sultan@kerneltoast.com
    Fixes: 77ff465799c602 ("zsmalloc: zs_page_migrate: skip unnecessary loops but not return -EBUSY if zspage is not inuse")
    Signed-off-by: Sultan Alsawaf <sultan@kerneltoast.com>
    Acked-by: Minchan Kim <minchan@kernel.org>
    Cc: Nitin Gupta <ngupta@vflare.org>
    Cc: Sergey Senozhatsky <senozhatsky@chromium.org>
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6a1cc25494056e6b8dff243f8b3d9c57259535f6
Author: Vitaly Chikunov <vt@altlinux.org>
Date:   Thu Apr 21 20:25:10 2022 +0300

    crypto: ecrdsa - Fix incorrect use of vli_cmp
    
    commit 7cc7ab73f83ee6d50dc9536bc3355495d8600fad upstream.
    
    Correctly compare values that shall be greater-or-equal and not just
    greater.
    
    Fixes: 0d7a78643f69 ("crypto: ecrdsa - add EC-RDSA (GOST 34.10) algorithm")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Vitaly Chikunov <vt@altlinux.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c013f7d1cd92d945398c63a7d6a8b0dd99c23679
Author: Fabio Estevam <festevam@denx.de>
Date:   Wed Apr 20 09:06:01 2022 -0300

    crypto: caam - fix i.MX6SX entropy delay value
    
    commit 4ee4cdad368a26de3967f2975806a9ee2fa245df upstream.
    
    Since commit 358ba762d9f1 ("crypto: caam - enable prediction resistance
    in HRWNG") the following CAAM errors can be seen on i.MX6SX:
    
    caam_jr 2101000.jr: 20003c5b: CCB: desc idx 60: RNG: Hardware error
    hwrng: no data available
    
    This error is due to an incorrect entropy delay for i.MX6SX.
    
    Fix it by increasing the minimum entropy delay for i.MX6SX
    as done in U-Boot:
    https://patchwork.ozlabs.org/project/uboot/patch/20220415111049.2565744-1-gaurav.jain@nxp.com/
    
    As explained in the U-Boot patch:
    
    "RNG self tests are run to determine the correct entropy delay.
    Such tests are executed with different voltages and temperatures to identify
    the worst case value for the entropy delay. For i.MX6SX, it was determined
    that after adding a margin value of 1000 the minimum entropy delay should be
    at least 12000."
    
    Cc: <stable@vger.kernel.org>
    Fixes: 358ba762d9f1 ("crypto: caam - enable prediction resistance in HRWNG")
    Signed-off-by: Fabio Estevam <festevam@denx.de>
    Reviewed-by: Horia GeantƒÉ <horia.geanta@nxp.com>
    Reviewed-by: Vabhav Sharma <vabhav.sharma@nxp.com>
    Reviewed-by: Gaurav Jain <gaurav.jain@nxp.com>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3d8fc6e28f321d753ab727e3c3e740daf36a8fa3
Author: Sean Christopherson <seanjc@google.com>
Date:   Fri Mar 11 03:27:41 2022 +0000

    KVM: x86: avoid calling x86 emulator without a decoded instruction
    
    commit fee060cd52d69c114b62d1a2948ea9648b5131f9 upstream.
    
    Whenever x86_decode_emulated_instruction() detects a breakpoint, it
    returns the value that kvm_vcpu_check_breakpoint() writes into its
    pass-by-reference second argument.  Unfortunately this is completely
    bogus because the expected outcome of x86_decode_emulated_instruction
    is an EMULATION_* value.
    
    Then, if kvm_vcpu_check_breakpoint() does "*r = 0" (corresponding to
    a KVM_EXIT_DEBUG userspace exit), it is misunderstood as EMULATION_OK
    and x86_emulate_instruction() is called without having decoded the
    instruction.  This causes various havoc from running with a stale
    emulation context.
    
    The fix is to move the call to kvm_vcpu_check_breakpoint() where it was
    before commit 4aa2691dcbd3 ("KVM: x86: Factor out x86 instruction
    emulation with decoding") introduced x86_decode_emulated_instruction().
    The other caller of the function does not need breakpoint checks,
    because it is invoked as part of a vmexit and the processor has already
    checked those before executing the instruction that #GP'd.
    
    This fixes CVE-2022-1852.
    
    Reported-by: Qiuhao Li <qiuhao@sysec.org>
    Reported-by: Gaoning Pan <pgn@zju.edu.cn>
    Reported-by: Yongkang Jia <kangel@zju.edu.cn>
    Fixes: 4aa2691dcbd3 ("KVM: x86: Factor out x86 instruction emulation with decoding")
    Cc: stable@vger.kernel.org
    Signed-off-by: Sean Christopherson <seanjc@google.com>
    Message-Id: <20220311032801.3467418-2-seanjc@google.com>
    [Rewrote commit message according to Qiuhao's report, since a patch
     already existed to fix the bug. - Paolo]
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a2a3fa5b616a1b4caaf1c352051e169471296d4b
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Tue May 24 09:43:31 2022 -0400

    x86, kvm: use correct GFP flags for preemption disabled
    
    commit baec4f5a018fe2d708fc1022330dba04b38b5fe3 upstream.
    
    Commit ddd7ed842627 ("x86/kvm: Alloc dummy async #PF token outside of
    raw spinlock") leads to the following Smatch static checker warning:
    
            arch/x86/kernel/kvm.c:212 kvm_async_pf_task_wake()
            warn: sleeping in atomic context
    
    arch/x86/kernel/kvm.c
        202         raw_spin_lock(&b->lock);
        203         n = _find_apf_task(b, token);
        204         if (!n) {
        205                 /*
        206                  * Async #PF not yet handled, add a dummy entry for the token.
        207                  * Allocating the token must be down outside of the raw lock
        208                  * as the allocator is preemptible on PREEMPT_RT kernels.
        209                  */
        210                 if (!dummy) {
        211                         raw_spin_unlock(&b->lock);
    --> 212                         dummy = kzalloc(sizeof(*dummy), GFP_KERNEL);
                                                                    ^^^^^^^^^^
    Smatch thinks the caller has preempt disabled.  The `smdb.py preempt
    kvm_async_pf_task_wake` output call tree is:
    
    sysvec_kvm_asyncpf_interrupt() <- disables preempt
    -> __sysvec_kvm_asyncpf_interrupt()
       -> kvm_async_pf_task_wake()
    
    The caller is this:
    
    arch/x86/kernel/kvm.c
       290        DEFINE_IDTENTRY_SYSVEC(sysvec_kvm_asyncpf_interrupt)
       291        {
       292                struct pt_regs *old_regs = set_irq_regs(regs);
       293                u32 token;
       294
       295                ack_APIC_irq();
       296
       297                inc_irq_stat(irq_hv_callback_count);
       298
       299                if (__this_cpu_read(apf_reason.enabled)) {
       300                        token = __this_cpu_read(apf_reason.token);
       301                        kvm_async_pf_task_wake(token);
       302                        __this_cpu_write(apf_reason.token, 0);
       303                        wrmsrl(MSR_KVM_ASYNC_PF_ACK, 1);
       304                }
       305
       306                set_irq_regs(old_regs);
       307        }
    
    The DEFINE_IDTENTRY_SYSVEC() is a wrapper that calls this function
    from the call_on_irqstack_cond().  It's inside the call_on_irqstack_cond()
    where preempt is disabled (unless it's already disabled).  The
    irq_enter/exit_rcu() functions disable/enable preempt.
    
    Reported-by: Dan Carpenter <dan.carpenter@oracle.com>
    Cc: stable@vger.kernel.org
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4a9f3a9c28a6966c699b4264b6a3c5aaed21ea3e
Author: Sean Christopherson <seanjc@google.com>
Date:   Thu May 19 07:57:11 2022 -0700

    x86/kvm: Alloc dummy async #PF token outside of raw spinlock
    
    commit 0547758a6de3cc71a0cfdd031a3621a30db6a68b upstream.
    
    Drop the raw spinlock in kvm_async_pf_task_wake() before allocating the
    the dummy async #PF token, the allocator is preemptible on PREEMPT_RT
    kernels and must not be called from truly atomic contexts.
    
    Opportunistically document why it's ok to loop on allocation failure,
    i.e. why the function won't get stuck in an infinite loop.
    
    Reported-by: Yajun Deng <yajun.deng@linux.dev>
    Cc: stable@vger.kernel.org
    Signed-off-by: Sean Christopherson <seanjc@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4c4a11c74adac284534f3db927c726bd419bbacb
Author: Xiaomeng Tong <xiam0nd.tong@gmail.com>
Date:   Thu Apr 14 14:21:03 2022 +0800

    KVM: PPC: Book3S HV: fix incorrect NULL check on list iterator
    
    commit 300981abddcb13f8f06ad58f52358b53a8096775 upstream.
    
    The bug is here:
            if (!p)
                    return ret;
    
    The list iterator value 'p' will *always* be set and non-NULL by
    list_for_each_entry(), so it is incorrect to assume that the iterator
    value will be NULL if the list is empty or no element is found.
    
    To fix the bug, Use a new value 'iter' as the list iterator, while use
    the old value 'p' as a dedicated variable to point to the found element.
    
    Fixes: dfaa973ae960 ("KVM: PPC: Book3S HV: In H_SVM_INIT_DONE, migrate remaining normal-GFNs to secure-GFNs")
    Cc: stable@vger.kernel.org # v5.9+
    Signed-off-by: Xiaomeng Tong <xiam0nd.tong@gmail.com>
    Signed-off-by: Michael Ellerman <mpe@ellerman.id.au>
    Link: https://lore.kernel.org/r/20220414062103.8153-1-xiam0nd.tong@gmail.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 91a36ec160ec1a0c8f5352b772dffcbb0b6023e3
Author: Florian Westphal <fw@strlen.de>
Date:   Fri May 20 00:02:04 2022 +0200

    netfilter: conntrack: re-fetch conntrack after insertion
    
    commit 56b14ecec97f39118bf85c9ac2438c5a949509ed upstream.
    
    In case the conntrack is clashing, insertion can free skb->_nfct and
    set skb->_nfct to the already-confirmed entry.
    
    This wasn't found before because the conntrack entry and the extension
    space used to free'd after an rcu grace period, plus the race needs
    events enabled to trigger.
    
    Reported-by: <syzbot+793a590957d9c1b96620@syzkaller.appspotmail.com>
    Fixes: 71d8c47fc653 ("netfilter: conntrack: introduce clash resolution on insertion race")
    Fixes: 2ad9d7747c10 ("netfilter: conntrack: free extension area immediately")
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c0aff1faf66b6b7a19103f83e6a5d0fdc64b9048
Author: Pablo Neira Ayuso <pablo@netfilter.org>
Date:   Fri May 27 09:56:18 2022 +0200

    netfilter: nf_tables: sanitize nft_set_desc_concat_parse()
    
    commit fecf31ee395b0295f2d7260aa29946b7605f7c85 upstream.
    
    Add several sanity checks for nft_set_desc_concat_parse():
    
    - validate desc->field_count not larger than desc->field_len array.
    - field length cannot be larger than desc->field_len (ie. U8_MAX)
    - total length of the concatenation cannot be larger than register array.
    
    Joint work with Florian Westphal.
    
    Fixes: f3a2181e16f1 ("netfilter: nf_tables: Support for sets with multiple ranged fields")
    Reported-by: <zhangziming.zzm@antgroup.com>
    Reviewed-by: Stefano Brivio <sbrivio@redhat.com>
    Signed-off-by: Florian Westphal <fw@strlen.de>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 44f1ce55308d914e911184d3df30a1a6d78253e7
Author: Nicolai Stange <nstange@suse.de>
Date:   Thu Jun 2 22:22:32 2022 +0200

    crypto: drbg - make reseeding from get_random_bytes() synchronous
    
    commit 074bcd4000e0d812bc253f86fedc40f81ed59ccc upstream.
    
    get_random_bytes() usually hasn't full entropy available by the time DRBG
    instances are first getting seeded from it during boot. Thus, the DRBG
    implementation registers random_ready_callbacks which would in turn
    schedule some work for reseeding the DRBGs once get_random_bytes() has
    sufficient entropy available.
    
    For reference, the relevant history around handling DRBG (re)seeding in
    the context of a not yet fully seeded get_random_bytes() is:
    
      commit 16b369a91d0d ("random: Blocking API for accessing
                            nonblocking_pool")
      commit 4c7879907edd ("crypto: drbg - add async seeding operation")
    
      commit 205a525c3342 ("random: Add callback API for random pool
                            readiness")
      commit 57225e679788 ("crypto: drbg - Use callback API for random
                            readiness")
      commit c2719503f5e1 ("random: Remove kernel blocking API")
    
    However, some time later, the initialization state of get_random_bytes()
    has been made queryable via rng_is_initialized() introduced with commit
    9a47249d444d ("random: Make crng state queryable"). This primitive now
    allows for streamlining the DRBG reseeding from get_random_bytes() by
    replacing that aforementioned asynchronous work scheduling from
    random_ready_callbacks with some simpler, synchronous code in
    drbg_generate() next to the related logic already present therein. Apart
    from improving overall code readability, this change will also enable DRBG
    users to rely on wait_for_random_bytes() for ensuring that the initial
    seeding has completed, if desired.
    
    The previous patches already laid the grounds by making drbg_seed() to
    record at each DRBG instance whether it was being seeded at a time when
    rng_is_initialized() still had been false as indicated by
    ->seeded == DRBG_SEED_STATE_PARTIAL.
    
    All that remains to be done now is to make drbg_generate() check for this
    condition, determine whether rng_is_initialized() has flipped to true in
    the meanwhile and invoke a reseed from get_random_bytes() if so.
    
    Make this move:
    - rename the former drbg_async_seed() work handler, i.e. the one in charge
      of reseeding a DRBG instance from get_random_bytes(), to
      "drbg_seed_from_random()",
    - change its signature as appropriate, i.e. make it take a struct
      drbg_state rather than a work_struct and change its return type from
      "void" to "int" in order to allow for passing error information from
      e.g. its __drbg_seed() invocation onwards to callers,
    - make drbg_generate() invoke this drbg_seed_from_random() once it
      encounters a DRBG instance with ->seeded == DRBG_SEED_STATE_PARTIAL by
      the time rng_is_initialized() has flipped to true and
    - prune everything related to the former, random_ready_callback based
      mechanism.
    
    As drbg_seed_from_random() is now getting invoked from drbg_generate() with
    the ->drbg_mutex being held, it must not attempt to recursively grab it
    once again. Remove the corresponding mutex operations from what is now
    drbg_seed_from_random(). Furthermore, as drbg_seed_from_random() can now
    report errors directly to its caller, there's no need for it to temporarily
    switch the DRBG's ->seeded state to DRBG_SEED_STATE_UNSEEDED so that a
    failure of the subsequently invoked __drbg_seed() will get signaled to
    drbg_generate(). Don't do it then.
    
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    [Jason: for stable, undid the modifications for the backport of 5acd3548.]
    Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e744e34a3c35644b5af2b45053fbd178a15bf73f
Author: Nicolai Stange <nstange@suse.de>
Date:   Thu Jun 2 22:22:31 2022 +0200

    crypto: drbg - move dynamic ->reseed_threshold adjustments to __drbg_seed()
    
    commit 262d83a4290c331cd4f617a457408bdb82fbb738 upstream.
    
    Since commit 42ea507fae1a ("crypto: drbg - reseed often if seedsource is
    degraded"), the maximum seed lifetime represented by ->reseed_threshold
    gets temporarily lowered if the get_random_bytes() source cannot provide
    sufficient entropy yet, as is common during boot, and restored back to
    the original value again once that has changed.
    
    More specifically, if the add_random_ready_callback() invoked from
    drbg_prepare_hrng() in the course of DRBG instantiation does not return
    -EALREADY, that is, if get_random_bytes() has not been fully initialized
    at this point yet, drbg_prepare_hrng() will lower ->reseed_threshold
    to a value of 50. The drbg_async_seed() scheduled from said
    random_ready_callback will eventually restore the original value.
    
    A future patch will replace the random_ready_callback based notification
    mechanism and thus, there will be no add_random_ready_callback() return
    value anymore which could get compared to -EALREADY.
    
    However, there's __drbg_seed() which gets invoked in the course of both,
    the DRBG instantiation as well as the eventual reseeding from
    get_random_bytes() in aforementioned drbg_async_seed(), if any. Moreover,
    it knows about the get_random_bytes() initialization state by the time the
    seed data had been obtained from it: the new_seed_state argument introduced
    with the previous patch would get set to DRBG_SEED_STATE_PARTIAL in case
    get_random_bytes() had not been fully initialized yet and to
    DRBG_SEED_STATE_FULL otherwise. Thus, __drbg_seed() provides a convenient
    alternative for managing that ->reseed_threshold lowering and restoring at
    a central place.
    
    Move all ->reseed_threshold adjustment code from drbg_prepare_hrng() and
    drbg_async_seed() respectively to __drbg_seed(). Make __drbg_seed()
    lower the ->reseed_threshold to 50 in case its new_seed_state argument
    equals DRBG_SEED_STATE_PARTIAL and let it restore the original value
    otherwise.
    
    There is no change in behaviour.
    
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Reviewed-by: Stephan M√ºller <smueller@chronox.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 54700e82a7a75d0f2b9126b7ff8bdd26efad738a
Author: Nicolai Stange <nstange@suse.de>
Date:   Thu Jun 2 22:22:30 2022 +0200

    crypto: drbg - track whether DRBG was seeded with !rng_is_initialized()
    
    commit 2bcd25443868aa8863779a6ebc6c9319633025d2 upstream.
    
    Currently, the DRBG implementation schedules asynchronous works from
    random_ready_callbacks for reseeding the DRBG instances with output from
    get_random_bytes() once the latter has sufficient entropy available.
    
    However, as the get_random_bytes() initialization state can get queried by
    means of rng_is_initialized() now, there is no real need for this
    asynchronous reseeding logic anymore and it's better to keep things simple
    by doing it synchronously when needed instead, i.e. from drbg_generate()
    once rng_is_initialized() has flipped to true.
    
    Of course, for this to work, drbg_generate() would need some means by which
    it can tell whether or not rng_is_initialized() has flipped to true since
    the last seeding from get_random_bytes(). Or equivalently, whether or not
    the last seed from get_random_bytes() has happened when
    rng_is_initialized() was still evaluating to false.
    
    As it currently stands, enum drbg_seed_state allows for the representation
    of two different DRBG seeding states: DRBG_SEED_STATE_UNSEEDED and
    DRBG_SEED_STATE_FULL. The former makes drbg_generate() to invoke a full
    reseeding operation involving both, the rather expensive jitterentropy as
    well as the get_random_bytes() randomness sources. The DRBG_SEED_STATE_FULL
    state on the other hand implies that no reseeding at all is required for a
    !->pr DRBG variant.
    
    Introduce the new DRBG_SEED_STATE_PARTIAL state to enum drbg_seed_state for
    representing the condition that a DRBG was being seeded when
    rng_is_initialized() had still been false. In particular, this new state
    implies that
    - the given DRBG instance has been fully seeded from the jitterentropy
      source (if enabled)
    - and drbg_generate() is supposed to reseed from get_random_bytes()
      *only* once rng_is_initialized() turns to true.
    
    Up to now, the __drbg_seed() helper used to set the given DRBG instance's
    ->seeded state to constant DRBG_SEED_STATE_FULL. Introduce a new argument
    allowing for the specification of the to be written ->seeded value instead.
    Make the first of its two callers, drbg_seed(), determine the appropriate
    value based on rng_is_initialized(). The remaining caller,
    drbg_async_seed(), is known to get invoked only once rng_is_initialized()
    is true, hence let it pass constant DRBG_SEED_STATE_FULL for the new
    argument to __drbg_seed().
    
    There is no change in behaviour, except for that the pr_devel() in
    drbg_generate() would now report "unseeded" for ->pr DRBG instances which
    had last been seeded when rng_is_initialized() was still evaluating to
    false.
    
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Reviewed-by: Stephan M√ºller <smueller@chronox.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b2bef5500e0d2000c40c361720b0788db2abca5e
Author: Nicolai Stange <nstange@suse.de>
Date:   Thu Jun 2 22:22:29 2022 +0200

    crypto: drbg - prepare for more fine-grained tracking of seeding state
    
    commit ce8ce31b2c5c8b18667784b8c515650c65d57b4e upstream.
    
    There are two different randomness sources the DRBGs are getting seeded
    from, namely the jitterentropy source (if enabled) and get_random_bytes().
    At initial DRBG seeding time during boot, the latter might not have
    collected sufficient entropy for seeding itself yet and thus, the DRBG
    implementation schedules a reseed work from a random_ready_callback once
    that has happened. This is particularly important for the !->pr DRBG
    instances, for which (almost) no further reseeds are getting triggered
    during their lifetime.
    
    Because collecting data from the jitterentropy source is a rather expensive
    operation, the aforementioned asynchronously scheduled reseed work
    restricts itself to get_random_bytes() only. That is, it in some sense
    amends the initial DRBG seed derived from jitterentropy output at full
    (estimated) entropy with fresh randomness obtained from get_random_bytes()
    once that has been seeded with sufficient entropy itself.
    
    With the advent of rng_is_initialized(), there is no real need for doing
    the reseed operation from an asynchronously scheduled work anymore and a
    subsequent patch will make it synchronous by moving it next to related
    logic already present in drbg_generate().
    
    However, for tracking whether a full reseed including the jitterentropy
    source is required or a "partial" reseed involving only get_random_bytes()
    would be sufficient already, the boolean struct drbg_state's ->seeded
    member must become a tristate value.
    
    Prepare for this by introducing the new enum drbg_seed_state and change
    struct drbg_state's ->seeded member's type from bool to that type.
    
    For facilitating review, enum drbg_seed_state is made to only contain
    two members corresponding to the former ->seeded values of false and true
    resp. at this point: DRBG_SEED_STATE_UNSEEDED and DRBG_SEED_STATE_FULL. A
    third one for tracking the intermediate state of "seeded from jitterentropy
    only" will be introduced with a subsequent patch.
    
    There is no change in behaviour at this point.
    
    Signed-off-by: Nicolai Stange <nstange@suse.de>
    Reviewed-by: Stephan M√ºller <smueller@chronox.de>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 630192aa45233acfe3d17952862ca215f6d31f09
Author: Justin M. Forbes <jforbes@fedoraproject.org>
Date:   Thu Jun 2 22:22:28 2022 +0200

    lib/crypto: add prompts back to crypto libraries
    
    commit e56e18985596617ae426ed5997fb2e737cffb58b upstream.
    
    Commit 6048fdcc5f269 ("lib/crypto: blake2s: include as built-in") took
    away a number of prompt texts from other crypto libraries. This makes
    values flip from built-in to module when oldconfig runs, and causes
    problems when these crypto libs need to be built in for thingslike
    BIG_KEYS.
    
    Fixes: 6048fdcc5f269 ("lib/crypto: blake2s: include as built-in")
    Cc: Herbert Xu <herbert@gondor.apana.org.au>
    Cc: linux-crypto@vger.kernel.org
    Signed-off-by: Justin M. Forbes <jforbes@fedoraproject.org>
    [Jason: - moved menu into submenu of lib/ instead of root menu
            - fixed chacha sub-dependencies for CONFIG_CRYPTO]
    Signed-off-by: Jason A. Donenfeld <Jason@zx2c4.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 82f723b8a5adf497f9e34c702a30ca7298615654
Author: Tadeusz Struk <tadeusz.struk@linaro.org>
Date:   Tue May 17 08:13:08 2022 +0900

    exfat: check if cluster num is valid
    
    commit 64ba4b15e5c045f8b746c6da5fc9be9a6b00b61d upstream.
    
    Syzbot reported slab-out-of-bounds read in exfat_clear_bitmap.
    This was triggered by reproducer calling truncute with size 0,
    which causes the following trace:
    
    BUG: KASAN: slab-out-of-bounds in exfat_clear_bitmap+0x147/0x490 fs/exfat/balloc.c:174
    Read of size 8 at addr ffff888115aa9508 by task syz-executor251/365
    
    Call Trace:
     __dump_stack lib/dump_stack.c:77 [inline]
     dump_stack_lvl+0x1e2/0x24b lib/dump_stack.c:118
     print_address_description+0x81/0x3c0 mm/kasan/report.c:233
     __kasan_report mm/kasan/report.c:419 [inline]
     kasan_report+0x1a4/0x1f0 mm/kasan/report.c:436
     __asan_report_load8_noabort+0x14/0x20 mm/kasan/report_generic.c:309
     exfat_clear_bitmap+0x147/0x490 fs/exfat/balloc.c:174
     exfat_free_cluster+0x25a/0x4a0 fs/exfat/fatent.c:181
     __exfat_truncate+0x99e/0xe00 fs/exfat/file.c:217
     exfat_truncate+0x11b/0x4f0 fs/exfat/file.c:243
     exfat_setattr+0xa03/0xd40 fs/exfat/file.c:339
     notify_change+0xb76/0xe10 fs/attr.c:336
     do_truncate+0x1ea/0x2d0 fs/open.c:65
    
    Move the is_valid_cluster() helper from fatent.c to a common
    header to make it reusable in other *.c files. And add is_valid_cluster()
    to validate if cluster number is within valid range in exfat_clear_bitmap()
    and exfat_set_bitmap().
    
    Link: https://syzkaller.appspot.com/bug?id=50381fc73821ecae743b8cf24b4c9a04776f767c
    Reported-by: syzbot+a4087e40b9c13aad7892@syzkaller.appspotmail.com
    Fixes: 1e49a94cf707 ("exfat: add bitmap operations")
    Cc: stable@vger.kernel.org # v5.7+
    Signed-off-by: Tadeusz Struk <tadeusz.struk@linaro.org>
    Reviewed-by: Sungjong Seo <sj1557.seo@samsung.com>
    Signed-off-by: Namjae Jeon <linkinjeon@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1f0681f3bd5665080bde3c5b9568cc27df765ce0
Author: Gustavo A. R. Silva <gustavoars@kernel.org>
Date:   Wed Apr 27 17:47:14 2022 -0500

    drm/i915: Fix -Wstringop-overflow warning in call to intel_read_wm_latency()
    
    commit 336feb502a715909a8136eb6a62a83d7268a353b upstream.
    
    Fix the following -Wstringop-overflow warnings when building with GCC-11:
    
    drivers/gpu/drm/i915/intel_pm.c:3106:9: warning: ‚Äòintel_read_wm_latency‚Äô accessing 16 bytes in a region of size 10 [-Wstringop-overflow=]
     3106 |         intel_read_wm_latency(dev_priv, dev_priv->wm.pri_latency);
          |         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    drivers/gpu/drm/i915/intel_pm.c:3106:9: note: referencing argument 2 of type ‚Äòu16 *‚Äô {aka ‚Äòshort unsigned int *‚Äô}
    drivers/gpu/drm/i915/intel_pm.c:2861:13: note: in a call to function ‚Äòintel_read_wm_latency‚Äô
     2861 | static void intel_read_wm_latency(struct drm_i915_private *dev_priv,
          |             ^~~~~~~~~~~~~~~~~~~~~
    
    by removing the over-specified array size from the argument declarations.
    
    It seems that this code is actually safe because the size of the
    array depends on the hardware generation, and the function checks
    for that.
    
    Notice that wm can be an array of 5 elements:
    drivers/gpu/drm/i915/intel_pm.c:3109:   intel_read_wm_latency(dev_priv, dev_priv->wm.pri_latency);
    
    or an array of 8 elements:
    drivers/gpu/drm/i915/intel_pm.c:3131:   intel_read_wm_latency(dev_priv, dev_priv->wm.skl_latency);
    
    and the compiler legitimately complains about that.
    
    This helps with the ongoing efforts to globally enable
    -Wstringop-overflow.
    
    Link: https://github.com/KSPP/linux/issues/181
    Signed-off-by: Gustavo A. R. Silva <gustavoars@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2728d95c6c952ccf2c9a4b769b5852dfb36268af
Author: Dave Chinner <dchinner@redhat.com>
Date:   Fri May 27 16:02:19 2022 +0300

    xfs: Fix CIL throttle hang when CIL space used going backwards
    
    commit 19f4e7cc819771812a7f527d7897c2deffbf7a00 upstream.
    
    A hang with tasks stuck on the CIL hard throttle was reported and
    largely diagnosed by Donald Buczek, who discovered that it was a
    result of the CIL context space usage decrementing in committed
    transactions once the hard throttle limit had been hit and processes
    were already blocked.  This resulted in the CIL push not waking up
    those waiters because the CIL context was no longer over the hard
    throttle limit.
    
    The surprising aspect of this was the CIL space usage going
    backwards regularly enough to trigger this situation. Assumptions
    had been made in design that the relogging process would only
    increase the size of the objects in the CIL, and so that space would
    only increase.
    
    This change and commit message fixes the issue and documents the
    result of an audit of the triggers that can cause the CIL space to
    go backwards, how large the backwards steps tend to be, the
    frequency in which they occur, and what the impact on the CIL
    accounting code is.
    
    Even though the CIL ctx->space_used can go backwards, it will only
    do so if the log item is already logged to the CIL and contains a
    space reservation for it's entire logged state. This is tracked by
    the shadow buffer state on the log item. If the item is not
    previously logged in the CIL it has no shadow buffer nor log vector,
    and hence the entire size of the logged item copied to the log
    vector is accounted to the CIL space usage. i.e.  it will always go
    up in this case.
    
    If the item has a log vector (i.e. already in the CIL) and the size
    decreases, then the existing log vector will be overwritten and the
    space usage will go down. This is the only condition where the space
    usage reduces, and it can only occur when an item is already tracked
    in the CIL. Hence we are safe from CIL space usage underruns as a
    result of log items decreasing in size when they are relogged.
    
    Typically this reduction in CIL usage occurs from metadata blocks
    being free, such as when a btree block merge occurs or a directory
    enter/xattr entry is removed and the da-tree is reduced in size.
    This generally results in a reduction in size of around a single
    block in the CIL, but also tends to increase the number of log
    vectors because the parent and sibling nodes in the tree needs to be
    updated when a btree block is removed. If a multi-level merge
    occurs, then we see reduction in size of 2+ blocks, but again the
    log vector count goes up.
    
    The other vector is inode fork size changes, which only log the
    current size of the fork and ignore the previously logged size when
    the fork is relogged. Hence if we are removing items from the inode
    fork (dir/xattr removal in shortform, extent record removal in
    extent form, etc) the relogged size of the inode for can decrease.
    
    No other log items can decrease in size either because they are a
    fixed size (e.g. dquots) or they cannot be relogged (e.g. relogging
    an intent actually creates a new intent log item and doesn't relog
    the old item at all.) Hence the only two vectors for CIL context
    size reduction are relogging inode forks and marking buffers active
    in the CIL as stale.
    
    Long story short: the majority of the code does the right thing and
    handles the reduction in log item size correctly, and only the CIL
    hard throttle implementation is problematic and needs fixing. This
    patch makes that fix, as well as adds comments in the log item code
    that result in items shrinking in size when they are relogged as a
    clear reminder that this can and does happen frequently.
    
    The throttle fix is based upon the change Donald proposed, though it
    goes further to ensure that once the throttle is activated, it
    captures all tasks until the CIL push issues a wakeup, regardless of
    whether the CIL space used has gone back under the throttle
    threshold.
    
    This ensures that we prevent tasks reducing the CIL slightly under
    the throttle threshold and then making more changes that push it
    well over the throttle limit. This is acheived by checking if the
    throttle wait queue is already active as a condition of throttling.
    Hence once we start throttling, we continue to apply the throttle
    until the CIL context push wakes everything on the wait queue.
    
    We can use waitqueue_active() for the waitqueue manipulations and
    checks as they are all done under the ctx->xc_push_lock. Hence the
    waitqueue has external serialisation and we can safely peek inside
    the wait queue without holding the internal waitqueue locks.
    
    Many thanks to Donald for his diagnostic and analysis work to
    isolate the cause of this hang.
    
    Reported-and-tested-by: Donald Buczek <buczek@molgen.mpg.de>
    Signed-off-by: Dave Chinner <dchinner@redhat.com>
    Reviewed-by: Brian Foster <bfoster@redhat.com>
    Reviewed-by: Chandan Babu R <chandanrlinux@gmail.com>
    Reviewed-by: Darrick J. Wong <djwong@kernel.org>
    Reviewed-by: Allison Henderson <allison.henderson@oracle.com>
    Signed-off-by: Darrick J. Wong <djwong@kernel.org>
    Signed-off-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a9e7f19a5577894242e09dab6dcfc8064e634a1c
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Fri May 27 16:02:18 2022 +0300

    xfs: fix an ABBA deadlock in xfs_rename
    
    commit 6da1b4b1ab36d80a3994fd4811c8381de10af604 upstream.
    
    When overlayfs is running on top of xfs and the user unlinks a file in
    the overlay, overlayfs will create a whiteout inode and ask xfs to
    "rename" the whiteout file atop the one being unlinked.  If the file
    being unlinked loses its one nlink, we then have to put the inode on the
    unlinked list.
    
    This requires us to grab the AGI buffer of the whiteout inode to take it
    off the unlinked list (which is where whiteouts are created) and to grab
    the AGI buffer of the file being deleted.  If the whiteout was created
    in a higher numbered AG than the file being deleted, we'll lock the AGIs
    in the wrong order and deadlock.
    
    Therefore, grab all the AGI locks we think we'll need ahead of time, and
    in order of increasing AG number per the locking rules.
    
    Reported-by: wenli xie <wlxie7296@gmail.com>
    Fixes: 93597ae8dac0 ("xfs: Fix deadlock between AGI and AGF when target_ip exists in xfs_rename()")
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Brian Foster <bfoster@redhat.com>
    Signed-off-by: Amir Goldstein <amir73il@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 72464fd2b4b76fe924fd8c3d5bfe9b10a61aaa1c
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Fri May 27 16:02:17 2022 +0300

    xfs: fix the forward progress assertion in xfs_iwalk_run_callbacks
    
    commit a5336d6bb2d02d0e9d4d3c8be04b80b8b68d56c8 upstream.
    
    In commit 27c14b5daa82 we started tracking the last inode seen during an
    inode walk to avoid infinite loops if a corrupt inobt record happens to
    have a lower ir_startino than the record preceeding it.  Unfortunately,
    the assertion trips over the case where there are completely empty inobt
    records (which can happen quite easily on 64k page filesystems) because
    we advance the tracking cursor without actually putting the empty record
    into the processing buffer.  Fix the assert to allow for this case.
    
    Reported-by: zlang@redhat.com
    Fixes: 27c14b5daa82 ("xfs: ensure inobt record walks always make forward progress")
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Zorro Lang <zlang@redhat.com>
    Reviewed-by: Dave Chinner <dchinner@redhat.com>
    Signed-off-by: Amir Goldstein <amir73il@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 45d97f70da4d47f303a5202dba124c1d0e9120c3
Author: Kaixu Xia <kaixuxia@tencent.com>
Date:   Fri May 27 16:02:16 2022 +0300

    xfs: show the proper user quota options
    
    commit 237d7887ae723af7d978e8b9a385fdff416f357b upstream.
    
    The quota option 'usrquota' should be shown if both the XFS_UQUOTA_ACCT
    and XFS_UQUOTA_ENFD flags are set. The option 'uqnoenforce' should be
    shown when only the XFS_UQUOTA_ACCT flag is set. The current code logic
    seems wrong, Fix it and show proper options.
    
    Signed-off-by: Kaixu Xia <kaixuxia@tencent.com>
    Reviewed-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Signed-off-by: Amir Goldstein <amir73il@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f20e67b455e425a0d3d03f27bda5fdd32dc2c324
Author: Darrick J. Wong <darrick.wong@oracle.com>
Date:   Fri May 27 16:02:15 2022 +0300

    xfs: detect overflows in bmbt records
    
    commit acf104c2331c1ba2a667e65dd36139d1555b1432 upstream.
    
    Detect file block mappings with a blockcount that's either so large that
    integer overflows occur or are zero, because neither are valid in the
    filesystem.  Worse yet, attempting directory modifications causes the
    iext code to trip over the bmbt key handling and takes the filesystem
    down.  We can fix most of this by preventing the bad metadata from
    entering the incore structures in the first place.
    
    Found by setting blockcount=0 in a directory data fork mapping and
    watching the fireworks.
    
    Signed-off-by: Darrick J. Wong <darrick.wong@oracle.com>
    Reviewed-by: Christoph Hellwig <hch@lst.de>
    Signed-off-by: Amir Goldstein <amir73il@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ffc8d613876f0225ac3cfe047fd0ab31623825cf
Author: Alex Elder <elder@linaro.org>
Date:   Thu Apr 21 13:53:33 2022 -0500

    net: ipa: compute proper aggregation limit
    
    commit c5794097b269f15961ed78f7f27b50e51766dec9 upstream.
    
    The aggregation byte limit for an endpoint is currently computed
    based on the endpoint's receive buffer size.
    
    However, some bytes at the front of each receive buffer are reserved
    on the assumption that--as with SKBs--it might be useful to insert
    data (such as headers) before what lands in the buffer.
    
    The aggregation byte limit currently doesn't take into account that
    reserved space, and as a result, aggregation could require space
    past that which is available in the buffer.
    
    Fix this by reducing the size used to compute the aggregation byte
    limit by the NET_SKB_PAD offset reserved for each receive buffer.
    
    Signed-off-by: Alex Elder <elder@linaro.org>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8adb751d294ed3b668f1c7e41bd7ebe49002a744
Author: Pavel Begunkov <asml.silence@gmail.com>
Date:   Fri Jun 3 13:17:05 2022 +0100

    io_uring: fix using under-expanded iters
    
    [ upstream commit cd65869512ab5668a5d16f789bc4da1319c435c4 ]
    
    The issue was first described and addressed in
    89c2b3b7491820 ("io_uring: reexpand under-reexpanded iters"), but
    shortly after reimplemented as.
    cd65869512ab56 ("io_uring: use iov_iter state save/restore helpers").
    
    Here we follow the approach from the second patch but without in-callback
    resubmissions, fixups for not yet supported in 5.10 short read retries
    and replacing iov_iter_state with iter copies to not pull even more
    dependencies, and because it's just much simpler.
    
    Signed-off-by: Pavel Begunkov <asml.silence@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 57d01bcae7041cfb86553091718d12bf36c082aa
Author: Pavel Begunkov <asml.silence@gmail.com>
Date:   Fri Jun 3 13:17:04 2022 +0100

    io_uring: don't re-import iovecs from callbacks
    
    We can't re-import or modify iterators from iocb callbacks, it's not
    safe as it might be reverted and/or reexpanded while unwinding stack.
    It's also not safe to resubmit as io-wq thread will race with stack
    undwinding for the iterator and other data.
    
    Disallow resubmission from callbacks, it can fail some cases that were
    handled before, but the possibility of such a failure was a part of the
    API from the beginning and so it should be fine.
    
    Signed-off-by: Pavel Begunkov <asml.silence@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6029f86740c92c182ff29b34b3c40bb5462050a1
Author: Stephen Brennan <stephen.s.brennan@oracle.com>
Date:   Thu May 19 09:50:30 2022 +0100

    assoc_array: Fix BUG_ON during garbage collect
    
    commit d1dc87763f406d4e67caf16dbe438a5647692395 upstream.
    
    A rare BUG_ON triggered in assoc_array_gc:
    
        [3430308.818153] kernel BUG at lib/assoc_array.c:1609!
    
    Which corresponded to the statement currently at line 1593 upstream:
    
        BUG_ON(assoc_array_ptr_is_meta(p));
    
    Using the data from the core dump, I was able to generate a userspace
    reproducer[1] and determine the cause of the bug.
    
    [1]: https://github.com/brenns10/kernel_stuff/tree/master/assoc_array_gc
    
    After running the iterator on the entire branch, an internal tree node
    looked like the following:
    
        NODE (nr_leaves_on_branch: 3)
          SLOT [0] NODE (2 leaves)
          SLOT [1] NODE (1 leaf)
          SLOT [2..f] NODE (empty)
    
    In the userspace reproducer, the pr_devel output when compressing this
    node was:
    
        -- compress node 0x5607cc089380 --
        free=0, leaves=0
        [0] retain node 2/1 [nx 0]
        [1] fold node 1/1 [nx 0]
        [2] fold node 0/1 [nx 2]
        [3] fold node 0/2 [nx 2]
        [4] fold node 0/3 [nx 2]
        [5] fold node 0/4 [nx 2]
        [6] fold node 0/5 [nx 2]
        [7] fold node 0/6 [nx 2]
        [8] fold node 0/7 [nx 2]
        [9] fold node 0/8 [nx 2]
        [10] fold node 0/9 [nx 2]
        [11] fold node 0/10 [nx 2]
        [12] fold node 0/11 [nx 2]
        [13] fold node 0/12 [nx 2]
        [14] fold node 0/13 [nx 2]
        [15] fold node 0/14 [nx 2]
        after: 3
    
    At slot 0, an internal node with 2 leaves could not be folded into the
    node, because there was only one available slot (slot 0). Thus, the
    internal node was retained. At slot 1, the node had one leaf, and was
    able to be folded in successfully. The remaining nodes had no leaves,
    and so were removed. By the end of the compression stage, there were 14
    free slots, and only 3 leaf nodes. The tree was ascended and then its
    parent node was compressed. When this node was seen, it could not be
    folded, due to the internal node it contained.
    
    The invariant for compression in this function is: whenever
    nr_leaves_on_branch < ASSOC_ARRAY_FAN_OUT, the node should contain all
    leaf nodes. The compression step currently cannot guarantee this, given
    the corner case shown above.
    
    To fix this issue, retry compression whenever we have retained a node,
    and yet nr_leaves_on_branch < ASSOC_ARRAY_FAN_OUT. This second
    compression will then allow the node in slot 1 to be folded in,
    satisfying the invariant. Below is the output of the reproducer once the
    fix is applied:
    
        -- compress node 0x560e9c562380 --
        free=0, leaves=0
        [0] retain node 2/1 [nx 0]
        [1] fold node 1/1 [nx 0]
        [2] fold node 0/1 [nx 2]
        [3] fold node 0/2 [nx 2]
        [4] fold node 0/3 [nx 2]
        [5] fold node 0/4 [nx 2]
        [6] fold node 0/5 [nx 2]
        [7] fold node 0/6 [nx 2]
        [8] fold node 0/7 [nx 2]
        [9] fold node 0/8 [nx 2]
        [10] fold node 0/9 [nx 2]
        [11] fold node 0/10 [nx 2]
        [12] fold node 0/11 [nx 2]
        [13] fold node 0/12 [nx 2]
        [14] fold node 0/13 [nx 2]
        [15] fold node 0/14 [nx 2]
        internal nodes remain despite enough space, retrying
        -- compress node 0x560e9c562380 --
        free=14, leaves=1
        [0] fold node 2/15 [nx 0]
        after: 3
    
    Changes
    =======
    DH:
     - Use false instead of 0.
     - Reorder the inserted lines in a couple of places to put retained before
       next_slot.
    
    ver #2)
     - Fix typo in pr_devel, correct comparison to "<="
    
    Fixes: 3cb989501c26 ("Add a generic associative array implementation.")
    Cc: <stable@vger.kernel.org>
    Signed-off-by: Stephen Brennan <stephen.s.brennan@oracle.com>
    Signed-off-by: David Howells <dhowells@redhat.com>
    cc: Andrew Morton <akpm@linux-foundation.org>
    cc: keyrings@vger.kernel.org
    Link: https://lore.kernel.org/r/20220511225517.407935-1-stephen.s.brennan@oracle.com/ # v1
    Link: https://lore.kernel.org/r/20220512215045.489140-1-stephen.s.brennan@oracle.com/ # v2
    Reviewed-by: Jarkko Sakkinen <jarkko@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b96b4aa65bbc0364ea44807f3a32b8d862008aa6
Author: Miri Korenblit <miriam.rachel.korenblit@intel.com>
Date:   Fri Jun 18 13:41:46 2021 +0300

    cfg80211: set custom regdomain after wiphy registration
    
    commit 1b7b3ac8ff3317cdcf07a1c413de9bdb68019c2b upstream.
    
    We used to set regulatory info before the registration of
    the device and then the regulatory info didn't get set, because
    the device isn't registered so there isn't a device to set the
    regulatory info for. So set the regulatory info after the device
    registration.
    Call reg_process_self_managed_hints() once again after the device
    registration because it does nothing before it.
    
    Signed-off-by: Miri Korenblit <miriam.rachel.korenblit@intel.com>
    Signed-off-by: Luca Coelho <luciano.coelho@intel.com>
    Link: https://lore.kernel.org/r/iwlwifi.20210618133832.c96eadcffe80.I86799c2c866b5610b4cf91115c21d8ceb525c5aa@changeid
    Signed-off-by: Johannes Berg <johannes.berg@intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8fbd54ab06c955d247c1a91d5d980cddc868f1e7
Author: David Howells <dhowells@redhat.com>
Date:   Thu May 26 07:34:52 2022 +0100

    pipe: Fix missing lock in pipe_resize_ring()
    
    commit 189b0ddc245139af81198d1a3637cac74f96e13a upstream.
    
    pipe_resize_ring() needs to take the pipe->rd_wait.lock spinlock to
    prevent post_one_notification() from trying to insert into the ring
    whilst the ring is being replaced.
    
    The occupancy check must be done after the lock is taken, and the lock
    must be taken after the new ring is allocated.
    
    The bug can lead to an oops looking something like:
    
     BUG: KASAN: use-after-free in post_one_notification.isra.0+0x62e/0x840
     Read of size 4 at addr ffff88801cc72a70 by task poc/27196
     ...
     Call Trace:
      post_one_notification.isra.0+0x62e/0x840
      __post_watch_notification+0x3b7/0x650
      key_create_or_update+0xb8b/0xd20
      __do_sys_add_key+0x175/0x340
      __x64_sys_add_key+0xbe/0x140
      do_syscall_64+0x5c/0xc0
      entry_SYSCALL_64_after_hwframe+0x44/0xae
    
    Reported by Selim Enes Karaduman @Enesdex working with Trend Micro Zero
    Day Initiative.
    
    Fixes: c73be61cede5 ("pipe: Add general notification queue support")
    Reported-by: zdi-disclosures@trendmicro.com # ZDI-CAN-17291
    Signed-off-by: David Howells <dhowells@redhat.com>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit cd720fad8b574f449fef015514542bd7455abde5
Author: Kuniyuki Iwashima <kuniyu@amazon.co.jp>
Date:   Fri Apr 29 14:38:01 2022 -0700

    pipe: make poll_usage boolean and annotate its access
    
    commit f485922d8fe4e44f6d52a5bb95a603b7c65554bb upstream.
    
    Patch series "Fix data-races around epoll reported by KCSAN."
    
    This series suppresses a false positive KCSAN's message and fixes a real
    data-race.
    
    
    This patch (of 2):
    
    pipe_poll() runs locklessly and assigns 1 to poll_usage.  Once poll_usage
    is set to 1, it never changes in other places.  However, concurrent writes
    of a value trigger KCSAN, so let's make KCSAN happy.
    
    BUG: KCSAN: data-race in pipe_poll / pipe_poll
    
    write to 0xffff8880042f6678 of 4 bytes by task 174 on cpu 3:
     pipe_poll (fs/pipe.c:656)
     ep_item_poll.isra.0 (./include/linux/poll.h:88 fs/eventpoll.c:853)
     do_epoll_wait (fs/eventpoll.c:1692 fs/eventpoll.c:1806 fs/eventpoll.c:2234)
     __x64_sys_epoll_wait (fs/eventpoll.c:2246 fs/eventpoll.c:2241 fs/eventpoll.c:2241)
     do_syscall_64 (arch/x86/entry/common.c:50 arch/x86/entry/common.c:80)
     entry_SYSCALL_64_after_hwframe (arch/x86/entry/entry_64.S:113)
    
    write to 0xffff8880042f6678 of 4 bytes by task 177 on cpu 1:
     pipe_poll (fs/pipe.c:656)
     ep_item_poll.isra.0 (./include/linux/poll.h:88 fs/eventpoll.c:853)
     do_epoll_wait (fs/eventpoll.c:1692 fs/eventpoll.c:1806 fs/eventpoll.c:2234)
     __x64_sys_epoll_wait (fs/eventpoll.c:2246 fs/eventpoll.c:2241 fs/eventpoll.c:2241)
     do_syscall_64 (arch/x86/entry/common.c:50 arch/x86/entry/common.c:80)
     entry_SYSCALL_64_after_hwframe (arch/x86/entry/entry_64.S:113)
    
    Reported by Kernel Concurrency Sanitizer on:
    CPU: 1 PID: 177 Comm: epoll_race Not tainted 5.17.0-58927-gf443e374ae13 #6
    Hardware name: Red Hat KVM, BIOS 1.11.0-2.amzn2 04/01/2014
    
    Link: https://lkml.kernel.org/r/20220322002653.33865-1-kuniyu@amazon.co.jp
    Link: https://lkml.kernel.org/r/20220322002653.33865-2-kuniyu@amazon.co.jp
    Fixes: 3b844826b6c6 ("pipe: avoid unnecessary EPOLLET wakeups under normal loads")
    Signed-off-by: Kuniyuki Iwashima <kuniyu@amazon.co.jp>
    Cc: Alexander Duyck <alexander.h.duyck@intel.com>
    Cc: Al Viro <viro@zeniv.linux.org.uk>
    Cc: Davidlohr Bueso <dave@stgolabs.net>
    Cc: Kuniyuki Iwashima <kuni1840@gmail.com>
    Cc: "Soheil Hassas Yeganeh" <soheil@google.com>
    Cc: "Sridhar Samudrala" <sridhar.samudrala@intel.com>
    Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ea62d169b6e731e0b54abda1d692406f6bc6a696
Author: Pablo Neira Ayuso <pablo@netfilter.org>
Date:   Wed May 25 10:36:38 2022 +0200

    netfilter: nf_tables: disallow non-stateful expression in sets earlier
    
    commit 520778042ccca019f3ffa136dd0ca565c486cedd upstream.
    
    Since 3e135cd499bf ("netfilter: nft_dynset: dynamic stateful expression
    instantiation"), it is possible to attach stateful expressions to set
    elements.
    
    cd5125d8f518 ("netfilter: nf_tables: split set destruction in deactivate
    and destroy phase") introduces conditional destruction on the object to
    accomodate transaction semantics.
    
    nft_expr_init() calls expr->ops->init() first, then check for
    NFT_STATEFUL_EXPR, this stills allows to initialize a non-stateful
    lookup expressions which points to a set, which might lead to UAF since
    the set is not properly detached from the set->binding for this case.
    Anyway, this combination is non-sense from nf_tables perspective.
    
    This patch fixes this problem by checking for NFT_STATEFUL_EXPR before
    expr->ops->init() is called.
    
    The reporter provides a KASAN splat and a poc reproducer (similar to
    those autogenerated by syzbot to report use-after-free errors). It is
    unknown to me if they are using syzbot or if they use similar automated
    tool to locate the bug that they are reporting.
    
    For the record, this is the KASAN splat.
    
    [   85.431824] ==================================================================
    [   85.432901] BUG: KASAN: use-after-free in nf_tables_bind_set+0x81b/0xa20
    [   85.433825] Write of size 8 at addr ffff8880286f0e98 by task poc/776
    [   85.434756]
    [   85.434999] CPU: 1 PID: 776 Comm: poc Tainted: G        W         5.18.0+ #2
    [   85.436023] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.14.0-2 04/01/2014
    
    Fixes: 0b2d8a7b638b ("netfilter: nf_tables: add helper functions for expression handling")
    Reported-and-tested-by: Aaron Adams <edg-e@nccgroup.com>
    Signed-off-by: Pablo Neira Ayuso <pablo@netfilter.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5525af175be2184e0c87e268bd17c81235662f7d
Author: Piyush Malgujar <pmalgujar@marvell.com>
Date:   Wed May 11 06:36:59 2022 -0700

    drivers: i2c: thunderx: Allow driver to work with ACPI defined TWSI controllers
    
    [ Upstream commit 03a35bc856ddc09f2cc1f4701adecfbf3b464cb3 ]
    
    Due to i2c->adap.dev.fwnode not being set, ACPI_COMPANION() wasn't properly
    found for TWSI controllers.
    
    Signed-off-by: Szymon Balcerak <sbalcerak@marvell.com>
    Signed-off-by: Piyush Malgujar <pmalgujar@marvell.com>
    Signed-off-by: Wolfram Sang <wsa@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit f0749aecb20b2d8fbc600a4467f29c6572e4f434
Author: Mika Westerberg <mika.westerberg@linux.intel.com>
Date:   Wed Apr 27 13:19:10 2022 +0300

    i2c: ismt: Provide a DMA buffer for Interrupt Cause Logging
    
    [ Upstream commit 17a0f3acdc6ec8b89ad40f6e22165a4beee25663 ]
    
    Before sending a MSI the hardware writes information pertinent to the
    interrupt cause to a memory location pointed by SMTICL register. This
    memory holds three double words where the least significant bit tells
    whether the interrupt cause of master/target/error is valid. The driver
    does not use this but we need to set it up because otherwise it will
    perform DMA write to the default address (0) and this will cause an
    IOMMU fault such as below:
    
      DMAR: DRHD: handling fault status reg 2
      DMAR: [DMA Write] Request device [00:12.0] PASID ffffffff fault addr 0
            [fault reason 05] PTE Write access is not set
    
    To prevent this from happening, provide a proper DMA buffer for this
    that then gets mapped by the IOMMU accordingly.
    
    Signed-off-by: Mika Westerberg <mika.westerberg@linux.intel.com>
    Reviewed-by: From: Andy Shevchenko <andriy.shevchenko@linux.intel.com>
    Signed-off-by: Wolfram Sang <wsa@kernel.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 828309eee5b639394c84dca27a712c8a714819d0
Author: Joel Stanley <joel@jms.id.au>
Date:   Tue May 17 18:52:17 2022 +0930

    net: ftgmac100: Disable hardware checksum on AST2600
    
    [ Upstream commit 6fd45e79e8b93b8d22fb8fe22c32fbad7e9190bd ]
    
    The AST2600 when using the i210 NIC over NC-SI has been observed to
    produce incorrect checksum results with specific MTU values. This was
    first observed when sending data across a long distance set of networks.
    
    On a local network, the following test was performed using a 1MB file of
    random data.
    
    On the receiver run this script:
    
     #!/bin/bash
     while [ 1 ]; do
            # Zero the stats
            nstat -r  > /dev/null
            nc -l 9899 > test-file
            # Check for checksum errors
            TcpInCsumErrors=$(nstat | grep TcpInCsumErrors)
            if [ -z "$TcpInCsumErrors" ]; then
                    echo No TcpInCsumErrors
            else
                    echo TcpInCsumErrors = $TcpInCsumErrors
            fi
     done
    
    On an AST2600 system:
    
     # nc <IP of  receiver host> 9899 < test-file
    
    The test was repeated with various MTU values:
    
     # ip link set mtu 1410 dev eth0
    
    The observed results:
    
     1500 - good
     1434 - bad
     1400 - good
     1410 - bad
     1420 - good
    
    The test was repeated after disabling tx checksumming:
    
     # ethtool -K eth0 tx-checksumming off
    
    And all MTU values tested resulted in transfers without error.
    
    An issue with the driver cannot be ruled out, however there has been no
    bug discovered so far.
    
    David has done the work to take the original bug report of slow data
    transfer between long distance connections and triaged it down to this
    test case.
    
    The vendor suspects this this is a hardware issue when using NC-SI. The
    fixes line refers to the patch that introduced AST2600 support.
    
    Reported-by: David Wilder <wilder@us.ibm.com>
    Reviewed-by: Dylan Hung <dylan_hung@aspeedtech.com>
    Signed-off-by: Joel Stanley <joel@jms.id.au>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 640397afdf6ebfac558ed8340bac4bfd05f06c53
Author: Lin Ma <linma@zju.edu.cn>
Date:   Wed May 18 18:53:21 2022 +0800

    nfc: pn533: Fix buggy cleanup order
    
    [ Upstream commit b8cedb7093b2d1394cae9b86494cba4b62d3a30a ]
    
    When removing the pn533 device (i2c or USB), there is a logic error. The
    original code first cancels the worker (flush_delayed_work) and then
    destroys the workqueue (destroy_workqueue), leaving the timer the last
    one to be deleted (del_timer). This result in a possible race condition
    in a multi-core preempt-able kernel. That is, if the cleanup
    (pn53x_common_clean) is concurrently run with the timer handler
    (pn533_listen_mode_timer), the timer can queue the poll_work to the
    already destroyed workqueue, causing use-after-free.
    
    This patch reorder the cleanup: it uses the del_timer_sync to make sure
    the handler is finished before the routine will destroy the workqueue.
    Note that the timer cannot be activated by the worker again.
    
    static void pn533_wq_poll(struct work_struct *work)
    ...
     rc = pn533_send_poll_frame(dev);
     if (rc)
       return;
    
     if (cur_mod->len == 0 && dev->poll_mod_count > 1)
       mod_timer(&dev->listen_timer, ...);
    
    That is, the mod_timer can be called only when pn533_send_poll_frame()
    returns no error, which is impossible because the device is detaching
    and the lower driver should return ENODEV code.
    
    Signed-off-by: Lin Ma <linma@zju.edu.cn>
    Signed-off-by: David S. Miller <davem@davemloft.net>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit ac8d5eb26c9edeb139af1e02e1d3743aa2e1fcd7
Author: Thomas Bartschies <thomas.bartschies@cvk.de>
Date:   Wed May 18 08:32:18 2022 +0200

    net: af_key: check encryption module availability consistency
    
    [ Upstream commit 015c44d7bff3f44d569716117becd570c179ca32 ]
    
    Since the recent introduction supporting the SM3 and SM4 hash algos for IPsec, the kernel
    produces invalid pfkey acquire messages, when these encryption modules are disabled. This
    happens because the availability of the algos wasn't checked in all necessary functions.
    This patch adds these checks.
    
    Signed-off-by: Thomas Bartschies <thomas.bartschies@cvk.de>
    Signed-off-by: Steffen Klassert <steffen.klassert@secunet.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit d007f49ab789bee8ed76021830b49745d5feaf61
Author: Al Viro <viro@zeniv.linux.org.uk>
Date:   Wed May 18 02:13:40 2022 -0400

    percpu_ref_init(): clean ->percpu_count_ref on failure
    
    [ Upstream commit a91714312eb16f9ecd1f7f8b3efe1380075f28d4 ]
    
    That way percpu_ref_exit() is safe after failing percpu_ref_init().
    At least one user (cgroup_create()) had a double-free that way;
    there might be other similar bugs.  Easier to fix in percpu_ref_init(),
    rather than playing whack-a-mole in sloppy users...
    
    Usual symptoms look like a messed refcounting in one of subsystems
    that use percpu allocations (might be percpu-refcount, might be
    something else).  Having refcounts for two different objects share
    memory is Not Nice(tm)...
    
    Reported-by: syzbot+5b1e53987f858500ec00@syzkaller.appspotmail.com
    Signed-off-by: Al Viro <viro@zeniv.linux.org.uk>
    Signed-off-by: Sasha Levin <sashal@kernel.org>

commit 75e35951d6ec28a3a1802ffd76fabe788aa8bb02
Author: IotaHydrae <writeforever@foxmail.com>
Date:   Wed May 4 19:59:04 2022 +0800

    pinctrl: sunxi: fix f1c100s uart2 function
    
    [ Upstream commit fa8785e5931367e2b43f2c507f26bcf3e281c0ca ]
    
    Change suniv f1c100s pinctrl,PD14 multiplexing function lvds1 to uart2
    
    When the pin PD13 and PD14 is setting up to uart2 function in dts,
    there's an error occurred:
    1c20800.pinctrl: unsupported function uart2 on pin PD14
    
    Because 'uart2' is not any one multiplexing option of PD14,
    and pinctrl don't know how to configure it.
    
    So change the pin PD14 lvds1 function to uart2.
    
    Signed-off-by: IotaHydrae <writeforever@foxmail.com>
    Reviewed-by: Andre Przywara <andre.przywara@arm.com>
    Link: https://lore.kernel.org/r/tencent_70C1308DDA794C81CAEF389049055BACEC09@qq.com
    Signed-off-by: Linus Walleij <linus.walleij@linaro.org>
    Signed-off-by: Sasha Levin <sashal@kernel.org>
