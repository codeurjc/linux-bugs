commit c275eaaaa34260e6c907bc5e7ee07c096bc45064
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Tue Aug 8 19:58:35 2023 +0200

    Linux 5.15.125
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 754e0c7c4a308ca844a711b435d7efdf0f84d02e
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Tue Aug 8 19:20:48 2023 +0200

    x86: fix backwards merge of GDS/SRSO bit
    
    Stable-tree-only change.
    
    Due to the way the GDS and SRSO patches flowed into the stable tree, it
    was a 50% chance that the merge of the which value GDS and SRSO should
    be.  Of course, I lost that bet, and chose the opposite of what Linus
    chose in commit 64094e7e3118 ("Merge tag 'gds-for-linus-2023-08-01' of
    git://git.kernel.org/pub/scm/linux/kernel/git/tip/tip")
    
    Fix this up by switching the values to match what is now in Linus's tree
    as that is the correct value to mirror.
    
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b14a3924c2675c22e07a5a190223b6b6cdc2867d
Author: Ross Lagerwall <ross.lagerwall@citrix.com>
Date:   Thu Aug 3 08:41:22 2023 +0200

    xen/netback: Fix buffer overrun triggered by unusual packet
    
    commit 534fc31d09b706a16d83533e16b5dc855caf7576 upstream.
    
    It is possible that a guest can send a packet that contains a head + 18
    slots and yet has a len <= XEN_NETBACK_TX_COPY_LEN. This causes nr_slots
    to underflow in xenvif_get_requests() which then causes the subsequent
    loop's termination condition to be wrong, causing a buffer overrun of
    queue->tx_map_ops.
    
    Rework the code to account for the extra frag_overflow slots.
    
    This is CVE-2023-34319 / XSA-432.
    
    Fixes: ad7f402ae4f4 ("xen/netback: Ensure protocol headers don't fall in the non-linear area")
    Signed-off-by: Ross Lagerwall <ross.lagerwall@citrix.com>
    Reviewed-by: Paul Durrant <paul@xen.org>
    Reviewed-by: Wei Liu <wei.liu@kernel.org>
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 153f9a7b02d4f292671e81077e901ef01e123a9f
Author: Borislav Petkov (AMD) <bp@alien8.de>
Date:   Mon Aug 7 10:46:04 2023 +0200

    x86/srso: Tie SBPB bit setting to microcode patch detection
    
    commit 5a15d8348881e9371afdf9f5357a135489496955 upstream.
    
    The SBPB bit in MSR_IA32_PRED_CMD is supported only after a microcode
    patch has been applied so set X86_FEATURE_SBPB only then. Otherwise,
    guests would attempt to set that bit and #GP on the MSR write.
    
    While at it, make SMT detection more robust as some guests - depending
    on how and what CPUID leafs their report - lead to cpu_smt_control
    getting set to CPU_SMT_NOT_SUPPORTED but SRSO_NO should be set for any
    guest incarnation where one simply cannot do SMT, for whatever reason.
    
    Fixes: fb3bd914b3ec ("x86/srso: Add a Speculative RAS Overflow mitigation")
    Reported-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Reported-by: Salvatore Bonaccorso <carnil@debian.org>
    Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit df4c3823cba5c43e2321eface8501bfafe76d0d9
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Fri Jul 28 17:28:43 2023 -0500

    x86/srso: Fix return thunks in generated code
    
    Upstream commit: 238ec850b95a02dcdff3edc86781aa913549282f
    
    Set X86_FEATURE_RETHUNK when enabling the SRSO mitigation so that
    generated code (e.g., ftrace, static call, eBPF) generates "jmp
    __x86_return_thunk" instead of RET.
    
      [ bp: Add a comment. ]
    
    Fixes: fb3bd914b3ec ("x86/srso: Add a Speculative RAS Overflow mitigation")
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0071b17eb66b12151f83cdbfc9824743004f87eb
Author: Borislav Petkov (AMD) <bp@alien8.de>
Date:   Fri Jul 7 13:53:41 2023 +0200

    x86/srso: Add IBPB on VMEXIT
    
    Upstream commit: d893832d0e1ef41c72cdae444268c1d64a2be8ad
    
    Add the option to flush IBPB only on VMEXIT in order to protect from
    malicious guests but one otherwise trusts the software that runs on the
    hypervisor.
    
    Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5398faac76a6188bbacc142984ec143fef7f640c
Author: Borislav Petkov (AMD) <bp@alien8.de>
Date:   Thu Jul 6 15:04:35 2023 +0200

    x86/srso: Add IBPB
    
    Upstream commit: 233d6f68b98d480a7c42ebe78c38f79d44741ca9
    
    Add the option to mitigate using IBPB on a kernel entry. Pull in the
    Retbleed alternative so that the IBPB call from there can be used. Also,
    if Retbleed mitigation is done using IBPB, the same mitigation can and
    must be used here.
    
    Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c24aaa7dde5ff82acb4415c15225e4a42982240d
Author: Borislav Petkov (AMD) <bp@alien8.de>
Date:   Thu Jun 29 17:43:40 2023 +0200

    x86/srso: Add SRSO_NO support
    
    Upstream commit: 1b5277c0ea0b247393a9c426769fde18cff5e2f6
    
    Add support for the CPUID flag which denotes that the CPU is not
    affected by SRSO.
    
    Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4e9115e194a8d21195a5e7600975ed601dd364ff
Author: Borislav Petkov (AMD) <bp@alien8.de>
Date:   Tue Jul 18 11:13:40 2023 +0200

    x86/srso: Add IBPB_BRTYPE support
    
    Upstream commit: 79113e4060aba744787a81edb9014f2865193854
    
    Add support for the synthetic CPUID flag which "if this bit is 1,
    it indicates that MSR 49h (PRED_CMD) bit 0 (IBPB) flushes all branch
    type predictions from the CPU branch predictor."
    
    This flag is there so that this capability in guests can be detected
    easily (otherwise one would have to track microcode revisions which is
    impossible for guests).
    
    It is also needed only for Zen3 and -4. The other two (Zen1 and -2)
    always flush branch type predictions by default.
    
    Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b35087763a44d1eb45857f799579a351332be505
Author: Borislav Petkov (AMD) <bp@alien8.de>
Date:   Wed Jun 28 11:02:39 2023 +0200

    x86/srso: Add a Speculative RAS Overflow mitigation
    
    Upstream commit: fb3bd914b3ec28f5fb697ac55c4846ac2d542855
    
    Add a mitigation for the speculative return address stack overflow
    vulnerability found on AMD processors.
    
    The mitigation works by ensuring all RET instructions speculate to
    a controlled location, similar to how speculation is controlled in the
    retpoline sequence.  To accomplish this, the __x86_return_thunk forces
    the CPU to mispredict every function return using a 'safe return'
    sequence.
    
    To ensure the safety of this mitigation, the kernel must ensure that the
    safe return sequence is itself free from attacker interference.  In Zen3
    and Zen4, this is accomplished by creating a BTB alias between the
    untraining function srso_untrain_ret_alias() and the safe return
    function srso_safe_ret_alias() which results in evicting a potentially
    poisoned BTB entry and using that safe one for all function returns.
    
    In older Zen1 and Zen2, this is accomplished using a reinterpretation
    technique similar to Retbleed one: srso_untrain_ret() and
    srso_safe_ret().
    
    Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c3b4c644525e1ffa291794dce5567ae2ca9c9d37
Author: Kim Phillips <kim.phillips@amd.com>
Date:   Tue Jan 10 16:46:37 2023 -0600

    x86/cpu, kvm: Add support for CPUID_80000021_EAX
    
    commit 8415a74852d7c24795007ee9862d25feb519007c upstream.
    
    Add support for CPUID leaf 80000021, EAX. The majority of the features will be
    used in the kernel and thus a separate leaf is appropriate.
    
    Include KVM's reverse_cpuid entry because features are used by VM guests, too.
    
      [ bp: Massage commit message. ]
    
    Signed-off-by: Kim Phillips <kim.phillips@amd.com>
    Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
    Acked-by: Sean Christopherson <seanjc@google.com>
    Link: https://lore.kernel.org/r/20230124163319.2277355-2-kim.phillips@amd.com
    [bwh: Backported to 6.1: adjust context]
    Signed-off-by: Ben Hutchings <benh@debian.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 236dd7133394bfe30275191e3aefcc6b3b09962b
Author: Borislav Petkov (AMD) <bp@alien8.de>
Date:   Sat Jul 8 10:21:35 2023 +0200

    x86/bugs: Increase the x86 bugs vector size to two u32s
    
    Upstream commit: 0e52740ffd10c6c316837c6c128f460f1aaba1ea
    
    There was never a doubt in my mind that they would not fit into a single
    u32 eventually.
    
    Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0242a8bdef560523b5d81f5979854266092ab0a6
Author: Dave Hansen <dave.hansen@linux.intel.com>
Date:   Tue Aug 1 07:31:07 2023 -0700

    Documentation/x86: Fix backwards on/off logic about YMM support
    
    commit 1b0fc0345f2852ffe54fb9ae0e12e2ee69ad6a20 upstream
    
    These options clearly turn *off* XSAVE YMM support.  Correct the
    typo.
    
    Reported-by: Ben Hutchings <ben@decadent.org.uk>
    Fixes: 553a5c03e90a ("x86/speculation: Add force option to GDS mitigation")
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 27a72e350869d5b06cc44d882cd34fb0f88f3f8b
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 25 21:38:25 2022 +0200

    x86/mm: Initialize text poking earlier
    
    commit 5b93a83649c7cba3a15eb7e8959b250841acb1b1 upstream.
    
    Move poking_init() up a bunch; specifically move it right after
    mm_init() which is right before ftrace_init().
    
    This will allow simplifying ftrace text poking which currently has
    a bunch of exceptions for early boot.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20221025201057.881703081@infradead.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d0317b9502ea8a8f66cd568e90f19b595b5d4a07
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 25 21:38:18 2022 +0200

    mm: Move mm_cachep initialization to mm_init()
    
    commit af80602799681c78f14fbe20b6185a56020dedee upstream.
    
    In order to allow using mm_alloc() much earlier, move initializing
    mm_cachep into mm_init().
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20221025201057.751153381@infradead.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8e4c2530879d7ac1eecc1815b1e34e597c7d4f22
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 25 21:38:21 2022 +0200

    x86/mm: Use mm_alloc() in poking_init()
    
    commit 3f4c8211d982099be693be9aa7d6fc4607dff290 upstream.
    
    Instead of duplicating init_mm, allocate a fresh mm. The advantage is
    that mm_alloc() has much simpler dependencies. Additionally it makes
    more conceptual sense, init_mm has no (and must not have) user state
    to duplicate.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20221025201057.816175235@infradead.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 13ec5cb4c113d9159b5138d45f588f40ba66ca56
Author: Juergen Gross <jgross@suse.com>
Date:   Mon Jan 9 16:09:22 2023 +0100

    x86/mm: fix poking_init() for Xen PV guests
    
    commit 26ce6ec364f18d2915923bc05784084e54a5c4cc upstream.
    
    Commit 3f4c8211d982 ("x86/mm: Use mm_alloc() in poking_init()") broke
    the kernel for running as Xen PV guest.
    
    It seems as if the new address space is never activated before being
    used, resulting in Xen rejecting to accept the new CR3 value (the PGD
    isn't pinned).
    
    Fix that by adding the now missing call of paravirt_arch_dup_mmap() to
    poking_init(). That call was previously done by dup_mm()->dup_mmap() and
    it is a NOP for all cases but for Xen PV, where it is just doing the
    pinning of the PGD.
    
    Fixes: 3f4c8211d982 ("x86/mm: Use mm_alloc() in poking_init()")
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20230109150922.10578-1-jgross@suse.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3e90080d56652be6cc9e5355ea65f569bf005fba
Author: Juergen Gross <jgross@suse.com>
Date:   Mon Jul 3 15:00:32 2023 +0200

    x86/xen: Fix secondary processors' FPU initialization
    
    commit fe3e0a13e597c1c8617814bf9b42ab732db5c26e upstream.
    
    Moving the call of fpu__init_cpu() from cpu_init() to start_secondary()
    broke Xen PV guests, as those don't call start_secondary() for APs.
    
    Call fpu__init_cpu() in Xen's cpu_bringup(), which is the Xen PV
    replacement of start_secondary().
    
    Fixes: b81fac906a8f ("x86/fpu: Move FPU initialization into arch_cpu_finalize_init()")
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Acked-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230703130032.22916-1-jgross@suse.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 348741a9e4d37d83024b45acce9b65233127f8b2
Author: Daniel Sneddon <daniel.sneddon@linux.intel.com>
Date:   Tue Aug 1 18:58:31 2023 +0200

    KVM: Add GDS_NO support to KVM
    
    commit 81ac7e5d741742d650b4ed6186c4826c1a0631a7 upstream
    
    Gather Data Sampling (GDS) is a transient execution attack using
    gather instructions from the AVX2 and AVX512 extensions. This attack
    allows malicious code to infer data that was previously stored in
    vector registers. Systems that are not vulnerable to GDS will set the
    GDS_NO bit of the IA32_ARCH_CAPABILITIES MSR. This is useful for VM
    guests that may think they are on vulnerable systems that are, in
    fact, not affected. Guests that are running on affected hosts where
    the mitigation is enabled are protected as if they were running
    on an unaffected system.
    
    On all hosts that are not affected or that are mitigated, set the
    GDS_NO bit.
    
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Acked-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 59d78655f808eb82a103f0fb79df9aa20ee2c7c1
Author: Daniel Sneddon <daniel.sneddon@linux.intel.com>
Date:   Tue Aug 1 18:58:31 2023 +0200

    x86/speculation: Add Kconfig option for GDS
    
    commit 53cf5797f114ba2bd86d23a862302119848eff19 upstream
    
    Gather Data Sampling (GDS) is mitigated in microcode. However, on
    systems that haven't received the updated microcode, disabling AVX
    can act as a mitigation. Add a Kconfig option that uses the microcode
    mitigation if available and disables AVX otherwise. Setting this
    option has no effect on systems not affected by GDS. This is the
    equivalent of setting gather_data_sampling=force.
    
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Acked-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0cc5643b63aef90165488dabaeff92697925baa6
Author: Daniel Sneddon <daniel.sneddon@linux.intel.com>
Date:   Tue Aug 1 18:58:31 2023 +0200

    x86/speculation: Add force option to GDS mitigation
    
    commit 553a5c03e90a6087e88f8ff878335ef0621536fb upstream
    
    The Gather Data Sampling (GDS) vulnerability allows malicious software
    to infer stale data previously stored in vector registers. This may
    include sensitive data such as cryptographic keys. GDS is mitigated in
    microcode, and systems with up-to-date microcode are protected by
    default. However, any affected system that is running with older
    microcode will still be vulnerable to GDS attacks.
    
    Since the gather instructions used by the attacker are part of the
    AVX2 and AVX512 extensions, disabling these extensions prevents gather
    instructions from being executed, thereby mitigating the system from
    GDS. Disabling AVX2 is sufficient, but we don't have the granularity
    to do this. The XCR0[2] disables AVX, with no option to just disable
    AVX2.
    
    Add a kernel parameter gather_data_sampling=force that will enable the
    microcode mitigation if available, otherwise it will disable AVX on
    affected systems.
    
    This option will be ignored if cmdline mitigations=off.
    
    This is a *big* hammer.  It is known to break buggy userspace that
    uses incomplete, buggy AVX enumeration.  Unfortunately, such userspace
    does exist in the wild:
    
            https://www.mail-archive.com/bug-coreutils@gnu.org/msg33046.html
    
    [ dhansen: add some more ominous warnings about disabling AVX ]
    
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Acked-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 348a89e2018428c3e55a87cdd9ae3cbd6cc8248a
Author: Daniel Sneddon <daniel.sneddon@linux.intel.com>
Date:   Tue Aug 1 18:58:31 2023 +0200

    x86/speculation: Add Gather Data Sampling mitigation
    
    commit 8974eb588283b7d44a7c91fa09fcbaf380339f3a upstream
    
    Gather Data Sampling (GDS) is a hardware vulnerability which allows
    unprivileged speculative access to data which was previously stored in
    vector registers.
    
    Intel processors that support AVX2 and AVX512 have gather instructions
    that fetch non-contiguous data elements from memory. On vulnerable
    hardware, when a gather instruction is transiently executed and
    encounters a fault, stale data from architectural or internal vector
    registers may get transiently stored to the destination vector
    register allowing an attacker to infer the stale data using typical
    side channel techniques like cache timing attacks.
    
    This mitigation is different from many earlier ones for two reasons.
    First, it is enabled by default and a bit must be set to *DISABLE* it.
    This is the opposite of normal mitigation polarity. This means GDS can
    be mitigated simply by updating microcode and leaving the new control
    bit alone.
    
    Second, GDS has a "lock" bit. This lock bit is there because the
    mitigation affects the hardware security features KeyLocker and SGX.
    It needs to be enabled and *STAY* enabled for these features to be
    mitigated against GDS.
    
    The mitigation is enabled in the microcode by default. Disable it by
    setting gather_data_sampling=off or by disabling all mitigations with
    mitigations=off. The mitigation status can be checked by reading:
    
        /sys/devices/system/cpu/vulnerabilities/gather_data_sampling
    
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Dave Hansen <dave.hansen@linux.intel.com>
    Acked-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a094d3b309670961ed2432389c1193ed5ab2e564
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    x86/fpu: Move FPU initialization into arch_cpu_finalize_init()
    
    commit b81fac906a8f9e682e513ddd95697ec7a20878d4 upstream
    
    Initializing the FPU during the early boot process is a pointless
    exercise. Early boot is convoluted and fragile enough.
    
    Nothing requires that the FPU is set up early. It has to be initialized
    before fork_init() because the task_struct size depends on the FPU register
    buffer size.
    
    Move the initialization to arch_cpu_finalize_init() which is the perfect
    place to do so.
    
    No functional change.
    
    This allows to remove quite some of the custom early command line parsing,
    but that's subject to the next installment.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230613224545.902376621@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 59f2739111cad3c322870185c91ca42f31d66ee1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    x86/fpu: Mark init functions __init
    
    commit 1703db2b90c91b2eb2d699519fc505fe431dde0e upstream
    
    No point in keeping them around.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230613224545.841685728@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bb9c20d903f6f9d4bca812220ac8b2348aa6c1b6
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    x86/fpu: Remove cpuinfo argument from init functions
    
    commit 1f34bb2a24643e0087652d81078e4f616562738d upstream
    
    Nothing in the call chain requires it
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230613224545.783704297@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit de8b7ce4c533f808105ae60e95d777a99eca2091
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    x86/init: Initialize signal frame size late
    
    commit 54d9a91a3d6713d1332e93be13b4eaf0fa54349d upstream
    
    No point in doing this during really early boot. Move it to an early
    initcall so that it is set up before possible user mode helpers are started
    during device initialization.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230613224545.727330699@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 041d929233bb2cadee3116742f400ac7004c8569
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    init, x86: Move mem_encrypt_init() into arch_cpu_finalize_init()
    
    commit 439e17576eb47f26b78c5bbc72e344d4206d2327 upstream
    
    Invoke the X86ism mem_encrypt_init() from X86 arch_cpu_finalize_init() and
    remove the weak fallback from the core code.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230613224545.670360645@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8ae795ed611538828858aaf98fe186ee7f6d5295
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    init: Invoke arch_cpu_finalize_init() earlier
    
    commit 9df9d2f0471b4c4702670380b8d8a45b40b23a7d upstream
    
    X86 is reworking the boot process so that initializations which are not
    required during early boot can be moved into the late boot process and out
    of the fragile and restricted initial boot phase.
    
    arch_cpu_finalize_init() is the obvious place to do such initializations,
    but arch_cpu_finalize_init() is invoked too late in start_kernel() e.g. for
    initializing the FPU completely. fork_init() requires that the FPU is
    initialized as the size of task_struct on X86 depends on the size of the
    required FPU register buffer.
    
    Fortunately none of the init calls between calibrate_delay() and
    arch_cpu_finalize_init() is relevant for the functionality of
    arch_cpu_finalize_init().
    
    Invoke it right after calibrate_delay() where everything which is relevant
    for arch_cpu_finalize_init() has been set up already.
    
    No functional change intended.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Rick Edgecombe <rick.p.edgecombe@intel.com>
    Link: https://lore.kernel.org/r/20230613224545.612182854@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7e270cebaffd12337e5851b0bb36a347d04ca528
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    init: Remove check_bugs() leftovers
    
    commit 61235b24b9cb37c13fcad5b9596d59a1afdcec30 upstream
    
    Everything is converted over to arch_cpu_finalize_init(). Remove the
    check_bugs() leftovers including the empty stubs in asm-generic, alpha,
    parisc, powerpc and xtensa.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Richard Henderson <richard.henderson@linaro.org>
    Link: https://lore.kernel.org/r/20230613224545.553215951@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 285384ac24c38d775e7b0271c67f67165258f16a
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    um/cpu: Switch to arch_cpu_finalize_init()
    
    commit 9349b5cd0908f8afe95529fc7a8cbb1417df9b0c upstream
    
    check_bugs() is about to be phased out. Switch over to the new
    arch_cpu_finalize_init() implementation.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Richard Weinberger <richard@nod.at>
    Link: https://lore.kernel.org/r/20230613224545.493148694@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6ea42178642654385e5394928fe5f69797e011c4
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    sparc/cpu: Switch to arch_cpu_finalize_init()
    
    commit 44ade508e3bfac45ae97864587de29eb1a881ec0 upstream
    
    check_bugs() is about to be phased out. Switch over to the new
    arch_cpu_finalize_init() implementation.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Sam Ravnborg <sam@ravnborg.org>
    Link: https://lore.kernel.org/r/20230613224545.431995857@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 21a1fc8d13d8f4cda5211fab491f7c07ad02be16
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    sh/cpu: Switch to arch_cpu_finalize_init()
    
    commit 01eb454e9bfe593f320ecbc9aaec60bf87cd453d upstream
    
    check_bugs() is about to be phased out. Switch over to the new
    arch_cpu_finalize_init() implementation.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230613224545.371697797@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dfeb371a2707c0a70dcf2058ce436f81ab7babb3
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    mips/cpu: Switch to arch_cpu_finalize_init()
    
    commit 7f066a22fe353a827a402ee2835e81f045b1574d upstream
    
    check_bugs() is about to be phased out. Switch over to the new
    arch_cpu_finalize_init() implementation.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230613224545.312438573@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4baf46a3ba00be6bff6d680544211eee5827ee76
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    m68k/cpu: Switch to arch_cpu_finalize_init()
    
    commit 9ceecc2589b9d7cef6b321339ed8de484eac4b20 upstream
    
    check_bugs() is about to be phased out. Switch over to the new
    arch_cpu_finalize_init() implementation.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Acked-by: Geert Uytterhoeven <geert@linux-m68k.org>
    Link: https://lore.kernel.org/r/20230613224545.254342916@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8c8165cd25cfd86e0aa1126fb89e47f53f29f02f
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    ia64/cpu: Switch to arch_cpu_finalize_init()
    
    commit 6c38e3005621800263f117fb00d6787a76e16de7 upstream
    
    check_bugs() is about to be phased out. Switch over to the new
    arch_cpu_finalize_init() implementation.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230613224545.137045745@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit de8c592cc5a1fa76b35d48916c4d372d4b4d3729
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    ARM: cpu: Switch to arch_cpu_finalize_init()
    
    commit ee31bb0524a2e7c99b03f50249a411cc1eaa411f upstream
    
    check_bugs() is about to be phased out. Switch over to the new
    arch_cpu_finalize_init() implementation.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230613224545.078124882@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 75da6209d3ba7a75d18fd4614198630f3c4dfab1
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    x86/cpu: Switch to arch_cpu_finalize_init()
    
    commit 7c7077a72674402654f3291354720cd73cdf649e upstream
    
    check_bugs() is a dumping ground for finalizing the CPU bringup. Only parts of
    it has to do with actual CPU bugs.
    
    Split it apart into arch_cpu_finalize_init() and cpu_select_mitigations().
    
    Fixup the bogus 32bit comments while at it.
    
    No functional change.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Reviewed-by: Borislav Petkov (AMD) <bp@alien8.de>
    Link: https://lore.kernel.org/r/20230613224545.019583869@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0774fc2177c3a0576d9d06c5dd507be8efc686ac
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Aug 1 18:58:30 2023 +0200

    init: Provide arch_cpu_finalize_init()
    
    commit 7725acaa4f0c04fbefb0e0d342635b967bb7d414 upstream
    
    check_bugs() has become a dumping ground for all sorts of activities to
    finalize the CPU initialization before running the rest of the init code.
    
    Most are empty, a few do actual bug checks, some do alternative patching
    and some cobble a CPU advertisement string together....
    
    Aside of that the current implementation requires duplicated function
    declaration and mostly empty header files for them.
    
    Provide a new function arch_cpu_finalize_init(). Provide a generic
    declaration if CONFIG_ARCH_HAS_CPU_FINALIZE_INIT is selected and a stub
    inline otherwise.
    
    This requires a temporary #ifdef in start_kernel() which will be removed
    along with check_bugs() once the architectures are converted over.
    
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Link: https://lore.kernel.org/r/20230613224544.957805717@linutronix.de
    Signed-off-by: Daniel Sneddon <daniel.sneddon@linux.intel.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
