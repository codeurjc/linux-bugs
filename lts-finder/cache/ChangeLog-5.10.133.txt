commit 5034934536433b2831c80134f1531bbdbc2de160
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Mon Jul 25 11:26:57 2022 +0200

    Linux 5.10.133
    
    Link: https://lore.kernel.org/r/20220723095224.302504400@linuxfoundation.org
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Tested-by: Linux Kernel Functional Testing <lkft@linaro.org>
    Tested-by: Rudi Heitbaum <rudi@heitbaum.com>
    Tested-by: Sudip Mukherjee <sudip.mukherjee@codethink.co.uk>
    Tested-by: Jon Hunter <jonathanh@nvidia.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2fc7f18ba2f98d15f174ce8e25a5afa46926eb55
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Wed Jul 14 14:28:02 2021 -0300

    tools headers: Remove broken definition of __LITTLE_ENDIAN
    
    commit fa2c02e5798c17c89cbb3135940086ebe07e5c9f upstream.
    
    The linux/kconfig.h file was copied from the kernel but the line where
    with the generated/autoconf.h include from where the CONFIG_ entries
    would come from was deleted, as tools/ build system don't create that
    file, so we ended up always defining just __LITTLE_ENDIAN as
    CONFIG_CPU_BIG_ENDIAN was nowhere to be found.
    
    This in turn ended up breaking the build in some systems where
    __LITTLE_ENDIAN was already defined, such as the androind NDK.
    
    So just ditch that block that depends on the CONFIG_CPU_BIG_ENDIAN
    define.
    
    The kconfig.h file was copied just to get IS_ENABLED() and a
    'make -C tools/all' doesn't breaks with this removal.
    
    Fixes: 93281c4a96572a34 ("x86/insn: Add an insn_decode() API")
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Link: http://lore.kernel.org/lkml/YO8hK7lqJcIWuBzx@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 060e39b8c21ceeca3eeaaca5f97dcd8530d85b67
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun May 9 10:19:37 2021 -0300

    tools arch: Update arch/x86/lib/mem{cpy,set}_64.S copies used in 'perf bench mem memcpy' - again
    
    commit fb24e308b6310541e70d11a3f19dc40742974b95 upstream.
    
    To bring in the change made in this cset:
    
     5e21a3ecad1500e3 ("x86/alternative: Merge include files")
    
    This just silences these perf tools build warnings, no change in the tools:
    
      Warning: Kernel ABI header at 'tools/arch/x86/lib/memcpy_64.S' differs from latest version at 'arch/x86/lib/memcpy_64.S'
      diff -u tools/arch/x86/lib/memcpy_64.S arch/x86/lib/memcpy_64.S
      Warning: Kernel ABI header at 'tools/arch/x86/lib/memset_64.S' differs from latest version at 'arch/x86/lib/memset_64.S'
      diff -u tools/arch/x86/lib/memset_64.S arch/x86/lib/memset_64.S
    
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Juergen Gross <jgross@suse.com>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fbf60f83e241f0ef967644ca06455f37fcea064b
Author: Vasily Gorbik <gor@linux.ibm.com>
Date:   Wed May 12 19:42:10 2021 +0200

    objtool: Fix elf_create_undef_symbol() endianness
    
    commit 46c7405df7de8deb97229eacebcee96d61415f3f upstream.
    
    Currently x86 cross-compilation fails on big endian system with:
    
      x86_64-cross-ld: init/main.o: invalid string offset 488112128 >= 6229 for section `.strtab'
    
    Mark new ELF data in elf_create_undef_symbol() as symbol, so that libelf
    does endianness handling correctly.
    
    Fixes: 2f2f7e47f052 ("objtool: Add elf_create_undef_symbol()")
    Signed-off-by: Vasily Gorbik <gor@linux.ibm.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Acked-by: Peter Zijlstra <a.p.zijlstra@chello.nl>
    Link: https://lore.kernel.org/r/patch-1.thread-6c9df9.git-d39264656387.your-ad-here.call-01620841104-ext-2554@work.hours
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 39065d54347fe1395371ad5397df353ef77c8989
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Oct 3 13:34:19 2021 -0700

    kvm: fix objtool relocation warning
    
    commit 291073a566b2094c7192872cc0f17ce73d83cb76 upstream.
    
    The recent change to make objtool aware of more symbol relocation types
    (commit 24ff65257375: "objtool: Teach get_alt_entry() about more
    relocation types") also added another check, and resulted in this
    objtool warning when building kvm on x86:
    
        arch/x86/kvm/emulate.o: warning: objtool: __ex_table+0x4: don't know how to handle reloc symbol type: kvm_fastop_exception
    
    The reason seems to be that kvm_fastop_exception() is marked as a global
    symbol, which causes the relocation to ke kept around for objtool.  And
    at the same time, the kvm_fastop_exception definition (which is done as
    an inline asm statement) doesn't actually set the type of the global,
    which then makes objtool unhappy.
    
    The minimal fix is to just not mark kvm_fastop_exception as being a
    global symbol.  It's only used in that one compilation unit anyway, so
    it was always pointless.  That's how all the other local exception table
    labels are done.
    
    I'm not entirely happy about the kinds of games that the kvm code plays
    with doing its own exception handling, and the fact that it confused
    objtool is most definitely a symptom of the code being a bit too subtle
    and ad-hoc.  But at least this trivial one-liner makes objtool no longer
    upset about what is going on.
    
    Fixes: 24ff65257375 ("objtool: Teach get_alt_entry() about more relocation types")
    Link: https://lore.kernel.org/lkml/CAHk-=wiZwq-0LknKhXN4M+T8jbxn_2i9mcKpO+OaBSSq_Eh7tg@mail.gmail.com/
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Sean Christopherson <seanjc@google.com>
    Cc: Vitaly Kuznetsov <vkuznets@redhat.com>
    Cc: Wanpeng Li <wanpengli@tencent.com>
    Cc: Jim Mattson <jmattson@google.com>
    Cc: Joerg Roedel <joro@8bytes.org>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: Josh Poimboeuf <jpoimboe@redhat.com>
    Cc: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6849ed81a33ae616bfadf40e5c68af265d106dff
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Nov 19 17:50:25 2021 +0100

    x86: Use -mindirect-branch-cs-prefix for RETPOLINE builds
    
    commit 68cf4f2a72ef8786e6b7af6fd9a89f27ac0f520d upstream.
    
    In order to further enable commit:
    
      bbe2df3f6b6d ("x86/alternative: Try inline spectre_v2=retpoline,amd")
    
    add the new GCC flag -mindirect-branch-cs-prefix:
    
      https://gcc.gnu.org/g:2196a681d7810ad8b227bf983f38ba716620545e
      https://gcc.gnu.org/bugzilla/show_bug.cgi?id=102952
      https://bugs.llvm.org/show_bug.cgi?id=52323
    
    to RETPOLINE=y builds. This should allow fully inlining retpoline,amd
    for GCC builds.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Kees Cook <keescook@chromium.org>
    Acked-by: Nick Desaulniers <ndesaulniers@google.com>
    Link: https://lkml.kernel.org/r/20211119165630.276205624@infradead.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8e2774270aa319f552fab969bc4500e412d2566b
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Jul 14 12:20:19 2022 +0200

    um: Add missing apply_returns()
    
    commit 564d998106397394b6aad260f219b882b3347e62 upstream.
    
    Implement apply_returns() stub for UM, just like all the other patching
    routines.
    
    Fixes: 15e67227c49a ("x86: Undo return-thunk damage")
    Reported-by: Randy Dunlap <rdunlap@infradead.org)
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/Ys%2Ft45l%2FgarIrD0u@worktop.programming.kicks-ass.net
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 725da3e67cec529788e284dac2c1249b2a531839
Author: Kim Phillips <kim.phillips@amd.com>
Date:   Fri Jul 8 16:21:28 2022 -0500

    x86/bugs: Remove apostrophe typo
    
    commit bcf163150cd37348a0cb59e95c916a83a9344b0e upstream.
    
    Remove a superfluous ' in the mitigation string.
    
    Fixes: e8ec1b6e08a2 ("x86/bugs: Enable STIBP for JMP2RET")
    Signed-off-by: Kim Phillips <kim.phillips@amd.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 81604506c26aef661bc460609981e01b706cf025
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Jul 1 13:39:15 2021 -0300

    tools headers cpufeatures: Sync with the kernel sources
    
    commit f098addbdb44c8a565367f5162f3ab170ed9404a upstream.
    
    To pick the changes from:
    
      f43b9876e857c739 ("x86/retbleed: Add fine grained Kconfig knobs")
      a149180fbcf336e9 ("x86: Add magic AMD return-thunk")
      15e67227c49a5783 ("x86: Undo return-thunk damage")
      369ae6ffc41a3c11 ("x86/retpoline: Cleanup some #ifdefery")
      4ad3278df6fe2b08 x86/speculation: Disable RRSBA behavior
      26aae8ccbc197223 x86/cpu/amd: Enumerate BTC_NO
      9756bba28470722d x86/speculation: Fill RSB on vmexit for IBRS
      3ebc170068885b6f x86/bugs: Add retbleed=ibpb
      2dbb887e875b1de3 x86/entry: Add kernel IBRS implementation
      6b80b59b35557065 x86/bugs: Report AMD retbleed vulnerability
      a149180fbcf336e9 x86: Add magic AMD return-thunk
      15e67227c49a5783 x86: Undo return-thunk damage
      a883d624aed463c8 x86/cpufeatures: Move RETPOLINE flags to word 11
      51802186158c74a0 x86/speculation/mmio: Enumerate Processor MMIO Stale Data bug
    
    This only causes these perf files to be rebuilt:
    
      CC       /tmp/build/perf/bench/mem-memcpy-x86-64-asm.o
      CC       /tmp/build/perf/bench/mem-memset-x86-64-asm.o
    
    And addresses this perf build warning:
    
      Warning: Kernel ABI header at 'tools/arch/x86/include/asm/cpufeatures.h' differs from latest version at 'arch/x86/include/asm/cpufeatures.h'
      diff -u tools/arch/x86/include/asm/cpufeatures.h arch/x86/include/asm/cpufeatures.h
      Warning: Kernel ABI header at 'tools/arch/x86/include/asm/disabled-features.h' differs from latest version at 'arch/x86/include/asm/disabled-features.h'
      diff -u tools/arch/x86/include/asm/disabled-features.h arch/x86/include/asm/disabled-features.h
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Ian Rogers <irogers@google.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Peter Zijlstra <peterz@infradead.org
    Link: https://lore.kernel.org/lkml/YtQM40VmiLTkPND2@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3f93b8630a91e9195607312b7f16a25417f61f7b
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Thu Jul 1 13:32:18 2021 -0300

    tools arch x86: Sync the msr-index.h copy with the kernel sources
    
    commit 91d248c3b903b46a58cbc7e8d38d684d3e4007c2 upstream.
    
    To pick up the changes from these csets:
    
      4ad3278df6fe2b08 ("x86/speculation: Disable RRSBA behavior")
      d7caac991feeef1b ("x86/cpu/amd: Add Spectral Chicken")
    
    That cause no changes to tooling:
    
      $ tools/perf/trace/beauty/tracepoints/x86_msr.sh > before
      $ cp arch/x86/include/asm/msr-index.h tools/arch/x86/include/asm/msr-index.h
      $ tools/perf/trace/beauty/tracepoints/x86_msr.sh > after
      $ diff -u before after
      $
    
    Just silences this perf build warning:
    
      Warning: Kernel ABI header at 'tools/arch/x86/include/asm/msr-index.h' differs from latest version at 'arch/x86/include/asm/msr-index.h'
      diff -u tools/arch/x86/include/asm/msr-index.h arch/x86/include/asm/msr-index.h
    
    Cc: Adrian Hunter <adrian.hunter@intel.com>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Ian Rogers <irogers@google.com>
    Cc: Jiri Olsa <jolsa@kernel.org>
    Cc: Namhyung Kim <namhyung@kernel.org>
    Cc: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Link: https://lore.kernel.org/lkml/YtQTm9wsB3hxQWvy@kernel.org
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 2ef1b06ceacfc6f96f6792126e107e75c0d7bd5d
Author: Paolo Bonzini <pbonzini@redhat.com>
Date:   Fri Jul 15 07:34:55 2022 -0400

    KVM: emulate: do not adjust size of fastop and setcc subroutines
    
    commit 79629181607e801c0b41b8790ac4ee2eb5d7bc3e upstream.
    
    Instead of doing complicated calculations to find the size of the subroutines
    (which are even more complicated because they need to be stringified into
    an asm statement), just hardcode to 16.
    
    It is less dense for a few combinations of IBT/SLS/retbleed, but it has
    the advantage of being really simple.
    
    Cc: stable@vger.kernel.org # 5.15.x: 84e7051c0bc1: x86/kvm: fix FASTOP_SIZE when return thunks are enabled
    Cc: stable@vger.kernel.org
    Suggested-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8e31dfd6306e7c6bb3758a459c2a6067be807886
Author: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
Date:   Wed Jul 13 14:12:41 2022 -0300

    x86/kvm: fix FASTOP_SIZE when return thunks are enabled
    
    commit 84e7051c0bc1f2a13101553959b3a9d9a8e24939 upstream.
    
    The return thunk call makes the fastop functions larger, just like IBT
    does. Consider a 16-byte FASTOP_SIZE when CONFIG_RETHUNK is enabled.
    
    Otherwise, functions will be incorrectly aligned and when computing their
    position for differently sized operators, they will executed in the middle
    or end of a function, which may as well be an int3, leading to a crash
    like:
    
    [   36.091116] int3: 0000 [#1] SMP NOPTI
    [   36.091119] CPU: 3 PID: 1371 Comm: qemu-system-x86 Not tainted 5.15.0-41-generic #44
    [   36.091120] Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 1.15.0-1 04/01/2014
    [   36.091121] RIP: 0010:xaddw_ax_dx+0x9/0x10 [kvm]
    [   36.091185] Code: 00 0f bb d0 c3 cc cc cc cc 48 0f bb d0 c3 cc cc cc cc 0f 1f 80 00 00 00 00 0f c0 d0 c3 cc cc cc cc 66 0f c1 d0 c3 cc cc cc cc <0f> 1f 80 00 00 00 00 0f c1 d0 c3 cc cc cc cc 48 0f c1 d0 c3 cc cc
    [   36.091186] RSP: 0018:ffffb1f541143c98 EFLAGS: 00000202
    [   36.091188] RAX: 0000000089abcdef RBX: 0000000000000001 RCX: 0000000000000000
    [   36.091188] RDX: 0000000076543210 RSI: ffffffffc073c6d0 RDI: 0000000000000200
    [   36.091189] RBP: ffffb1f541143ca0 R08: ffff9f1803350a70 R09: 0000000000000002
    [   36.091190] R10: ffff9f1803350a70 R11: 0000000000000000 R12: ffff9f1803350a70
    [   36.091190] R13: ffffffffc077fee0 R14: 0000000000000000 R15: 0000000000000000
    [   36.091191] FS:  00007efdfce8d640(0000) GS:ffff9f187dd80000(0000) knlGS:0000000000000000
    [   36.091192] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [   36.091192] CR2: 0000000000000000 CR3: 0000000009b62002 CR4: 0000000000772ee0
    [   36.091195] PKRU: 55555554
    [   36.091195] Call Trace:
    [   36.091197]  <TASK>
    [   36.091198]  ? fastop+0x5a/0xa0 [kvm]
    [   36.091222]  x86_emulate_insn+0x7b8/0xe90 [kvm]
    [   36.091244]  x86_emulate_instruction+0x2f4/0x630 [kvm]
    [   36.091263]  ? kvm_arch_vcpu_load+0x7c/0x230 [kvm]
    [   36.091283]  ? vmx_prepare_switch_to_host+0xf7/0x190 [kvm_intel]
    [   36.091290]  complete_emulated_mmio+0x297/0x320 [kvm]
    [   36.091310]  kvm_arch_vcpu_ioctl_run+0x32f/0x550 [kvm]
    [   36.091330]  kvm_vcpu_ioctl+0x29e/0x6d0 [kvm]
    [   36.091344]  ? kvm_vcpu_ioctl+0x120/0x6d0 [kvm]
    [   36.091357]  ? __fget_files+0x86/0xc0
    [   36.091362]  ? __fget_files+0x86/0xc0
    [   36.091363]  __x64_sys_ioctl+0x92/0xd0
    [   36.091366]  do_syscall_64+0x59/0xc0
    [   36.091369]  ? syscall_exit_to_user_mode+0x27/0x50
    [   36.091370]  ? do_syscall_64+0x69/0xc0
    [   36.091371]  ? syscall_exit_to_user_mode+0x27/0x50
    [   36.091372]  ? __x64_sys_writev+0x1c/0x30
    [   36.091374]  ? do_syscall_64+0x69/0xc0
    [   36.091374]  ? exit_to_user_mode_prepare+0x37/0xb0
    [   36.091378]  ? syscall_exit_to_user_mode+0x27/0x50
    [   36.091379]  ? do_syscall_64+0x69/0xc0
    [   36.091379]  ? do_syscall_64+0x69/0xc0
    [   36.091380]  ? do_syscall_64+0x69/0xc0
    [   36.091381]  ? do_syscall_64+0x69/0xc0
    [   36.091381]  entry_SYSCALL_64_after_hwframe+0x61/0xcb
    [   36.091384] RIP: 0033:0x7efdfe6d1aff
    [   36.091390] Code: 00 48 89 44 24 18 31 c0 48 8d 44 24 60 c7 04 24 10 00 00 00 48 89 44 24 08 48 8d 44 24 20 48 89 44 24 10 b8 10 00 00 00 0f 05 <41> 89 c0 3d 00 f0 ff ff 77 1f 48 8b 44 24 18 64 48 2b 04 25 28 00
    [   36.091391] RSP: 002b:00007efdfce8c460 EFLAGS: 00000246 ORIG_RAX: 0000000000000010
    [   36.091393] RAX: ffffffffffffffda RBX: 000000000000ae80 RCX: 00007efdfe6d1aff
    [   36.091393] RDX: 0000000000000000 RSI: 000000000000ae80 RDI: 000000000000000c
    [   36.091394] RBP: 0000558f1609e220 R08: 0000558f13fb8190 R09: 00000000ffffffff
    [   36.091394] R10: 0000558f16b5e950 R11: 0000000000000246 R12: 0000000000000000
    [   36.091394] R13: 0000000000000001 R14: 0000000000000000 R15: 0000000000000000
    [   36.091396]  </TASK>
    [   36.091397] Modules linked in: isofs nls_iso8859_1 kvm_intel joydev kvm input_leds serio_raw sch_fq_codel dm_multipath scsi_dh_rdac scsi_dh_emc scsi_dh_alua ipmi_devintf ipmi_msghandler drm msr ip_tables x_tables autofs4 btrfs blake2b_generic zstd_compress raid10 raid456 async_raid6_recov async_memcpy async_pq async_xor async_tx xor raid6_pq libcrc32c raid1 raid0 multipath linear crct10dif_pclmul crc32_pclmul ghash_clmulni_intel aesni_intel virtio_net net_failover crypto_simd ahci xhci_pci cryptd psmouse virtio_blk libahci xhci_pci_renesas failover
    [   36.123271] ---[ end trace db3c0ab5a48fabcc ]---
    [   36.123272] RIP: 0010:xaddw_ax_dx+0x9/0x10 [kvm]
    [   36.123319] Code: 00 0f bb d0 c3 cc cc cc cc 48 0f bb d0 c3 cc cc cc cc 0f 1f 80 00 00 00 00 0f c0 d0 c3 cc cc cc cc 66 0f c1 d0 c3 cc cc cc cc <0f> 1f 80 00 00 00 00 0f c1 d0 c3 cc cc cc cc 48 0f c1 d0 c3 cc cc
    [   36.123320] RSP: 0018:ffffb1f541143c98 EFLAGS: 00000202
    [   36.123321] RAX: 0000000089abcdef RBX: 0000000000000001 RCX: 0000000000000000
    [   36.123321] RDX: 0000000076543210 RSI: ffffffffc073c6d0 RDI: 0000000000000200
    [   36.123322] RBP: ffffb1f541143ca0 R08: ffff9f1803350a70 R09: 0000000000000002
    [   36.123322] R10: ffff9f1803350a70 R11: 0000000000000000 R12: ffff9f1803350a70
    [   36.123323] R13: ffffffffc077fee0 R14: 0000000000000000 R15: 0000000000000000
    [   36.123323] FS:  00007efdfce8d640(0000) GS:ffff9f187dd80000(0000) knlGS:0000000000000000
    [   36.123324] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
    [   36.123325] CR2: 0000000000000000 CR3: 0000000009b62002 CR4: 0000000000772ee0
    [   36.123327] PKRU: 55555554
    [   36.123328] Kernel panic - not syncing: Fatal exception in interrupt
    [   36.123410] Kernel Offset: 0x1400000 from 0xffffffff81000000 (relocation range: 0xffffffff80000000-0xffffffffbfffffff)
    [   36.135305] ---[ end Kernel panic - not syncing: Fatal exception in interrupt ]---
    
    Fixes: aa3d480315ba ("x86: Use return-thunk in asm code")
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Co-developed-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Josh Poimboeuf <jpoimboe@kernel.org>
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Reported-by: Linux Kernel Functional Testing <lkft@linaro.org>
    Message-Id: <20220713171241.184026-1-cascardo@canonical.com>
    Tested-by: Jack Wang <jinpu.wang@ionos.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5779e2f0cc241d76ae309e2f6f52168204e93fdb
Author: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
Date:   Fri Jul 15 16:45:50 2022 -0300

    efi/x86: use naked RET on mixed mode call wrapper
    
    commit 51a6fa0732d6be6a44e0032752ad2ac10d67c796 upstream.
    
    When running with return thunks enabled under 32-bit EFI, the system
    crashes with:
    
      kernel tried to execute NX-protected page - exploit attempt? (uid: 0)
      BUG: unable to handle page fault for address: 000000005bc02900
      #PF: supervisor instruction fetch in kernel mode
      #PF: error_code(0x0011) - permissions violation
      PGD 18f7063 P4D 18f7063 PUD 18ff063 PMD 190e063 PTE 800000005bc02063
      Oops: 0011 [#1] PREEMPT SMP PTI
      CPU: 0 PID: 0 Comm: swapper/0 Not tainted 5.19.0-rc6+ #166
      Hardware name: QEMU Standard PC (Q35 + ICH9, 2009), BIOS 0.0.0 02/06/2015
      RIP: 0010:0x5bc02900
      Code: Unable to access opcode bytes at RIP 0x5bc028d6.
      RSP: 0018:ffffffffb3203e10 EFLAGS: 00010046
      RAX: 0000000000000000 RBX: 0000000000000000 RCX: 0000000000000048
      RDX: 000000000190dfac RSI: 0000000000001710 RDI: 000000007eae823b
      RBP: ffffffffb3203e70 R08: 0000000001970000 R09: ffffffffb3203e28
      R10: 747563657865206c R11: 6c6977203a696665 R12: 0000000000001710
      R13: 0000000000000030 R14: 0000000001970000 R15: 0000000000000001
      FS:  0000000000000000(0000) GS:ffff8e013ca00000(0000) knlGS:0000000000000000
      CS:  0010 DS: 0018 ES: 0018 CR0: 0000000080050033
      CR2: 000000005bc02900 CR3: 0000000001930000 CR4: 00000000000006f0
      Call Trace:
       ? efi_set_virtual_address_map+0x9c/0x175
       efi_enter_virtual_mode+0x4a6/0x53e
       start_kernel+0x67c/0x71e
       x86_64_start_reservations+0x24/0x2a
       x86_64_start_kernel+0xe9/0xf4
       secondary_startup_64_no_verify+0xe5/0xeb
    
    That's because it cannot jump to the return thunk from the 32-bit code.
    
    Using a naked RET and marking it as safe allows the system to proceed
    booting.
    
    Fixes: aa3d480315ba ("x86: Use return-thunk in asm code")
    Reported-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Cc: Peter Zijlstra (Intel) <peterz@infradead.org>
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Josh Poimboeuf <jpoimboe@kernel.org>
    Cc: <stable@vger.kernel.org>
    Tested-by: Guenter Roeck <linux@roeck-us.net>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit abf88ff13414f3991b35c295c4b564c31e3cb2b0
Author: Nathan Chancellor <nathan@kernel.org>
Date:   Wed Jul 13 08:24:37 2022 -0700

    x86/speculation: Use DECLARE_PER_CPU for x86_spec_ctrl_current
    
    commit db886979683a8360ced9b24ab1125ad0c4d2cf76 upstream.
    
    Clang warns:
    
      arch/x86/kernel/cpu/bugs.c:58:21: error: section attribute is specified on redeclared variable [-Werror,-Wsection]
      DEFINE_PER_CPU(u64, x86_spec_ctrl_current);
                          ^
      arch/x86/include/asm/nospec-branch.h:283:12: note: previous declaration is here
      extern u64 x86_spec_ctrl_current;
                 ^
      1 error generated.
    
    The declaration should be using DECLARE_PER_CPU instead so all
    attributes stay in sync.
    
    Cc: stable@vger.kernel.org
    Fixes: fc02735b14ff ("KVM: VMX: Prevent guest RSB poisoning attacks with eIBRS")
    Reported-by: kernel test robot <lkp@intel.com>
    Signed-off-by: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ecc0d92a9f6cc3f74b67d2c9887d0c800018e661
Author: Jiri Slaby <jirislaby@kernel.org>
Date:   Wed Jul 13 11:50:46 2022 +0200

    x86/asm/32: Fix ANNOTATE_UNRET_SAFE use on 32-bit
    
    commit 3131ef39fb03bbde237d0b8260445898f3dfda5b upstream.
    
    The build on x86_32 currently fails after commit
    
      9bb2ec608a20 (objtool: Update Retpoline validation)
    
    with:
    
      arch/x86/kernel/../../x86/xen/xen-head.S:35: Error: no such instruction: `annotate_unret_safe'
    
    ANNOTATE_UNRET_SAFE is defined in nospec-branch.h. And head_32.S is
    missing this include. Fix this.
    
    Fixes: 9bb2ec608a20 ("objtool: Update Retpoline validation")
    Signed-off-by: Jiri Slaby <jslaby@suse.cz>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/63e23f80-033f-f64e-7522-2816debbc367@kernel.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 95d89ec7dba56f7974aeda2beace2112df9f1418
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Thu Jan 21 15:29:21 2021 -0600

    x86/ftrace: Add UNWIND_HINT_FUNC annotation for ftrace_stub
    
    commit 18660698a3d30868524cefb60dcd4e0e297f71bb upstream.
    
    Prevent an unreachable objtool warning after the sibling call detection
    gets improved.  ftrace_stub() is basically a function, annotate it as
    such.
    
    Acked-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lore.kernel.org/r/6845e1b2fb0723a95740c6674e548ba38c5ea489.1611263461.git.jpoimboe@redhat.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 668cb1ddf0ae7fcffcfc2ac1cfec9f770c8191fc
Author: Ben Hutchings <ben@decadent.org.uk>
Date:   Thu Jul 14 00:39:33 2022 +0200

    x86/xen: Fix initialisation in hypercall_page after rethunk
    
    The hypercall_page is special and the RETs there should not be changed
    into rethunk calls (but can have SLS mitigation).  Change the initial
    instructions to ret + int3 padding, as was done in upstream commit
    5b2fc51576ef "x86/ibt,xen: Sprinkle the ENDBR".
    
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 81f20e5000eca278a8bab4959c4fa1beda1fbed5
Author: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Date:   Thu Jun 30 12:19:47 2022 +0200

    x86, kvm: use proper ASM macros for kvm_vcpu_is_preempted
    
    commit edbaf6e5e93acda96aae23ba134ef3c1466da3b5 upstream.
    
    The build rightfully complains about:
            arch/x86/kernel/kvm.o: warning: objtool: __raw_callee_save___kvm_vcpu_is_preempted()+0x12: missing int3 after ret
    
    because the ASM_RET call is not being used correctly in kvm_vcpu_is_preempted().
    
    This was hand-fixed-up in the kvm merge commit a4cfff3f0f8c ("Merge branch
    'kvm-older-features' into HEAD") which of course can not be backported to
    stable kernels, so just fix this up directly instead.
    
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Ben Hutchings <bwh@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 844947eee36c8ab21005883d6626e713a678c868
Author: Borislav Petkov <bp@suse.de>
Date:   Wed Mar 17 11:33:04 2021 +0100

    tools/insn: Restore the relative include paths for cross building
    
    commit 0705ef64d1ff52b817e278ca6e28095585ff31e1 upstream.
    
    Building perf on ppc causes:
    
      In file included from util/intel-pt-decoder/intel-pt-insn-decoder.c:15:
      util/intel-pt-decoder/../../../arch/x86/lib/insn.c:14:10: fatal error: asm/inat.h: No such file or directory
         14 | #include <asm/inat.h> /*__ignore_sync_check__ */
            |          ^~~~~~~~~~~~
    
    Restore the relative include paths so that the compiler can find the
    headers.
    
    Fixes: 93281c4a9657 ("x86/insn: Add an insn_decode() API")
    Reported-by: Ian Rogers <irogers@google.com>
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Tested-by: Ian Rogers <irogers@google.com>
    Tested-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Link: https://lkml.kernel.org/r/20210317150858.02b1bbc8@canb.auug.org.au
    Cc: Florian Fainelli <f.fainelli@gmail.com>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c035ca88b0742952150b1671bb5d26b96f921245
Author: Thomas Gleixner <tglx@linutronix.de>
Date:   Tue Jul 12 14:01:06 2022 +0200

    x86/static_call: Serialize __static_call_fixup() properly
    
    commit c27c753ea6fd1237f4f96abf8b623d7bab505513 upstream.
    
    __static_call_fixup() invokes __static_call_transform() without holding
    text_mutex, which causes lockdep to complain in text_poke_bp().
    
    Adding the proper locking cures that, but as this is either used during
    early boot or during module finalizing, it's not required to use
    text_poke_bp(). Add an argument to __static_call_transform() which tells
    it to use text_poke_early() for it.
    
    Fixes: ee88d363d156 ("x86,static_call: Use alternative RET encoding")
    Signed-off-by: Thomas Gleixner <tglx@linutronix.de>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit eb38964b6ff864b8bdf87c9cf6221d0b0611a990
Author: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
Date:   Fri Jul 8 13:36:09 2022 -0700

    x86/speculation: Disable RRSBA behavior
    
    commit 4ad3278df6fe2b0852b00d5757fc2ccd8e92c26e upstream.
    
    Some Intel processors may use alternate predictors for RETs on
    RSB-underflow. This condition may be vulnerable to Branch History
    Injection (BHI) and intramode-BTI.
    
    Kernel earlier added spectre_v2 mitigation modes (eIBRS+Retpolines,
    eIBRS+LFENCE, Retpolines) which protect indirect CALLs and JMPs against
    such attacks. However, on RSB-underflow, RET target prediction may
    fallback to alternate predictors. As a result, RET's predicted target
    may get influenced by branch history.
    
    A new MSR_IA32_SPEC_CTRL bit (RRSBA_DIS_S) controls this fallback
    behavior when in kernel mode. When set, RETs will not take predictions
    from alternate predictors, hence mitigating RETs as well. Support for
    this is enumerated by CPUID.7.2.EDX[RRSBA_CTRL] (bit2).
    
    For spectre v2 mitigation, when a user selects a mitigation that
    protects indirect CALLs and JMPs against BHI and intramode-BTI, set
    RRSBA_DIS_S also to protect RETs for RSB-underflow case.
    
    Signed-off-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [bwh: Backported to 5.15: adjust context in scattered.c]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c2ca992144281917cfae19d231b1195c02906a4e
Author: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
Date:   Fri Jul 8 19:10:11 2022 +0200

    x86/kexec: Disable RET on kexec
    
    commit 697977d8415d61f3acbc4ee6d564c9dcf0309507 upstream.
    
    All the invocations unroll to __x86_return_thunk and this file
    must be PIC independent.
    
    This fixes kexec on 64-bit AMD boxes.
    
      [ bp: Fix 32-bit build. ]
    
    Reported-by: Edward Tran <edward.tran@oracle.com>
    Reported-by: Awais Tanveer <awais.tanveer@oracle.com>
    Suggested-by: Ankur Arora <ankur.a.arora@oracle.com>
    Signed-off-by: Konrad Rzeszutek Wilk <konrad.wilk@oracle.com>
    Signed-off-by: Alexandre Chartre <alexandre.chartre@oracle.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 51552b6b52fc865f37ef3ddacd27d807a36695ac
Author: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
Date:   Thu Jul 7 13:41:52 2022 -0300

    x86/bugs: Do not enable IBPB-on-entry when IBPB is not supported
    
    commit 2259da159fbe5dba8ac00b560cf00b6a6537fa18 upstream.
    
    There are some VM configurations which have Skylake model but do not
    support IBPB. In those cases, when using retbleed=ibpb, userspace is going
    to be killed and kernel is going to panic.
    
    If the CPU does not support IBPB, warn and proceed with the auto option. Also,
    do not fallback to IBPB on AMD/Hygon systems if it is not supported.
    
    Fixes: 3ebc17006888 ("x86/bugs: Add retbleed=ibpb")
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 609336351d08699395be24860902e6e0b7860e2b
Author: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
Date:   Wed Jul 6 15:01:15 2022 -0700

    x86/bugs: Add Cannon lake to RETBleed affected CPU list
    
    commit f54d45372c6ac9c993451de5e51312485f7d10bc upstream.
    
    Cannon lake is also affected by RETBleed, add it to the list.
    
    Fixes: 6ad0ad2bf8a6 ("x86/bugs: Report Intel retbleed vulnerability")
    Signed-off-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b24fdd0f1c3328cf8ee0c518b93a7187f8cee097
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Jun 27 22:21:17 2022 +0000

    x86/retbleed: Add fine grained Kconfig knobs
    
    commit f43b9876e857c739d407bc56df288b0ebe1a9164 upstream.
    
    Do fine-grained Kconfig for all the various retbleed parts.
    
    NOTE: if your compiler doesn't support return thunks this will
    silently 'upgrade' your mitigation to IBPB, you might not like this.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: there is no CONFIG_OBJTOOL]
    [cascardo: objtool calling and option parsing has changed]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10:
     - In scripts/Makefile.build, add the objtool option with an ifdef
       block, same as for other options
     - Adjust filename, context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f7851ed697be2ce86bd8baf29111762b7b3ff6cc
Author: Andrew Cooper <andrew.cooper3@citrix.com>
Date:   Fri Jun 24 14:41:21 2022 +0100

    x86/cpu/amd: Enumerate BTC_NO
    
    commit 26aae8ccbc1972233afd08fb3f368947c0314265 upstream.
    
    BTC_NO indicates that hardware is not susceptible to Branch Type Confusion.
    
    Zen3 CPUs don't suffer BTC.
    
    Hypervisors are expected to synthesise BTC_NO when it is appropriate
    given the migration pool, to prevent kernels using heuristics.
    
      [ bp: Massage. ]
    
    Signed-off-by: Andrew Cooper <andrew.cooper3@citrix.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: no X86_FEATURE_BRS]
    [cascardo: no X86_FEATURE_CPPC]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a74f5d23e68d9687ed06bd462d344867824707d8
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Jun 24 14:03:25 2022 +0200

    x86/common: Stamp out the stepping madness
    
    commit 7a05bc95ed1c5a59e47aaade9fb4083c27de9e62 upstream.
    
    The whole MMIO/RETBLEED enumeration went overboard on steppings. Get
    rid of all that and simply use ANY.
    
    If a future stepping of these models would not be affected, it had
    better set the relevant ARCH_CAP_$FOO_NO bit in
    IA32_ARCH_CAPABILITIES.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Dave Hansen <dave.hansen@linux.intel.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 4d7f72b6e1bc630bec7e4cd51814bc2b092bf153
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Tue Jun 14 23:16:15 2022 +0200

    x86/speculation: Fill RSB on vmexit for IBRS
    
    commit 9756bba28470722dacb79ffce554336dd1f6a6cd upstream.
    
    Prevent RSB underflow/poisoning attacks with RSB.  While at it, add a
    bunch of comments to attempt to document the current state of tribal
    knowledge about RSB attacks and what exactly is being mitigated.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 47ae76fb27398e867980d63789058ff7c4f12a35
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Tue Jun 14 23:16:14 2022 +0200

    KVM: VMX: Fix IBRS handling after vmexit
    
    commit bea7e31a5caccb6fe8ed989c065072354f0ecb52 upstream.
    
    For legacy IBRS to work, the IBRS bit needs to be always re-written
    after vmexit, even if it's already on.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5269be9111e2b66572e78647f2e8948f7fc96466
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Tue Jun 14 23:16:13 2022 +0200

    KVM: VMX: Prevent guest RSB poisoning attacks with eIBRS
    
    commit fc02735b14fff8c6678b521d324ade27b1a3d4cf upstream.
    
    On eIBRS systems, the returns in the vmexit return path from
    __vmx_vcpu_run() to vmx_vcpu_run() are exposed to RSB poisoning attacks.
    
    Fix that by moving the post-vmexit spec_ctrl handling to immediately
    after the vmexit.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 84061fff2ad98a7809f00e88a54f584f84830388
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Tue Jun 14 23:16:12 2022 +0200

    KVM: VMX: Convert launched argument to flags
    
    commit bb06650634d3552c0f8557e9d16aa1a408040e28 upstream.
    
    Convert __vmx_vcpu_run()'s 'launched' argument to 'flags', in
    preparation for doing SPEC_CTRL handling immediately after vmexit, which
    will need another flag.
    
    This is much easier than adding a fourth argument, because this code
    supports both 32-bit and 64-bit, and the fourth argument on 32-bit would
    have to be pushed on the stack.
    
    Note that __vmx_vcpu_run_flags() is called outside of the noinstr
    critical section because it will soon start calling potentially
    traceable functions.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 07401c2311f6fddd3c49a392eafc2c28a899f768
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Tue Jun 14 23:16:11 2022 +0200

    KVM: VMX: Flatten __vmx_vcpu_run()
    
    commit 8bd200d23ec42d66ccd517a72dd0b9cc6132d2fd upstream.
    
    Move the vmx_vm{enter,exit}() functionality into __vmx_vcpu_run().  This
    will make it easier to do the spec_ctrl handling before the first RET.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: remove ENDBR]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit df93717a32f57e1b033dbfa2a78809d7d4000648
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Fri Jun 24 12:52:40 2022 +0200

    objtool: Re-add UNWIND_HINT_{SAVE_RESTORE}
    
    commit 8faea26e611189e933ea2281975ff4dc7c1106b6 upstream.
    
    Commit
    
      c536ed2fffd5 ("objtool: Remove SAVE/RESTORE hints")
    
    removed the save/restore unwind hints because they were no longer
    needed. Now they're going to be needed again so re-add them.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1dbefa57725204be0348351ea4756c52b10b3504
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Fri Jun 17 12:12:48 2022 -0700

    x86/speculation: Remove x86_spec_ctrl_mask
    
    commit acac5e98ef8d638a411cfa2ee676c87e1973f126 upstream.
    
    This mask has been made redundant by kvm_spec_ctrl_test_value().  And it
    doesn't even work when MSR interception is disabled, as the guest can
    just write to SPEC_CTRL directly.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ce11f91b21c25dda8b06988817115bef1c636434
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Tue Jun 14 23:16:08 2022 +0200

    x86/speculation: Use cached host SPEC_CTRL value for guest entry/exit
    
    commit bbb69e8bee1bd882784947095ffb2bfe0f7c9470 upstream.
    
    There's no need to recalculate the host value for every entry/exit.
    Just use the cached value in spec_ctrl_current().
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit aad83db22e9950577b5b827f57ed7108b3ca5553
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Tue Jun 14 23:16:07 2022 +0200

    x86/speculation: Fix SPEC_CTRL write on SMT state change
    
    commit 56aa4d221f1ee2c3a49b45b800778ec6e0ab73c5 upstream.
    
    If the SMT state changes, SSBD might get accidentally disabled.  Fix
    that.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d29c07912a49fce965228f73a293e2c899bc7e35
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Tue Jun 14 23:16:06 2022 +0200

    x86/speculation: Fix firmware entry SPEC_CTRL handling
    
    commit e6aa13622ea8283cc699cac5d018cc40a2ba2010 upstream.
    
    The firmware entry code may accidentally clear STIBP or SSBD. Fix that.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f1b01ace814b0a8318041e3aea5fd36cc74f09b0
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Tue Jun 14 23:16:05 2022 +0200

    x86/speculation: Fix RSB filling with CONFIG_RETPOLINE=n
    
    commit b2620facef4889fefcbf2e87284f34dcd4189bce upstream.
    
    If a kernel is built with CONFIG_RETPOLINE=n, but the user still wants
    to mitigate Spectre v2 using IBRS or eIBRS, the RSB filling will be
    silently disabled.
    
    There's nothing retpoline-specific about RSB buffer filling.  Remove the
    CONFIG_RETPOLINE guards around it.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ea1aa926f423a8cf1b2416bb909bfbea37d12b11
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:16:04 2022 +0200

    x86/cpu/amd: Add Spectral Chicken
    
    commit d7caac991feeef1b871ee6988fd2c9725df09039 upstream.
    
    Zen2 uarchs have an undocumented, unnamed, MSR that contains a chicken
    bit for some speculation behaviour. It needs setting.
    
    Note: very belatedly AMD released naming; it's now officially called
          MSR_AMD64_DE_CFG2 and MSR_AMD64_DE_CFG2_SUPPRESS_NOBR_PRED_BIT
          but shall remain the SPECTRAL CHICKEN.
    
    Suggested-by: Andrew Cooper <Andrew.Cooper3@citrix.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0d1a8a16e62c8048f2ff7f9c6f448bf595d2a2a8
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:16:03 2022 +0200

    objtool: Add entry UNRET validation
    
    commit a09a6e2399ba0595c3042b3164f3ca68a3cff33e upstream.
    
    Since entry asm is tricky, add a validation pass that ensures the
    retbleed mitigation has been done before the first actual RET
    instruction.
    
    Entry points are those that either have UNWIND_HINT_ENTRY, which acts
    as UNWIND_HINT_EMPTY but marks the instruction as an entry point, or
    those that have UWIND_HINT_IRET_REGS at +0.
    
    This is basically a variant of validate_branch() that is
    intra-function and it will simply follow all branches from marked
    entry points and ensures that all paths lead to ANNOTATE_UNRET_END.
    
    If a path hits RET or an indirection the path is a fail and will be
    reported.
    
    There are 3 ANNOTATE_UNRET_END instances:
    
     - UNTRAIN_RET itself
     - exception from-kernel; this path doesn't need UNTRAIN_RET
     - all early exceptions; these also don't need UNTRAIN_RET
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: arch/x86/entry/entry_64.S no pt_regs return at .Lerror_entry_done_lfence]
    [cascardo: tools/objtool/builtin-check.c no link option validation]
    [cascardo: tools/objtool/check.c opts.ibt is ibt]
    [cascardo: tools/objtool/include/objtool/builtin.h leave unret option as bool, no struct opts]
    [cascardo: objtool is still called from scripts/link-vmlinux.sh]
    [cascardo: no IBT support]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10:
     - In scripts/link-vmlinux.sh, use "test -n" instead of is_enabled
     - Adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fbab1c94eb1a3139d7ac0620dc6d7d6a33f3b255
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Tue Jun 14 15:07:19 2022 -0700

    x86/bugs: Do IBPB fallback check only once
    
    commit 0fe4aeea9c01baabecc8c3afc7889c809d939bc2 upstream.
    
    When booting with retbleed=auto, if the kernel wasn't built with
    CONFIG_CC_HAS_RETURN_THUNK, the mitigation falls back to IBPB.  Make
    sure a warning is printed in that case.  The IBPB fallback check is done
    twice, but it really only needs to be done once.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c8845b875437b8ea9cd023f15b44c436c9c5b62d
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:16:02 2022 +0200

    x86/bugs: Add retbleed=ibpb
    
    commit 3ebc170068885b6fc7bedda6c667bb2c4d533159 upstream.
    
    jmp2ret mitigates the easy-to-attack case at relatively low overhead.
    It mitigates the long speculation windows after a mispredicted RET, but
    it does not mitigate the short speculation window from arbitrary
    instruction boundaries.
    
    On Zen2, there is a chicken bit which needs setting, which mitigates
    "arbitrary instruction boundaries" down to just "basic block boundaries".
    
    But there is no fix for the short speculation window on basic block
    boundaries, other than to flush the entire BTB to evict all attacker
    predictions.
    
    On the spectrum of "fast & blurry" -> "safe", there is (on top of STIBP
    or no-SMT):
    
      1) Nothing            System wide open
      2) jmp2ret            May stop a script kiddy
      3) jmp2ret+chickenbit  Raises the bar rather further
      4) IBPB               Only thing which can count as "safe".
    
    Tentative numbers put IBPB-on-entry at a 2.5x hit on Zen2, and a 10x hit
    on Zen1 according to lmbench.
    
      [ bp: Fixup feature bit comments, document option, 32-bit build fix. ]
    
    Suggested-by: Andrew Cooper <Andrew.Cooper3@citrix.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f728eff26339d85825e588d461f0e55267bc6c3f
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:16:00 2022 +0200

    x86/xen: Rename SYS* entry points
    
    commit b75b7f8ef1148be1b9321ffc2f6c19238904b438 upstream.
    
    Native SYS{CALL,ENTER} entry points are called
    entry_SYS{CALL,ENTER}_{64,compat}, make sure the Xen versions are
    named consistently.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 28aa3fa0b2c9d0cd7bdac42d9eb7fe3d5f6c79e8
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:59 2022 +0200

    objtool: Update Retpoline validation
    
    commit 9bb2ec608a209018080ca262f771e6a9ff203b6f upstream.
    
    Update retpoline validation with the new CONFIG_RETPOLINE requirement of
    not having bare naked RET instructions.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: conflict fixup at arch/x86/xen/xen-head.S]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 55bba093fd91a76971134e3a4e3576e536c08f5c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:58 2022 +0200

    intel_idle: Disable IBRS during long idle
    
    commit bf5835bcdb9635c97f85120dba9bfa21e111130f upstream.
    
    Having IBRS enabled while the SMT sibling is idle unnecessarily slows
    down the running sibling. OTOH, disabling IBRS around idle takes two
    MSR writes, which will increase the idle latency.
    
    Therefore, only disable IBRS around deeper idle states. Shallow idle
    states are bounded by the tick in duration, since NOHZ is not allowed
    for them by virtue of their short target residency.
    
    Only do this for mwait-driven idle, since that keeps interrupts disabled
    across idle, which makes disabling IBRS vs IRQ-entry a non-issue.
    
    Note: C6 is a random threshold, most importantly C1 probably shouldn't
    disable IBRS, benchmarking needed.
    
    Suggested-by: Tim Chen <tim.c.chen@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: no CPUIDLE_FLAG_IRQ_ENABLE]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e8142e2d6cb6b39fdd78bc17199429f79bcd051c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Jun 24 13:48:58 2022 +0200

    x86/bugs: Report Intel retbleed vulnerability
    
    commit 6ad0ad2bf8a67e27d1f9d006a1dabb0e1c360cc3 upstream.
    
    Skylake suffers from RSB underflow speculation issues; report this
    vulnerability and it's mitigation (spectre_v2=ibrs).
    
      [jpoimboe: cleanups, eibrs]
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a0f8ef71d762501769df69e35c4c4e7496866d90
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:56 2022 +0200

    x86/bugs: Split spectre_v2_select_mitigation() and spectre_v2_user_select_mitigation()
    
    commit 166115c08a9b0b846b783088808a27d739be6e8d upstream.
    
    retbleed will depend on spectre_v2, while spectre_v2_user depends on
    retbleed. Break this cycle.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dabc2a1b406ae0ff5286c91f7519b3e20ec2aa63
Author: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
Date:   Tue Jun 14 23:15:55 2022 +0200

    x86/speculation: Add spectre_v2=ibrs option to support Kernel IBRS
    
    commit 7c693f54c873691a4b7da05c7e0f74e67745d144 upstream.
    
    Extend spectre_v2= boot option with Kernel IBRS.
    
      [jpoimboe: no STIBP with IBRS]
    
    Signed-off-by: Pawan Gupta <pawan.kumar.gupta@linux.intel.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6d7e13ccc4d73e5c88cc015bc0154b7d08f65038
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:54 2022 +0200

    x86/bugs: Optimize SPEC_CTRL MSR writes
    
    commit c779bc1a9002fa474175b80e72b85c9bf628abb0 upstream.
    
    When changing SPEC_CTRL for user control, the WRMSR can be delayed
    until return-to-user when KERNEL_IBRS has been enabled.
    
    This avoids an MSR write during context switch.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3dddacf8c3cc29b9b37d8c4353f746e510ad1371
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:53 2022 +0200

    x86/entry: Add kernel IBRS implementation
    
    commit 2dbb887e875b1de3ca8f40ddf26bcfe55798c609 upstream.
    
    Implement Kernel IBRS - currently the only known option to mitigate RSB
    underflow speculation issues on Skylake hardware.
    
    Note: since IBRS_ENTER requires fuller context established than
    UNTRAIN_RET, it must be placed after it. However, since UNTRAIN_RET
    itself implies a RET, it must come after IBRS_ENTER. This means
    IBRS_ENTER needs to also move UNTRAIN_RET.
    
    Note 2: KERNEL_IBRS is sub-optimal for XenPV.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: conflict at arch/x86/entry/entry_64.S, skip_r11rcx]
    [cascardo: conflict at arch/x86/entry/entry_64_compat.S]
    [cascardo: conflict fixups, no ANNOTATE_NOENDBR]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9e727e0d9486121de5c21cbb65fcc0c907834b17
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:52 2022 +0200

    x86/bugs: Keep a per-CPU IA32_SPEC_CTRL value
    
    commit caa0ff24d5d0e02abce5e65c3d2b7f20a6617be5 upstream.
    
    Due to TIF_SSBD and TIF_SPEC_IB the actual IA32_SPEC_CTRL value can
    differ from x86_spec_ctrl_base. As such, keep a per-CPU value
    reflecting the current task's MSR content.
    
      [jpoimboe: rename]
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a989e75136192036d47e4dc4fe87ff9c961d6b46
Author: Kim Phillips <kim.phillips@amd.com>
Date:   Tue Jun 14 23:15:51 2022 +0200

    x86/bugs: Enable STIBP for JMP2RET
    
    commit e8ec1b6e08a2102d8755ccb06fa26d540f26a2fa upstream.
    
    For untrained return thunks to be fully effective, STIBP must be enabled
    or SMT disabled.
    
    Co-developed-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Kim Phillips <kim.phillips@amd.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3f29791d56d32a610a2b57a9b700b1bc1912e41f
Author: Alexandre Chartre <alexandre.chartre@oracle.com>
Date:   Tue Jun 14 23:15:50 2022 +0200

    x86/bugs: Add AMD retbleed= boot parameter
    
    commit 7fbf47c7ce50b38a64576b150e7011ae73d54669 upstream.
    
    Add the "retbleed=<value>" boot parameter to select a mitigation for
    RETBleed. Possible values are "off", "auto" and "unret"
    (JMP2RET mitigation). The default value is "auto".
    
    Currently, "retbleed=auto" will select the unret mitigation on
    AMD and Hygon and no mitigation on Intel (JMP2RET is not effective on
    Intel).
    
      [peterz: rebase; add hygon]
      [jpoimboe: cleanups]
    
    Signed-off-by: Alexandre Chartre <alexandre.chartre@oracle.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 876750cca4f043bd626a3ac760ce887dda3b6ec7
Author: Alexandre Chartre <alexandre.chartre@oracle.com>
Date:   Tue Jun 14 23:15:49 2022 +0200

    x86/bugs: Report AMD retbleed vulnerability
    
    commit 6b80b59b3555706508008f1f127b5412c89c7fd8 upstream.
    
    Report that AMD x86 CPUs are vulnerable to the RETBleed (Arbitrary
    Speculative Code Execution with Return Instructions) attack.
    
      [peterz: add hygon]
      [kim: invert parity; fam15h]
    
    Co-developed-by: Kim Phillips <kim.phillips@amd.com>
    Signed-off-by: Kim Phillips <kim.phillips@amd.com>
    Signed-off-by: Alexandre Chartre <alexandre.chartre@oracle.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit df748593c55389892902aecb8691080ad5e8cff5
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:48 2022 +0200

    x86: Add magic AMD return-thunk
    
    commit a149180fbcf336e97ce4eb2cdc13672727feb94d upstream.
    
    Note: needs to be in a section distinct from Retpolines such that the
    Retpoline RET substitution cannot possibly use immediate jumps.
    
    ORC unwinding for zen_untrain_ret() and __x86_return_thunk() is a
    little tricky but works due to the fact that zen_untrain_ret() doesn't
    have any stack ops and as such will emit a single ORC entry at the
    start (+0x3f).
    
    Meanwhile, unwinding an IP, including the __x86_return_thunk() one
    (+0x40) will search for the largest ORC entry smaller or equal to the
    IP, these will find the one ORC entry (+0x3f) and all works.
    
      [ Alexandre: SVM part. ]
      [ bp: Build fix, massages. ]
    
    Suggested-by: Andrew Cooper <Andrew.Cooper3@citrix.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: conflicts at arch/x86/entry/entry_64_compat.S]
    [cascardo: there is no ANNOTATE_NOENDBR]
    [cascardo: objtool commit 34c861e806478ac2ea4032721defbf1d6967df08 missing]
    [cascardo: conflict fixup]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: SEV-ES is not supported, so drop the change
     in arch/x86/kvm/svm/vmenter.S]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c70d6f82141b89db6c076b0cbf9a7a2edc29e46d
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:47 2022 +0200

    objtool: Treat .text.__x86.* as noinstr
    
    commit 951ddecf435659553ed15a9214e153a3af43a9a1 upstream.
    
    Needed because zen_untrain_ret() will be called from noinstr code.
    
    Also makes sense since the thunks MUST NOT contain instrumentation nor
    be poked with dynamic instrumentation.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c9eb5dcdc8f4a848b45b97725f5a2b8d324bb31a
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:45 2022 +0200

    x86: Use return-thunk in asm code
    
    commit aa3d480315ba6c3025a60958e1981072ea37c3df upstream.
    
    Use the return thunk in asm code. If the thunk isn't needed, it will
    get patched into a RET instruction during boot by apply_returns().
    
    Since alternatives can't handle relocations outside of the first
    instruction, putting a 'jmp __x86_return_thunk' in one is not valid,
    therefore carve out the memmove ERMS path into a separate label and jump
    to it.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: no RANDSTRUCT_CFLAGS]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5b2edaf709b50c81b3c6ddb745c8a76ab6632645
Author: Kim Phillips <kim.phillips@amd.com>
Date:   Tue Jun 14 23:15:44 2022 +0200

    x86/sev: Avoid using __x86_return_thunk
    
    commit 0ee9073000e8791f8b134a8ded31bcc767f7f232 upstream.
    
    Specifically, it's because __enc_copy() encrypts the kernel after
    being relocated outside the kernel in sme_encrypt_execute(), and the
    RET macro's jmp offset isn't amended prior to execution.
    
    Signed-off-by: Kim Phillips <kim.phillips@amd.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d6eb50e9b7245a238872a9a969f84993339780a5
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:43 2022 +0200

    x86/vsyscall_emu/64: Don't use RET in vsyscall emulation
    
    commit 15583e514eb16744b80be85dea0774ece153177d upstream.
    
    This is userspace code and doesn't play by the normal kernel rules.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ee4996f07d868ee6cc7e76151dfab9a2344cdeb0
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:42 2022 +0200

    x86/kvm: Fix SETcc emulation for return thunks
    
    commit af2e140f34208a5dfb6b7a8ad2d56bda88f0524d upstream.
    
    Prepare the SETcc fastop stuff for when RET can be larger still.
    
    The tricky bit here is that the expressions should not only be
    constant C expressions, but also absolute GAS expressions. This means
    no ?: and 'true' is ~0.
    
    Also ensure em_setcc() has the same alignment as the actual FOP_SETCC()
    ops, this ensures there cannot be an alignment hole between em_setcc()
    and the first op.
    
    Additionally, add a .skip directive to the FOP_SETCC() macro to fill
    any remaining space with INT3 traps; however the primary purpose of
    this directive is to generate AS warnings when the remaining space
    goes negative. Which is a very good indication the alignment magic
    went side-ways.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: ignore ENDBR when computing SETCC_LENGTH]
    [cascardo: conflict fixup]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e0e06a922706204df43d50032c05af75d8e75f8e
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:41 2022 +0200

    x86/bpf: Use alternative RET encoding
    
    commit d77cfe594ad50e0bf95d457e02ccd578791b2a15 upstream.
    
    Use the return thunk in eBPF generated code, if needed.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: add the necessary cnt variable to emit_return()]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 00b136bb6254e0abf6aaafe62c4da5f6c4fea4cb
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:40 2022 +0200

    x86/ftrace: Use alternative RET encoding
    
    commit 1f001e9da6bbf482311e45e48f53c2bd2179e59c upstream.
    
    Use the return thunk in ftrace trampolines, if needed.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: still copy return from ftrace_stub]
    [cascardo: use memcpy(text_gen_insn) as there is no __text_gen_insn]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7723edf5edfdfdabd8234e45142be86598a04cad
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:39 2022 +0200

    x86,static_call: Use alternative RET encoding
    
    commit ee88d363d15617ff50ac24fab0ffec11113b2aeb upstream.
    
    In addition to teaching static_call about the new way to spell 'RET',
    there is an added complication in that static_call() is allowed to
    rewrite text before it is known which particular spelling is required.
    
    In order to deal with this; have a static_call specific fixup in the
    apply_return() 'alternative' patching routine that will rewrite the
    static_call trampoline to match the definite sequence.
    
    This in turn creates the problem of uniquely identifying static call
    trampolines. Currently trampolines are 8 bytes, the first 5 being the
    jmp.d32/ret sequence and the final 3 a byte sequence that spells out
    'SCT'.
    
    This sequence is used in __static_call_validate() to ensure it is
    patching a trampoline and not a random other jmp.d32. That is,
    false-positives shouldn't be plenty, but aren't a big concern.
    
    OTOH the new __static_call_fixup() must not have false-positives, and
    'SCT' decodes to the somewhat weird but semi plausible sequence:
    
      push %rbx
      rex.XB push %r12
    
    Additionally, there are SLS concerns with immediate jumps. Combined it
    seems like a good moment to change the signature to a single 3 byte
    trap instruction that is unique to this usage and will not ever get
    generated by accident.
    
    As such, change the signature to: '0x0f, 0xb9, 0xcc', which decodes
    to:
    
      ud1 %esp, %ecx
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: skip validation as introduced by 2105a92748e8 ("static_call,x86: Robustify trampoline patching")]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 446eb6f08936e6f87bea9f35be05556a7211df9b
Author: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
Date:   Fri Jul 1 09:00:45 2022 -0300

    objtool: skip non-text sections when adding return-thunk sites
    
    The .discard.text section is added in order to reserve BRK, with a
    temporary function just so it can give it a size. This adds a relocation to
    the return thunk, which objtool will add to the .return_sites section.
    Linking will then fail as there are references to the .discard.text
    section.
    
    Do not add instructions from non-text sections to the list of return thunk
    calls, avoiding the reference to .discard.text.
    
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Acked-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8bdb25f7aee312450e9c9ac21ae209d9cf0602e5
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:38 2022 +0200

    x86,objtool: Create .return_sites
    
    commit d9e9d2300681d68a775c28de6aa6e5290ae17796 upstream.
    
    Find all the return-thunk sites and record them in a .return_sites
    section such that the kernel can undo this.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: conflict fixup because of functions added to support IBT]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 716410960ba0a2d2c3f59cb46315467c9faf59b2
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:37 2022 +0200

    x86: Undo return-thunk damage
    
    commit 15e67227c49a57837108acfe1c80570e1bd9f962 upstream.
    
    Introduce X86_FEATURE_RETHUNK for those afflicted with needing this.
    
      [ bp: Do only INT3 padding - simpler. ]
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: CONFIG_STACK_VALIDATION vs CONFIG_OBJTOOL]
    [cascardo: no IBT support]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 270de63cf4a380fe9942d3e0da599c0e966fad78
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:36 2022 +0200

    x86/retpoline: Use -mfunction-return
    
    commit 0b53c374b9eff2255a386f1f1cfb9a928e52a5ae upstream.
    
    Utilize -mfunction-return=thunk-extern when available to have the
    compiler replace RET instructions with direct JMPs to the symbol
    __x86_return_thunk. This does not affect assembler (.S) sources, only C
    sources.
    
    -mfunction-return=thunk-extern has been available since gcc 7.3 and
    clang 15.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Nick Desaulniers <ndesaulniers@google.com>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Tested-by: Nick Desaulniers <ndesaulniers@google.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: RETPOLINE_CFLAGS is at Makefile]
    [cascardo: remove ANNOTATE_NOENDBR from __x86_return_thunk]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 37b9bb094123a14a986137d693b5aa18a240128b
Author: Ben Hutchings <ben@decadent.org.uk>
Date:   Mon Jul 11 00:31:38 2022 +0200

    Makefile: Set retpoline cflags based on CONFIG_CC_IS_{CLANG,GCC}
    
    This was done as part of commit 7d73c3e9c51400d3e0e755488050804e4d44737a
    "Makefile: remove stale cc-option checks" upstream, and is needed to
    support backporting further retpoline changes.
    
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3e519ed8d509f5f2e1c67984f3cdf079b725e724
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:35 2022 +0200

    x86/retpoline: Swizzle retpoline thunk
    
    commit 00e1533325fd1fb5459229fe37f235462649f668 upstream.
    
    Put the actual retpoline thunk as the original code so that it can
    become more complicated. Specifically, it allows RET to be a JMP,
    which can't be .altinstr_replacement since that doesn't do relocations
    (except for the very first instruction).
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6a2b142886c52244a9c1dfb0a36971daa963541a
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:34 2022 +0200

    x86/retpoline: Cleanup some #ifdefery
    
    commit 369ae6ffc41a3c1137cab697635a84d0cc7cdcea upstream.
    
    On it's own not much of a cleanup but it prepares for more/similar
    code.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    [cascardo: conflict fixup because of DISABLE_ENQCMD]
    [cascardo: no changes at nospec-branch.h and bpf_jit_comp.c]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit feec5277d5aa9780d4814084262b98af2b1a2242
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:33 2022 +0200

    x86/cpufeatures: Move RETPOLINE flags to word 11
    
    commit a883d624aed463c84c22596006e5a96f5b44db31 upstream.
    
    In order to extend the RETPOLINE features to 4, move them to word 11
    where there is still room. This mostly keeps DISABLE_RETPOLINE
    simple.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: bits 8 and 9 of word 11 are also free here,
     so comment them accordingly]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7070bbb66c5303117e4c7651711ea7daae4c64b5
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Jun 14 23:15:32 2022 +0200

    x86/kvm/vmx: Make noinstr clean
    
    commit 742ab6df974ae8384a2dd213db1a3a06cf6d8936 upstream.
    
    The recent mmio_stale_data fixes broke the noinstr constraints:
    
      vmlinux.o: warning: objtool: vmx_vcpu_enter_exit+0x15b: call to wrmsrl.constprop.0() leaves .noinstr.text section
      vmlinux.o: warning: objtool: vmx_vcpu_enter_exit+0x1bf: call to kvm_arch_has_assigned_device() leaves .noinstr.text section
    
    make it all happy again.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit accb8cfd506da1e218a0cd56a11f37885dc32adf
Author: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
Date:   Fri Jul 1 11:21:20 2022 -0300

    x86/realmode: build with -D__DISABLE_EXPORTS
    
    Commit 156ff4a544ae ("x86/ibt: Base IBT bits") added this option when
    building realmode in order to disable IBT there. This is also needed in
    order to disable return thunks.
    
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 236b959da9d145c311f9daa65e3fbbe1a3c9c9af
Author: Mikulas Patocka <mpatocka@redhat.com>
Date:   Mon May 16 11:06:36 2022 -0400

    objtool: Fix objtool regression on x32 systems
    
    commit 22682a07acc308ef78681572e19502ce8893c4d4 upstream.
    
    Commit c087c6e7b551 ("objtool: Fix type of reloc::addend") failed to
    appreciate cross building from ILP32 hosts, where 'int' == 'long' and
    the issue persists.
    
    As such, use s64/int64_t/Elf64_Sxword for this field and suffer the
    pain that is ISO C99 printf formats for it.
    
    Fixes: c087c6e7b551 ("objtool: Fix type of reloc::addend")
    Signed-off-by: Mikulas Patocka <mpatocka@redhat.com>
    [peterz: reword changelog, s/long long/s64/]
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Cc: <stable@vger.kernel.org>
    Link: https://lkml.kernel.org/r/alpine.LRH.2.02.2205161041260.11556@file01.intranet.prod.int.rdu2.redhat.com
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 148811a84292467b0527eb789f24cd4fe004136c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri May 6 14:14:35 2022 +0200

    x86/entry: Remove skip_r11rcx
    
    commit 1b331eeea7b8676fc5dbdf80d0a07e41be226177 upstream.
    
    Yes, r11 and rcx have been restored previously, but since they're being
    popped anyway (into rsi) might as well pop them into their own regs --
    setting them to the value they already are.
    
    Less magical code.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/20220506121631.365070674@infradead.org
    [bwh: Backported to 5.10: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e1db6c8a69ec74aa0ecff19857895d10f39c6d98
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue May 17 17:42:04 2022 +0200

    objtool: Fix symbol creation
    
    commit ead165fa1042247b033afad7be4be9b815d04ade upstream.
    
    Nathan reported objtool failing with the following messages:
    
      warning: objtool: no non-local symbols !?
      warning: objtool: gelf_update_symshndx: invalid section index
    
    The problem is due to commit 4abff6d48dbc ("objtool: Fix code relocs
    vs weak symbols") failing to consider the case where an object would
    have no non-local symbols.
    
    The problem that commit tries to address is adding a STB_LOCAL symbol
    to the symbol table in light of the ELF spec's requirement that:
    
      In each symbol table, all symbols with STB_LOCAL binding preced the
      weak and global symbols.  As ``Sections'' above describes, a symbol
      table section's sh_info section header member holds the symbol table
      index for the first non-local symbol.
    
    The approach taken is to find this first non-local symbol, move that
    to the end and then re-use the freed spot to insert a new local symbol
    and increment sh_info.
    
    Except it never considered the case of object files without global
    symbols and got a whole bunch of details wrong -- so many in fact that
    it is a wonder it ever worked :/
    
    Specifically:
    
     - It failed to re-hash the symbol on the new index, so a subsequent
       find_symbol_by_index() would not find it at the new location and a
       query for the old location would now return a non-deterministic
       choice between the old and new symbol.
    
     - It failed to appreciate that the GElf wrappers are not a valid disk
       format (it works because GElf is basically Elf64 and we only
       support x86_64 atm.)
    
     - It failed to fully appreciate how horrible the libelf API really is
       and got the gelf_update_symshndx() call pretty much completely
       wrong; with the direct consequence that if inserting a second
       STB_LOCAL symbol would require moving the same STB_GLOBAL symbol
       again it would completely come unstuck.
    
    Write a new elf_update_symbol() function that wraps all the magic
    required to update or create a new symbol at a given index.
    
    Specifically, gelf_update_sym*() require an @ndx argument that is
    relative to the @data argument; this means you have to manually
    iterate the section data descriptor list and update @ndx.
    
    Fixes: 4abff6d48dbc ("objtool: Fix code relocs vs weak symbols")
    Reported-by: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@kernel.org>
    Tested-by: Nathan Chancellor <nathan@kernel.org>
    Cc: <stable@vger.kernel.org>
    Link: https://lkml.kernel.org/r/YoPCTEYjoPqE4ZxB@hirez.programming.kicks-ass.net
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    [bwh: Backported to 5.10: elf_hash_add() takes a hash table pointer,
     not just a name]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3e8afd072d098958a507fb10251a201c9899150c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Sun Apr 17 17:03:40 2022 +0200

    objtool: Fix type of reloc::addend
    
    commit c087c6e7b551b7f208c0b852304f044954cf2bb3 upstream.
    
    Elf{32,64}_Rela::r_addend is of type: Elf{32,64}_Sword, that means
    that our reloc::addend needs to be long or face tuncation issues when
    we do elf_rebuild_reloc_section():
    
      - 107:  48 b8 00 00 00 00 00 00 00 00   movabs $0x0,%rax        109: R_X86_64_64        level4_kernel_pgt+0x80000067
      + 107:  48 b8 00 00 00 00 00 00 00 00   movabs $0x0,%rax        109: R_X86_64_64        level4_kernel_pgt-0x7fffff99
    
    Fixes: 627fce14809b ("objtool: Add ORC unwind table generation")
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lkml.kernel.org/r/20220419203807.596871927@infradead.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 42ec4d71353f4c6da1d94baf64acbb1badc16b11
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Sun Apr 17 17:03:36 2022 +0200

    objtool: Fix code relocs vs weak symbols
    
    commit 4abff6d48dbcea8200c7ea35ba70c242d128ebf3 upstream.
    
    Occasionally objtool driven code patching (think .static_call_sites
    .retpoline_sites etc..) goes sideways and it tries to patch an
    instruction that doesn't match.
    
    Much head-scatching and cursing later the problem is as outlined below
    and affects every section that objtool generates for us, very much
    including the ORC data. The below uses .static_call_sites because it's
    convenient for demonstration purposes, but as mentioned the ORC
    sections, .retpoline_sites and __mount_loc are all similarly affected.
    
    Consider:
    
    foo-weak.c:
    
      extern void __SCT__foo(void);
    
      __attribute__((weak)) void foo(void)
      {
              return __SCT__foo();
      }
    
    foo.c:
    
      extern void __SCT__foo(void);
      extern void my_foo(void);
    
      void foo(void)
      {
              my_foo();
              return __SCT__foo();
      }
    
    These generate the obvious code
    (gcc -O2 -fcf-protection=none -fno-asynchronous-unwind-tables -c foo*.c):
    
    foo-weak.o:
    0000000000000000 <foo>:
       0:   e9 00 00 00 00          jmpq   5 <foo+0x5>      1: R_X86_64_PLT32       __SCT__foo-0x4
    
    foo.o:
    0000000000000000 <foo>:
       0:   48 83 ec 08             sub    $0x8,%rsp
       4:   e8 00 00 00 00          callq  9 <foo+0x9>      5: R_X86_64_PLT32       my_foo-0x4
       9:   48 83 c4 08             add    $0x8,%rsp
       d:   e9 00 00 00 00          jmpq   12 <foo+0x12>    e: R_X86_64_PLT32       __SCT__foo-0x4
    
    Now, when we link these two files together, you get something like
    (ld -r -o foos.o foo-weak.o foo.o):
    
    foos.o:
    0000000000000000 <foo-0x10>:
       0:   e9 00 00 00 00          jmpq   5 <foo-0xb>      1: R_X86_64_PLT32       __SCT__foo-0x4
       5:   66 2e 0f 1f 84 00 00 00 00 00   nopw   %cs:0x0(%rax,%rax,1)
       f:   90                      nop
    
    0000000000000010 <foo>:
      10:   48 83 ec 08             sub    $0x8,%rsp
      14:   e8 00 00 00 00          callq  19 <foo+0x9>     15: R_X86_64_PLT32      my_foo-0x4
      19:   48 83 c4 08             add    $0x8,%rsp
      1d:   e9 00 00 00 00          jmpq   22 <foo+0x12>    1e: R_X86_64_PLT32      __SCT__foo-0x4
    
    Noting that ld preserves the weak function text, but strips the symbol
    off of it (hence objdump doing that funny negative offset thing). This
    does lead to 'interesting' unused code issues with objtool when ran on
    linked objects, but that seems to be working (fingers crossed).
    
    So far so good.. Now lets consider the objtool static_call output
    section (readelf output, old binutils):
    
    foo-weak.o:
    
    Relocation section '.rela.static_call_sites' at offset 0x2c8 contains 1 entry:
        Offset             Info             Type               Symbol's Value  Symbol's Name + Addend
    0000000000000000  0000000200000002 R_X86_64_PC32          0000000000000000 .text + 0
    0000000000000004  0000000d00000002 R_X86_64_PC32          0000000000000000 __SCT__foo + 1
    
    foo.o:
    
    Relocation section '.rela.static_call_sites' at offset 0x310 contains 2 entries:
        Offset             Info             Type               Symbol's Value  Symbol's Name + Addend
    0000000000000000  0000000200000002 R_X86_64_PC32          0000000000000000 .text + d
    0000000000000004  0000000d00000002 R_X86_64_PC32          0000000000000000 __SCT__foo + 1
    
    foos.o:
    
    Relocation section '.rela.static_call_sites' at offset 0x430 contains 4 entries:
        Offset             Info             Type               Symbol's Value  Symbol's Name + Addend
    0000000000000000  0000000100000002 R_X86_64_PC32          0000000000000000 .text + 0
    0000000000000004  0000000d00000002 R_X86_64_PC32          0000000000000000 __SCT__foo + 1
    0000000000000008  0000000100000002 R_X86_64_PC32          0000000000000000 .text + 1d
    000000000000000c  0000000d00000002 R_X86_64_PC32          0000000000000000 __SCT__foo + 1
    
    So we have two patch sites, one in the dead code of the weak foo and one
    in the real foo. All is well.
    
    *HOWEVER*, when the toolchain strips unused section symbols it
    generates things like this (using new enough binutils):
    
    foo-weak.o:
    
    Relocation section '.rela.static_call_sites' at offset 0x2c8 contains 1 entry:
        Offset             Info             Type               Symbol's Value  Symbol's Name + Addend
    0000000000000000  0000000200000002 R_X86_64_PC32          0000000000000000 foo + 0
    0000000000000004  0000000d00000002 R_X86_64_PC32          0000000000000000 __SCT__foo + 1
    
    foo.o:
    
    Relocation section '.rela.static_call_sites' at offset 0x310 contains 2 entries:
        Offset             Info             Type               Symbol's Value  Symbol's Name + Addend
    0000000000000000  0000000200000002 R_X86_64_PC32          0000000000000000 foo + d
    0000000000000004  0000000d00000002 R_X86_64_PC32          0000000000000000 __SCT__foo + 1
    
    foos.o:
    
    Relocation section '.rela.static_call_sites' at offset 0x430 contains 4 entries:
        Offset             Info             Type               Symbol's Value  Symbol's Name + Addend
    0000000000000000  0000000100000002 R_X86_64_PC32          0000000000000000 foo + 0
    0000000000000004  0000000d00000002 R_X86_64_PC32          0000000000000000 __SCT__foo + 1
    0000000000000008  0000000100000002 R_X86_64_PC32          0000000000000000 foo + d
    000000000000000c  0000000d00000002 R_X86_64_PC32          0000000000000000 __SCT__foo + 1
    
    And now we can see how that foos.o .static_call_sites goes side-ways, we
    now have _two_ patch sites in foo. One for the weak symbol at foo+0
    (which is no longer a static_call site!) and one at foo+d which is in
    fact the right location.
    
    This seems to happen when objtool cannot find a section symbol, in which
    case it falls back to any other symbol to key off of, however in this
    case that goes terribly wrong!
    
    As such, teach objtool to create a section symbol when there isn't
    one.
    
    Fixes: 44f6a7c0755d ("objtool: Fix seg fault with Clang non-section symbols")
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lkml.kernel.org/r/20220419203807.655552918@infradead.org
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 831d5c07b7e7c6eab9df64ae328bacb5a6a0313a
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Wed Mar 23 23:35:01 2022 +0100

    objtool: Fix SLS validation for kcov tail-call replacement
    
    commit 7a53f408902d913cd541b4f8ad7dbcd4961f5b82 upstream.
    
    Since not all compilers have a function attribute to disable KCOV
    instrumentation, objtool can rewrite KCOV instrumentation in noinstr
    functions as per commit:
    
      f56dae88a81f ("objtool: Handle __sanitize_cov*() tail calls")
    
    However, this has subtle interaction with the SLS validation from
    commit:
    
      1cc1e4c8aab4 ("objtool: Add straight-line-speculation validation")
    
    In that when a tail-call instrucion is replaced with a RET an
    additional INT3 instruction is also written, but is not represented in
    the decoded instruction stream.
    
    This then leads to false positive missing INT3 objtool warnings in
    noinstr code.
    
    Instead of adding additional struct instruction objects, mark the RET
    instruction with retpoline_safe to suppress the warning (since we know
    there really is an INT3).
    
    Fixes: 1cc1e4c8aab4 ("objtool: Add straight-line-speculation validation")
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20220323230712.GA8939@worktop.programming.kicks-ass.net
    Signed-off-by: Sasha Levin <sashal@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9728af8857dfd0bfed48ab137955d28afbc107e5
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Mar 24 00:05:55 2022 +0100

    crypto: x86/poly1305 - Fixup SLS
    
    commit 7ed7aa4de9421229be6d331ed52d5cd09c99f409 upstream.
    
    Due to being a perl generated asm file, it got missed by the mass
    convertion script.
    
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_init_x86_64()+0x3a: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_blocks_x86_64()+0xf2: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_emit_x86_64()+0x37: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: __poly1305_block()+0x6d: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: __poly1305_init_avx()+0x1e8: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_blocks_avx()+0x18a: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_blocks_avx()+0xaf8: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_emit_avx()+0x99: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_blocks_avx2()+0x18a: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_blocks_avx2()+0x776: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_blocks_avx512()+0x18a: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_blocks_avx512()+0x796: missing int3 after ret
    arch/x86/crypto/poly1305-x86_64-cryptogams.o: warning: objtool: poly1305_blocks_avx512()+0x10bd: missing int3 after ret
    
    Fixes: f94909ceb1ed ("x86: Prepare asm files for straight-line-speculation")
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Herbert Xu <herbert@gondor.apana.org.au>
    Signed-off-by: Sasha Levin <sashal@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 03c5c33e043e77a1a848c52f37c512efb412f2c3
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Mar 8 16:30:14 2022 +0100

    objtool: Default ignore INT3 for unreachable
    
    commit 1ffbe4e935f9b7308615c75be990aec07464d1e7 upstream.
    
    Ignore all INT3 instructions for unreachable code warnings, similar to NOP.
    This allows using INT3 for various paddings instead of NOPs.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lore.kernel.org/r/20220308154317.343312938@infradead.org
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit bef21f88b47e399a76276ef1620fb816a0cc4e83
Author: Borislav Petkov <bp@suse.de>
Date:   Wed Mar 16 22:05:52 2022 +0100

    kvm/emulate: Fix SETcc emulation function offsets with SLS
    
    commit fe83f5eae432ccc8e90082d6ed506d5233547473 upstream.
    
    The commit in Fixes started adding INT3 after RETs as a mitigation
    against straight-line speculation.
    
    The fastop SETcc implementation in kvm's insn emulator uses macro magic
    to generate all possible SETcc functions and to jump to them when
    emulating the respective instruction.
    
    However, it hardcodes the size and alignment of those functions to 4: a
    three-byte SETcc insn and a single-byte RET. BUT, with SLS, there's an
    INT3 that gets slapped after the RET, which brings the whole scheme out
    of alignment:
    
      15:   0f 90 c0                seto   %al
      18:   c3                      ret
      19:   cc                      int3
      1a:   0f 1f 00                nopl   (%rax)
      1d:   0f 91 c0                setno  %al
      20:   c3                      ret
      21:   cc                      int3
      22:   0f 1f 00                nopl   (%rax)
      25:   0f 92 c0                setb   %al
      28:   c3                      ret
      29:   cc                      int3
    
    and this explodes like this:
    
      int3: 0000 [#1] PREEMPT SMP PTI
      CPU: 0 PID: 2435 Comm: qemu-system-x86 Not tainted 5.17.0-rc8-sls #1
      Hardware name: Dell Inc. Precision WorkStation T3400  /0TP412, BIOS A14 04/30/2012
      RIP: 0010:setc+0x5/0x8 [kvm]
      Code: 00 00 0f 1f 00 0f b6 05 43 24 06 00 c3 cc 0f 1f 80 00 00 00 00 0f 90 c0 c3 cc 0f \
              1f 00 0f 91 c0 c3 cc 0f 1f 00 0f 92 c0 c3 cc <0f> 1f 00 0f 93 c0 c3 cc 0f 1f 00 \
              0f 94 c0 c3 cc 0f 1f 00 0f 95 c0
      Call Trace:
       <TASK>
       ? x86_emulate_insn [kvm]
       ? x86_emulate_instruction [kvm]
       ? vmx_handle_exit [kvm_intel]
       ? kvm_arch_vcpu_ioctl_run [kvm]
       ? kvm_vcpu_ioctl [kvm]
       ? __x64_sys_ioctl
       ? do_syscall_64
       ? entry_SYSCALL_64_after_hwframe
       </TASK>
    
    Raise the alignment value when SLS is enabled and use a macro for that
    instead of hard-coding naked numbers.
    
    Fixes: e463a09af2f0 ("x86: Add straight-line-speculation mitigation")
    Reported-by: Jamie Heilman <jamie@audible.transient.net>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Tested-by: Jamie Heilman <jamie@audible.transient.net>
    Link: https://lore.kernel.org/r/YjGzJwjrvxg5YZ0Z@audible.transient.net
    [Add a comment and a bit of safety checking, since this is going to be changed
     again for IBT support. - Paolo]
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 494ed76c1446b67621b1c55b8b2dceb5c6dfee64
Author: Arnaldo Carvalho de Melo <acme@redhat.com>
Date:   Sun May 9 10:19:37 2021 -0300

    tools arch: Update arch/x86/lib/mem{cpy,set}_64.S copies used in 'perf bench mem memcpy'
    
    commit 35cb8c713a496e8c114eed5e2a5a30b359876df2 upstream.
    
    To bring in the change made in this cset:
    
      f94909ceb1ed4bfd ("x86: Prepare asm files for straight-line-speculation")
    
    It silences these perf tools build warnings, no change in the tools:
    
      Warning: Kernel ABI header at 'tools/arch/x86/lib/memcpy_64.S' differs from latest version at 'arch/x86/lib/memcpy_64.S'
      diff -u tools/arch/x86/lib/memcpy_64.S arch/x86/lib/memcpy_64.S
      Warning: Kernel ABI header at 'tools/arch/x86/lib/memset_64.S' differs from latest version at 'arch/x86/lib/memset_64.S'
      diff -u tools/arch/x86/lib/memset_64.S arch/x86/lib/memset_64.S
    
    The code generated was checked before and after using 'objdump -d /tmp/build/perf/bench/mem-memcpy-x86-64-asm.o',
    no changes.
    
    Cc: Borislav Petkov <bp@suse.de>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Signed-off-by: Arnaldo Carvalho de Melo <acme@redhat.com>
    Signed-off-by: Sasha Levin <sashal@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e9925a4584dc2dd1a5eb4ffc44cd42bb1117a797
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Sat Dec 4 14:43:44 2021 +0100

    x86: Add straight-line-speculation mitigation
    
    commit e463a09af2f0677b9485a7e8e4e70b396b2ffb6f upstream.
    
    Make use of an upcoming GCC feature to mitigate
    straight-line-speculation for x86:
    
      https://gcc.gnu.org/g:53a643f8568067d7700a9f2facc8ba39974973d3
      https://gcc.gnu.org/bugzilla/show_bug.cgi?id=102952
      https://bugs.llvm.org/show_bug.cgi?id=52323
    
    It's built tested on x86_64-allyesconfig using GCC-12 and GCC-11.
    
    Maintenance overhead of this should be fairly low due to objtool
    validation.
    
    Size overhead of all these additional int3 instructions comes to:
    
         text          data     bss     dec     hex filename
      22267751      6933356 2011368 31212475        1dc43bb defconfig-build/vmlinux
      22804126      6933356 1470696 31208178        1dc32f2 defconfig-build/vmlinux.sls
    
    Or roughly 2.4% additional text.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/20211204134908.140103474@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    [bwh: Backported to 5.10:
     - In scripts/Makefile.build, add the objtool option with an ifdef
       block, same as for other options
     - Adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0f8532c2837793acdaa07c6b47fda0bf1fa61f40
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Sat Dec 4 14:43:42 2021 +0100

    objtool: Add straight-line-speculation validation
    
    commit 1cc1e4c8aab4213bd4e6353dec2620476a233d6d upstream.
    
    Teach objtool to validate the straight-line-speculation constraints:
    
     - speculation trap after indirect calls
     - speculation trap after RET
    
    Notable: when an instruction is annotated RETPOLINE_SAFE, indicating
      speculation isn't a problem, also don't care about sls for that
      instruction.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/20211204134908.023037659@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    [bwh: Backported to 5.10: adjust filenames, context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1f6e6683c46612baf01555e214d863aaa03c399b
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Sat Dec 4 14:43:43 2021 +0100

    x86/alternative: Relax text_poke_bp() constraint
    
    commit 26c44b776dba4ac692a0bf5a3836feb8a63fea6b upstream.
    
    Currently, text_poke_bp() is very strict to only allow patching a
    single instruction; however with straight-line-speculation it will be
    required to patch: ret; int3, which is two instructions.
    
    As such, relax the constraints a little to allow int3 padding for all
    instructions that do not imply the execution of the next instruction,
    ie: RET, JMP.d8 and JMP.d32.
    
    While there, rename the text_poke_loc::rel32 field to ::disp.
    
    Note: this fills up the text_poke_loc structure which is now a round
      16 bytes big.
    
      [ bp: Put comments ontop instead of on the side. ]
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/20211204134908.082342723@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 277f4ddc36c578691678b8ae59b60d76ad15fa1b
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Sat Dec 4 14:43:41 2021 +0100

    x86: Prepare inline-asm for straight-line-speculation
    
    commit b17c2baa305cccbd16bafa289fd743cc2db77966 upstream.
    
    Replace all ret/retq instructions with ASM_RET in preparation of
    making it more than a single instruction.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/20211204134907.964635458@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    [bwh: Backported to 5.10: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3c91e2257622c169bf74d587e48b96923285ed74
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Sat Dec 4 14:43:40 2021 +0100

    x86: Prepare asm files for straight-line-speculation
    
    commit f94909ceb1ed4bfdb2ada72f93236305e6d6951f upstream.
    
    Replace all ret/retq instructions with RET in preparation of making
    RET a macro. Since AS is case insensitive it's a big no-op without
    RET defined.
    
      find arch/x86/ -name \*.S | while read file
      do
            sed -i 's/\<ret[q]*\>/RET/' $file
      done
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/20211204134907.905503893@infradead.org
    [bwh: Backported to 5.10: ran the above command]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a512fcd881c1ae4ed607d5fed54248be06fd3478
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Sat Dec 4 14:43:39 2021 +0100

    x86/lib/atomic64_386_32: Rename things
    
    commit 22da5a07c75e1104caf6a42f189c97b83d070073 upstream.
    
    Principally, in order to get rid of #define RET in this code to make
    place for a new RET, but also to clarify the code, rename a bunch of
    things:
    
      s/UNLOCK/IRQ_RESTORE/
      s/LOCK/IRQ_SAVE/
      s/BEGIN/BEGIN_IRQ_SAVE/
      s/\<RET\>/RET_IRQ_RESTORE/
      s/RET_ENDP/\tRET_IRQ_RESTORE\rENDP/
    
    which then leaves RET unused so it can be removed.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lore.kernel.org/r/20211204134907.841623970@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c2746d567dcda6df41b1c3c1e930f51429f5a364
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:48 2021 +0200

    bpf,x86: Respect X86_FEATURE_RETPOLINE*
    
    commit 87c87ecd00c54ecd677798cb49ef27329e0fab41 upstream.
    
    Current BPF codegen doesn't respect X86_FEATURE_RETPOLINE* flags and
    unconditionally emits a thunk call, this is sub-optimal and doesn't
    match the regular, compiler generated, code.
    
    Update the i386 JIT to emit code equal to what the compiler emits for
    the regular kernel text (IOW. a plain THUNK call).
    
    Update the x86_64 JIT to emit code similar to the result of compiler
    and kernel rewrites as according to X86_FEATURE_RETPOLINE* flags.
    Inlining RETPOLINE_AMD (lfence; jmp *%reg) and !RETPOLINE (jmp *%reg),
    while doing a THUNK call for RETPOLINE.
    
    This removes the hard-coded retpoline thunks and shrinks the generated
    code. Leaving a single retpoline thunk definition in the kernel.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120310.614772675@infradead.org
    [cascardo: RETPOLINE_AMD was renamed to RETPOLINE_LFENCE]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: add the necessary cnt variable to
     emit_indirect_jump()]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1713e5c4f8527c9ca5327d98ab6fd3c40df788aa
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:47 2021 +0200

    bpf,x86: Simplify computing label offsets
    
    commit dceba0817ca329868a15e2e1dd46eb6340b69206 upstream.
    
    Take an idea from the 32bit JIT, which uses the multi-pass nature of
    the JIT to compute the instruction offsets on a prior pass in order to
    compute the relative jump offsets on a later pass.
    
    Application to the x86_64 JIT is slightly more involved because the
    offsets depend on program variables (such as callee_regs_used and
    stack_depth) and hence the computed offsets need to be kept in the
    context of the JIT.
    
    This removes, IMO quite fragile, code that hard-codes the offsets and
    tries to compute the length of variable parts of it.
    
    Convert both emit_bpf_tail_call_*() functions which have an out: label
    at the end. Additionally emit_bpt_tail_call_direct() also has a poke
    table entry, for which it computes the offset from the end (and thus
    already relies on the previous pass to have computed addrs[i]), also
    convert this to be a forward based offset.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Alexei Starovoitov <ast@kernel.org>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120310.552304864@infradead.org
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: keep the cnt variable in
     emit_bpf_tail_call_{,in}direct()]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 38a80a3ca2cb069dd5608703b015a206a672aae5
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:45 2021 +0200

    x86/alternative: Add debug prints to apply_retpolines()
    
    commit d4b5a5c993009ffeb5febe3b701da3faab6adb96 upstream.
    
    Make sure we can see the text changes when booting with
    'debug-alternative'.
    
    Example output:
    
     [ ] SMP alternatives: retpoline at: __traceiter_initcall_level+0x1f/0x30 (ffffffff8100066f) len: 5 to: __x86_indirect_thunk_rax+0x0/0x20
     [ ] SMP alternatives: ffffffff82603e58: [2:5) optimized NOPs: ff d0 0f 1f 00
     [ ] SMP alternatives: ffffffff8100066f: orig: e8 cc 30 00 01
     [ ] SMP alternatives: ffffffff8100066f: repl: ff d0 0f 1f 00
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120310.422273830@infradead.org
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3d13ee0d411a078ca1538d823c2c759b8b266fb1
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:44 2021 +0200

    x86/alternative: Try inline spectre_v2=retpoline,amd
    
    commit bbe2df3f6b6da7848398d55b1311d58a16ec21e4 upstream.
    
    Try and replace retpoline thunk calls with:
    
      LFENCE
      CALL    *%\reg
    
    for spectre_v2=retpoline,amd.
    
    Specifically, the sequence above is 5 bytes for the low 8 registers,
    but 6 bytes for the high 8 registers. This means that unless the
    compilers prefix stuff the call with higher registers this replacement
    will fail.
    
    Luckily GCC strongly favours RAX for the indirect calls and most (95%+
    for defconfig-x86_64) will be converted. OTOH clang strongly favours
    R11 and almost nothing gets converted.
    
    Note: it will also generate a correct replacement for the Jcc.d32
    case, except unless the compilers start to prefix stuff that, it'll
    never fit. Specifically:
    
      Jncc.d8 1f
      LFENCE
      JMP     *%\reg
    1:
    
    is 7-8 bytes long, where the original instruction in unpadded form is
    only 6 bytes.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120310.359986601@infradead.org
    [cascardo: RETPOLINE_AMD was renamed to RETPOLINE_LFENCE]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b0e2dc950654162bc68cec530156251e7ad3f03a
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:43 2021 +0200

    x86/alternative: Handle Jcc __x86_indirect_thunk_\reg
    
    commit 2f0cbb2a8e5bbf101e9de118fc0eb168111a5e1e upstream.
    
    Handle the rare cases where the compiler (clang) does an indirect
    conditional tail-call using:
    
      Jcc __x86_indirect_thunk_\reg
    
    For the !RETPOLINE case this can be rewritten to fit the original (6
    byte) instruction like:
    
      Jncc.d8       1f
      JMP           *%\reg
      NOP
    1:
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120310.296470217@infradead.org
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 381fd04c97b469106d83a48343512c5312347155
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:42 2021 +0200

    x86/alternative: Implement .retpoline_sites support
    
    commit 7508500900814d14e2e085cdc4e28142721abbdf upstream.
    
    Rewrite retpoline thunk call sites to be indirect calls for
    spectre_v2=off. This ensures spectre_v2=off is as near to a
    RETPOLINE=n build as possible.
    
    This is the replacement for objtool writing alternative entries to
    ensure the same and achieves feature-parity with the previous
    approach.
    
    One noteworthy feature is that it relies on the thunks to be in
    machine order to compute the register index.
    
    Specifically, this does not yet address the Jcc __x86_indirect_thunk_*
    calls generated by clang, a future patch will add this.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120310.232495794@infradead.org
    [cascardo: small conflict fixup at arch/x86/kernel/module.c]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10:
     - Use hex literal instead of BYTES_NOP1
     - Adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6eb95718f3ea92affae94401f273b580f6b97372
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:41 2021 +0200

    x86/retpoline: Create a retpoline thunk array
    
    commit 1a6f74429c42a3854980359a758e222005712aee upstream.
    
    Stick all the retpolines in a single symbol and have the individual
    thunks as inner labels, this should guarantee thunk order and layout.
    
    Previously there were 16 (or rather 15 without rsp) separate symbols and
    a toolchain might reasonably expect it could displace them however it
    liked, with disregard for their relative position.
    
    However, now they're part of a larger symbol. Any change to their
    relative position would disrupt this larger _array symbol and thus not
    be sound.
    
    This is the same reasoning used for data symbols. On their own there
    is no guarantee about their relative position wrt to one aonther, but
    we're still able to do arrays because an array as a whole is a single
    larger symbol.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120310.169659320@infradead.org
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0de47ad5b9d57e52b81c3ce0faa91c8b7749affe
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:40 2021 +0200

    x86/retpoline: Move the retpoline thunk declarations to nospec-branch.h
    
    commit 6fda8a38865607db739be3e567a2387376222dbd upstream.
    
    Because it makes no sense to split the retpoline gunk over multiple
    headers.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120310.106290934@infradead.org
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 41ef958070000770758531247db417523aa6977f
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:39 2021 +0200

    x86/asm: Fixup odd GEN-for-each-reg.h usage
    
    commit b6d3d9944bd7c9e8c06994ead3c9952f673f2a66 upstream.
    
    Currently GEN-for-each-reg.h usage leaves GEN defined, relying on any
    subsequent usage to start with #undef, which is rude.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120310.041792350@infradead.org
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8ef808b3f406ed920adea8ffc949f63c059bf3a7
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:38 2021 +0200

    x86/asm: Fix register order
    
    commit a92ede2d584a2e070def59c7e47e6b6f6341c55c upstream.
    
    Ensure the register order is correct; this allows for easy translation
    between register number and trampoline and vice-versa.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120309.978573921@infradead.org
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ccb8fc65a3e89815e43abc4f263b3a47aa7397dd
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:37 2021 +0200

    x86/retpoline: Remove unused replacement symbols
    
    commit 4fe79e710d9574a14993f8b4e16b7252da72d5e8 upstream.
    
    Now that objtool no longer creates alternatives, these replacement
    symbols are no longer needed, remove them.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120309.915051744@infradead.org
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 908bd980a80ea23ff834c3fff828c3d37ada6cc2
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:36 2021 +0200

    objtool,x86: Replace alternatives with .retpoline_sites
    
    commit 134ab5bd1883312d7a4b3033b05c6b5a1bb8889b upstream.
    
    Instead of writing complete alternatives, simply provide a list of all
    the retpoline thunk calls. Then the kernel is free to do with them as
    it pleases. Simpler code all-round.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120309.850007165@infradead.org
    [cascardo: fixed conflict because of missing
     8b946cc38e063f0f7bb67789478c38f6d7d457c9]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: deleted functions had slightly different code]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 023e78bbf13c15a55013ca25641509a6697170e1
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:34 2021 +0200

    objtool: Explicitly avoid self modifying code in .altinstr_replacement
    
    commit dd003edeffa3cb87bc9862582004f405d77d7670 upstream.
    
    Assume ALTERNATIVE()s know what they're doing and do not change, or
    cause to change, instructions in .altinstr_replacement sections.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120309.722511775@infradead.org
    [cascardo: context adjustment]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: objtool doesn't have any mcount handling]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6e4676f438f8a454d85c12ffa2abf613f9a8f75c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Tue Oct 26 14:01:33 2021 +0200

    objtool: Classify symbols
    
    commit 1739c66eb7bd5f27f1b69a5a26e10e8327d1e136 upstream.
    
    In order to avoid calling str*cmp() on symbol names, over and over, do
    them all once upfront and store the result.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Reviewed-by: Borislav Petkov <bp@suse.de>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Alexei Starovoitov <ast@kernel.org>
    Link: https://lore.kernel.org/r/20211026120309.658539311@infradead.org
    [cascardo: no pv_target on struct symbol, because of missing
     db2b0c5d7b6f19b3c2cab08c531b65342eb5252b]
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10: objtool doesn't have any mcount handling]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit acc0be56b4152046aac56b48a70729925036b187
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Jun 24 11:41:02 2021 +0200

    objtool: Handle __sanitize_cov*() tail calls
    
    commit f56dae88a81fded66adf2bea9922d1d98d1da14f upstream.
    
    Turns out the compilers also generate tail calls to __sanitize_cov*(),
    make sure to also patch those out in noinstr code.
    
    Fixes: 0f1441b44e82 ("objtool: Fix noinstr vs KCOV")
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Marco Elver <elver@google.com>
    Link: https://lore.kernel.org/r/20210624095147.818783799@infradead.org
    Signed-off-by: Sasha Levin <sashal@kernel.org>
    [bwh: Backported to 5.10:
     - objtool doesn't have any mcount handling
     - Write the NOPs as hex literals since we can't use <asm/nops.h>]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9d7ec2418a3a6669a69d96927bf9ce8f2efea444
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Jun 24 11:41:01 2021 +0200

    objtool: Introduce CFI hash
    
    commit 8b946cc38e063f0f7bb67789478c38f6d7d457c9 upstream.
    
    Andi reported that objtool on vmlinux.o consumes more memory than his
    system has, leading to horrific performance.
    
    This is in part because we keep a struct instruction for every
    instruction in the file in-memory. Shrink struct instruction by
    removing the CFI state (which includes full register state) from it
    and demand allocating it.
    
    Given most instructions don't actually change CFI state, there's lots
    of repetition there, so add a hash table to find previous CFI
    instances.
    
    Reduces memory consumption (and runtime) for processing an
    x86_64-allyesconfig:
    
      pre:  4:40.84 real,   143.99 user,    44.18 sys,      30624988 mem
      post: 2:14.61 real,   108.58 user,    25.04 sys,      16396184 mem
    
    Suggested-by: Andi Kleen <andi@firstfloor.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lore.kernel.org/r/20210624095147.756759107@infradead.org
    Signed-off-by: Thadeu Lima de Souza Cascardo <cascardo@canonical.com>
    [bwh: Backported to 5.10:
     - Don't use bswap_if_needed() since we don't have any of the other fixes
       for mixed-endian cross-compilation
     - Since we don't have "objtool: Rewrite hashtable sizing", make
       cfi_hash_alloc() set the number of bits similarly to elf_hash_bits()
     - objtool doesn't have any mcount handling
     - Adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e8b1128fb0d6aa97420d5012ab9f62ad262f8f77
Author: Joe Lawrence <joe.lawrence@redhat.com>
Date:   Sun Aug 22 18:50:36 2021 -0400

    objtool: Make .altinstructions section entry size consistent
    
    commit dc02368164bd0ec603e3f5b3dd8252744a667b8a upstream.
    
    Commit e31694e0a7a7 ("objtool: Don't make .altinstructions writable")
    aligned objtool-created and kernel-created .altinstructions section
    flags, but there remains a minor discrepency in their use of a section
    entry size: objtool sets one while the kernel build does not.
    
    While sh_entsize of sizeof(struct alt_instr) seems intuitive, this small
    deviation can cause failures with external tooling (kpatch-build).
    
    Fix this by creating new .altinstructions sections with sh_entsize of 0
    and then later updating sec->sh_size as alternatives are added to the
    section.  An added benefit is avoiding the data descriptor and buffer
    created by elf_create_section(), but previously unused by
    elf_add_alternative().
    
    Fixes: 9bc0bb50727c ("objtool/x86: Rewrite retpoline thunk calls")
    Signed-off-by: Joe Lawrence <joe.lawrence@redhat.com>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lore.kernel.org/r/20210822225037.54620-2-joe.lawrence@redhat.com
    Cc: Andy Lavr <andy.lavr@gmail.com>
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: x86@kernel.org
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1afa44480b62ef3928cad4e7dea0fe076ae163c8
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Mon Oct 4 10:07:50 2021 -0700

    objtool: Remove reloc symbol type checks in get_alt_entry()
    
    commit 4d8b35968bbf9e42b6b202eedb510e2c82ad8b38 upstream.
    
    Converting a special section's relocation reference to a symbol is
    straightforward.  No need for objtool to complain that it doesn't know
    how to handle it.  Just handle it.
    
    This fixes the following warning:
    
      arch/x86/kvm/emulate.o: warning: objtool: __ex_table+0x4: don't know how to handle reloc symbol type: kvm_fastop_exception
    
    Fixes: 24ff65257375 ("objtool: Teach get_alt_entry() about more relocation types")
    Reported-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lore.kernel.org/r/feadbc3dfb3440d973580fad8d3db873cbfe1694.1633367242.git.jpoimboe@redhat.com
    Cc: Peter Zijlstra <peterz@infradead.org>
    Cc: x86@kernel.org
    Cc: Miroslav Benes <mbenes@suse.cz>
    Cc: linux-kernel@vger.kernel.org
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e7118a25a87f6b456c70f6a216b1b5042709cee7
Author: Linus Torvalds <torvalds@linux-foundation.org>
Date:   Sun Oct 3 13:45:48 2021 -0700

    objtool: print out the symbol type when complaining about it
    
    commit 7fab1c12bde926c5a8c7d5984c551d0854d7e0b3 upstream.
    
    The objtool warning that the kvm instruction emulation code triggered
    wasn't very useful:
    
        arch/x86/kvm/emulate.o: warning: objtool: __ex_table+0x4: don't know how to handle reloc symbol type: kvm_fastop_exception
    
    in that it helpfully tells you which symbol name it had trouble figuring
    out the relocation for, but it doesn't actually say what the unknown
    symbol type was that triggered it all.
    
    In this case it was because of missing type information (type 0, aka
    STT_NOTYPE), but on the whole it really should just have printed that
    out as part of the message.
    
    Because if this warning triggers, that's very much the first thing you
    want to know - why did reloc2sec_off() return failure for that symbol?
    
    So rather than just saying you can't handle some type of symbol without
    saying what the type _was_, just print out the type number too.
    
    Fixes: 24ff65257375 ("objtool: Teach get_alt_entry() about more relocation types")
    Link: https://lore.kernel.org/lkml/CAHk-=wiZwq-0LknKhXN4M+T8jbxn_2i9mcKpO+OaBSSq_Eh7tg@mail.gmail.com/
    Signed-off-by: Linus Torvalds <torvalds@linux-foundation.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 7ea073195745a8db3cd561faba5cd9870a862045
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Sep 30 12:43:10 2021 +0200

    objtool: Teach get_alt_entry() about more relocation types
    
    commit 24ff652573754fe4c03213ebd26b17e86842feb3 upstream.
    
    Occasionally objtool encounters symbol (as opposed to section)
    relocations in .altinstructions. Typically they are the alternatives
    written by elf_add_alternative() as encountered on a noinstr
    validation run on vmlinux after having already ran objtool on the
    individual .o files.
    
    Basically this is the counterpart of commit 44f6a7c0755d ("objtool:
    Fix seg fault with Clang non-section symbols"), because when these new
    assemblers (binutils now also does this) strip the section symbols,
    elf_add_reloc_to_insn() is forced to emit symbol based relocations.
    
    As such, teach get_alt_entry() about different relocation types.
    
    Fixes: 9bc0bb50727c ("objtool/x86: Rewrite retpoline thunk calls")
    Reported-by: Stephen Rothwell <sfr@canb.auug.org.au>
    Reported-by: Borislav Petkov <bp@alien8.de>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Nathan Chancellor <nathan@kernel.org>
    Link: https://lore.kernel.org/r/YVWUvknIEVNkPvnP@hirez.programming.kicks-ass.net
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 364e463097a7c949e19fa93283f1a888ba96ed21
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Wed Jun 23 10:42:28 2021 -0500

    objtool: Don't make .altinstructions writable
    
    commit e31694e0a7a709293319475d8001e05e31f2178c upstream.
    
    When objtool creates the .altinstructions section, it sets the SHF_WRITE
    flag to make the section writable -- unless the section had already been
    previously created by the kernel.  The mismatch between kernel-created
    and objtool-created section flags can cause failures with external
    tooling (kpatch-build).  And the section doesn't need to be writable
    anyway.
    
    Make the section flags consistent with the kernel's.
    
    Fixes: 9bc0bb50727c ("objtool/x86: Rewrite retpoline thunk calls")
    Reported-by: Joe Lawrence <joe.lawrence@redhat.com>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/6c284ae89717889ea136f9f0064d914cd8329d31.1624462939.git.jpoimboe@redhat.com
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f231b2ee8533d79b93bd163e93caf578d991726b
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Jun 21 16:13:55 2021 +0200

    objtool/x86: Ignore __x86_indirect_alt_* symbols
    
    commit 31197d3a0f1caeb60fb01f6755e28347e4f44037 upstream.
    
    Because the __x86_indirect_alt* symbols are just that, objtool will
    try and validate them as regular symbols, instead of the alternative
    replacements that they are.
    
    This goes sideways for FRAME_POINTER=y builds; which generate a fair
    amount of warnings.
    
    Fixes: 9bc0bb50727c ("objtool/x86: Rewrite retpoline thunk calls")
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lore.kernel.org/r/YNCgxwLBiK9wclYJ@hirez.programming.kicks-ass.net
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e32542e9ed362bf8ea48941d965495e1593b5cef
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Thu Jun 10 09:04:29 2021 +0200

    objtool: Only rewrite unconditional retpoline thunk calls
    
    commit 2d49b721dc18c113d5221f4cf5a6104eb66cb7f2 upstream.
    
    It turns out that the compilers generate conditional branches to the
    retpoline thunks like:
    
      5d5:   0f 85 00 00 00 00       jne    5db <cpuidle_reflect+0x22>
            5d7: R_X86_64_PLT32     __x86_indirect_thunk_r11-0x4
    
    while the rewrite can only handle JMP/CALL to the thunks. The result
    is the alternative wrecking the code. Make sure to skip writing the
    alternatives for conditional branches.
    
    Fixes: 9bc0bb50727c ("objtool/x86: Rewrite retpoline thunk calls")
    Reported-by: Lukasz Majczak <lma@semihalf.com>
    Reported-by: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Tested-by: Nathan Chancellor <nathan@kernel.org>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a0319253825ebd8c5b19e31902c4f35f85e93285
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Mon Jun 7 11:45:58 2021 +0200

    objtool: Fix .symtab_shndx handling for elf_create_undef_symbol()
    
    commit 584fd3b31889852d0d6f3dd1e3d8e9619b660d2c upstream.
    
    When an ELF object uses extended symbol section indexes (IOW it has a
    .symtab_shndx section), these must be kept in sync with the regular
    symbol table (.symtab).
    
    So for every new symbol we emit, make sure to also emit a
    .symtab_shndx value to keep the arrays of equal size.
    
    Note: since we're writing an UNDEF symbol, most GElf_Sym fields will
    be 0 and we can repurpose one (st_size) to host the 0 for the xshndx
    value.
    
    Fixes: 2f2f7e47f052 ("objtool: Add elf_create_undef_symbol()")
    Reported-by: Nick Desaulniers <ndesaulniers@google.com>
    Suggested-by: Fangrui Song <maskray@google.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Tested-by: Nick Desaulniers <ndesaulniers@google.com>
    Link: https://lkml.kernel.org/r/YL3q1qFO9QIRL/BA@hirez.programming.kicks-ass.net
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 76474a9dd34a7a33abc82952b82f7092750f3bdc
Author: Borislav Petkov <bp@suse.de>
Date:   Tue Jun 1 17:51:22 2021 +0200

    x86/alternative: Optimize single-byte NOPs at an arbitrary position
    
    commit 2b31e8ed96b260ce2c22bd62ecbb9458399e3b62 upstream.
    
    Up until now the assumption was that an alternative patching site would
    have some instructions at the beginning and trailing single-byte NOPs
    (0x90) padding. Therefore, the patching machinery would go and optimize
    those single-byte NOPs into longer ones.
    
    However, this assumption is broken on 32-bit when code like
    hv_do_hypercall() in hyperv_init() would use the ratpoline speculation
    killer CALL_NOSPEC. The 32-bit version of that macro would align certain
    insns to 16 bytes, leading to the compiler issuing a one or more
    single-byte NOPs, depending on the holes it needs to fill for alignment.
    
    That would lead to the warning in optimize_nops() to fire:
    
      ------------[ cut here ]------------
      Not a NOP at 0xc27fb598
       WARNING: CPU: 0 PID: 0 at arch/x86/kernel/alternative.c:211 optimize_nops.isra.13
    
    due to that function verifying whether all of the following bytes really
    are single-byte NOPs.
    
    Therefore, carve out the NOP padding into a separate function and call
    it for each NOP range beginning with a single-byte NOP.
    
    Fixes: 23c1ad538f4f ("x86/alternatives: Optimize optimize_nops()")
    Reported-by: Richard Narron <richard@aaazen.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://bugzilla.kernel.org/show_bug.cgi?id=213301
    Link: https://lkml.kernel.org/r/20210601212125.17145-1-bp@alien8.de
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit f3fe1b141d2cd956ca59d142ef3b5f5cf4e5149c
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Wed Feb 24 10:29:14 2021 -0600

    objtool: Support asm jump tables
    
    commit 99033461e685b48549ec77608b4bda75ddf772ce upstream.
    
    Objtool detection of asm jump tables would normally just work, except
    for the fact that asm retpolines use alternatives.  Objtool thinks the
    alternative code path (a jump to the retpoline) is a sibling call.
    
    Don't treat alternative indirect branches as sibling calls when the
    original instruction has a jump table.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Tested-by: Ard Biesheuvel <ardb@kernel.org>
    Acked-by: Ard Biesheuvel <ardb@kernel.org>
    Tested-by: Sami Tolvanen <samitolvanen@google.com>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
    Link: https://lore.kernel.org/r/460cf4dc675d64e1124146562cabd2c05aa322e8.1614182415.git.jpoimboe@redhat.com
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0b2c8bf4983bdefbb69337c7d68cbe7c2d47a61a
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:15 2021 +0100

    objtool/x86: Rewrite retpoline thunk calls
    
    commit 9bc0bb50727c8ac69fbb33fb937431cf3518ff37 upstream.
    
    When the compiler emits: "CALL __x86_indirect_thunk_\reg" for an
    indirect call, have objtool rewrite it to:
    
            ALTERNATIVE "call __x86_indirect_thunk_\reg",
                        "call *%reg", ALT_NOT(X86_FEATURE_RETPOLINE)
    
    Additionally, in order to not emit endless identical
    .altinst_replacement chunks, use a global symbol for them, see
    __x86_indirect_alt_*.
    
    This also avoids objtool from having to do code generation.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151300.320177914@infradead.org
    [bwh: Backported to 5.10: include "arch_elf.h" instead of "arch/elf.h"]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit ed7783dca5baff4103c214214abf0a3aeb27a79f
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:14 2021 +0100

    objtool: Skip magical retpoline .altinstr_replacement
    
    commit 50e7b4a1a1b264fc7df0698f2defb93cadf19a7b upstream.
    
    When the .altinstr_replacement is a retpoline, skip the alternative.
    We already special case retpolines anyway.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151300.259429287@infradead.org
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e87c18c4a951bba1d69c7acaf401d613cf9a828c
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:13 2021 +0100

    objtool: Cache instruction relocs
    
    commit 7bd2a600f3e9d27286bbf23c83d599e9cc7cf245 upstream.
    
    Track the reloc of instructions in the new instruction->reloc field
    to avoid having to look them up again later.
    
    ( Technically x86 instructions can have two relocations, but not jumps
      and calls, for which we're using this. )
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151300.195441549@infradead.org
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 33092b486686c31432c5354dbb18651e44200668
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:12 2021 +0100

    objtool: Keep track of retpoline call sites
    
    commit 43d5430ad74ef5156353af7aec352426ec7a8e57 upstream.
    
    Provide infrastructure for architectures to rewrite/augment compiler
    generated retpoline calls. Similar to what we do for static_call()s,
    keep track of the instructions that are retpoline calls.
    
    Use the same list_head, since a retpoline call cannot also be a
    static_call.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151300.130805730@infradead.org
    [bwh: Backported to 5.10: adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 8a6d73f7db7f8486918d144e457e3b1d2cd22dba
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:11 2021 +0100

    objtool: Add elf_create_undef_symbol()
    
    commit 2f2f7e47f0525cbaad5dd9675fd9d8aa8da12046 upstream.
    
    Allow objtool to create undefined symbols; this allows creating
    relocations to symbols not currently in the symbol table.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151300.064743095@infradead.org
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b69e1b4b689faa1af25a0a76cd1ef8c612770608
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:10 2021 +0100

    objtool: Extract elf_symbol_add()
    
    commit 9a7827b7789c630c1efdb121daa42c6e77dce97f upstream.
    
    Create a common helper to add symbols.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151300.003468981@infradead.org
    [bwh: Backported to 5.10: rb_add() parameter order is different]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit da962cd0a2fe2e2c29c75f425fb29fc09b4233cc
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:09 2021 +0100

    objtool: Extract elf_strtab_concat()
    
    commit 417a4dc91e559f92404c2544f785b02ce75784c3 upstream.
    
    Create a common helper to append strings to a strtab.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151259.941474004@infradead.org
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b37c439250118f6fecfd6436d8b218a452ab6fa8
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:08 2021 +0100

    objtool: Create reloc sections implicitly
    
    commit d0c5c4cc73da0b05b0d9e5f833f2d859e1b45f8e upstream.
    
    Have elf_add_reloc() create the relocation section implicitly.
    
    Suggested-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151259.880174448@infradead.org
    [bwh: Backported to 5.10: drop changes in create_mcount_loc_sections()]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fcdb7926d399910ee847856b28d7bde5437f77f0
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:07 2021 +0100

    objtool: Add elf_create_reloc() helper
    
    commit ef47cc01cb4abcd760d8ac66b9361d6ade4d0846 upstream.
    
    We have 4 instances of adding a relocation. Create a common helper
    to avoid growing even more.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151259.817438847@infradead.org
    [bwh: Backported to 5.10: drop changes in create_mcount_loc_sections()]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c9049cf4804ab6f2b73d4cc244c3e2f6e0a9f10e
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:06 2021 +0100

    objtool: Rework the elf_rebuild_reloc_section() logic
    
    commit 3a647607b57ad8346e659ddd3b951ac292c83690 upstream.
    
    Instead of manually calling elf_rebuild_reloc_section() on sections
    we've called elf_add_reloc() on, have elf_write() DTRT.
    
    This makes it easier to add random relocations in places without
    carefully tracking when we're done and need to flush what section.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151259.754213408@infradead.org
    [bwh: Backported to 5.10: drop changes in create_mcount_loc_sections()]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d42fa5bf19fc04833f3c27e9555051c428422248
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:04 2021 +0100

    objtool: Handle per arch retpoline naming
    
    commit 530b4ddd9dd92b263081f5c7786d39a8129c8b2d upstream.
    
    The __x86_indirect_ naming is obviously not generic. Shorten to allow
    matching some additional magic names later.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151259.630296706@infradead.org
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6e95f8caffb3f10e48b100c47e753ca83042fe6f
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:03 2021 +0100

    objtool: Correctly handle retpoline thunk calls
    
    commit bcb1b6ff39da7e8a6a986eb08126fba2b5e13c32 upstream.
    
    Just like JMP handling, convert a direct CALL to a retpoline thunk
    into a retpoline safe indirect CALL.
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Reviewed-by: Miroslav Benes <mbenes@suse.cz>
    Link: https://lkml.kernel.org/r/20210326151259.567568238@infradead.org
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 28ca351296742a9e7506a548acaf7ea3bc9feef0
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:02 2021 +0100

    x86/retpoline: Simplify retpolines
    
    commit 119251855f9adf9421cb5eb409933092141ab2c7 upstream.
    
    Due to:
    
      c9c324dc22aa ("objtool: Support stack layout changes in alternatives")
    
    it is now possible to simplify the retpolines.
    
    Currently our retpolines consist of 2 symbols:
    
     - __x86_indirect_thunk_\reg: the compiler target
     - __x86_retpoline_\reg:  the actual retpoline.
    
    Both are consecutive in code and aligned such that for any one register
    they both live in the same cacheline:
    
      0000000000000000 <__x86_indirect_thunk_rax>:
       0:   ff e0                   jmpq   *%rax
       2:   90                      nop
       3:   90                      nop
       4:   90                      nop
    
      0000000000000005 <__x86_retpoline_rax>:
       5:   e8 07 00 00 00          callq  11 <__x86_retpoline_rax+0xc>
       a:   f3 90                   pause
       c:   0f ae e8                lfence
       f:   eb f9                   jmp    a <__x86_retpoline_rax+0x5>
      11:   48 89 04 24             mov    %rax,(%rsp)
      15:   c3                      retq
      16:   66 2e 0f 1f 84 00 00 00 00 00   nopw   %cs:0x0(%rax,%rax,1)
    
    The thunk is an alternative_2, where one option is a JMP to the
    retpoline. This was done so that objtool didn't need to deal with
    alternatives with stack ops. But that problem has been solved, so now
    it is possible to fold the entire retpoline into the alternative to
    simplify and consolidate unused bytes:
    
      0000000000000000 <__x86_indirect_thunk_rax>:
       0:   ff e0                   jmpq   *%rax
       2:   90                      nop
       3:   90                      nop
       4:   90                      nop
       5:   90                      nop
       6:   90                      nop
       7:   90                      nop
       8:   90                      nop
       9:   90                      nop
       a:   90                      nop
       b:   90                      nop
       c:   90                      nop
       d:   90                      nop
       e:   90                      nop
       f:   90                      nop
      10:   90                      nop
      11:   66 66 2e 0f 1f 84 00 00 00 00 00        data16 nopw %cs:0x0(%rax,%rax,1)
      1c:   0f 1f 40 00             nopl   0x0(%rax)
    
    Notice that since the longest alternative sequence is now:
    
       0:   e8 07 00 00 00          callq  c <.altinstr_replacement+0xc>
       5:   f3 90                   pause
       7:   0f ae e8                lfence
       a:   eb f9                   jmp    5 <.altinstr_replacement+0x5>
       c:   48 89 04 24             mov    %rax,(%rsp)
      10:   c3                      retq
    
    17 bytes, we have 15 bytes NOP at the end of our 32 byte slot. (IOW, if
    we can shrink the retpoline by 1 byte we can pack it more densely).
    
     [ bp: Massage commit message. ]
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lkml.kernel.org/r/20210326151259.506071949@infradead.org
    [bwh: Backported to 5.10:
     - Use X86_FEATRURE_RETPOLINE_LFENCE flag instead of
       X86_FEATURE_RETPOLINE_AMD, since the later renaming of this flag
       has already been applied
     - Adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e68db6f780c6e0ec777045ece0880f5764617394
Author: Peter Zijlstra <peterz@infradead.org>
Date:   Fri Mar 26 16:12:01 2021 +0100

    x86/alternatives: Optimize optimize_nops()
    
    commit 23c1ad538f4f371bdb67d8a112314842d5db7e5a upstream.
    
    Currently, optimize_nops() scans to see if the alternative starts with
    NOPs. However, the emit pattern is:
    
      141:  \oldinstr
      142:  .skip (len-(142b-141b)), 0x90
    
    That is, when 'oldinstr' is short, the tail is padded with NOPs. This case
    never gets optimized.
    
    Rewrite optimize_nops() to replace any trailing string of NOPs inside
    the alternative to larger NOPs. Also run it irrespective of patching,
    replacing NOPs in both the original and replaced code.
    
    A direct consequence is that 'padlen' becomes superfluous, so remove it.
    
     [ bp:
       - Adjust commit message
       - remove a stale comment about needing to pad
       - add a comment in optimize_nops()
       - exit early if the NOP verif. loop catches a mismatch - function
         should not not add NOPs in that case
       - fix the "optimized NOPs" offsets output ]
    
    Signed-off-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Signed-off-by: Ingo Molnar <mingo@kernel.org>
    Link: https://lkml.kernel.org/r/20210326151259.442992235@infradead.org
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 9a6471666b7387ba0af70d504fe1602cc3d3e5b2
Author: Ben Hutchings <ben@decadent.org.uk>
Date:   Mon Jul 11 00:43:31 2022 +0200

    x86: Add insn_decode_kernel()
    
    This was done by commit 52fa82c21f64e900a72437269a5cc9e0034b424e
    upstream, but this backport avoids changing all callers of the
    old decoder API.
    
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit d9cd21911498a9b423e2bdf728b283e4507e968e
Author: Borislav Petkov <bp@suse.de>
Date:   Fri Nov 6 19:37:25 2020 +0100

    x86/alternative: Use insn_decode()
    
    commit 63c66cde7bbcc79aac14b25861c5b2495eede57b upstream.
    
    No functional changes, just simplification.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lkml.kernel.org/r/20210304174237.31945-10-bp@alien8.de
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e6f8dc86a1c15b862486a61abcb54b88e8c177e3
Author: Borislav Petkov <bp@suse.de>
Date:   Thu Nov 19 19:20:18 2020 +0100

    x86/insn-eval: Handle return values from the decoder
    
    commit 6e8c83d2a3afbfd5ee019ec720b75a42df515caa upstream.
    
    Now that the different instruction-inspecting functions return a value,
    test that and return early from callers if error has been encountered.
    
    While at it, do not call insn_get_modrm() when calling
    insn_get_displacement() because latter will make sure to call
    insn_get_modrm() if ModRM hasn't been parsed yet.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lkml.kernel.org/r/20210304174237.31945-6-bp@alien8.de
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 6bc6875b82a0cb99212c4b78fe7606418888af30
Author: Borislav Petkov <bp@suse.de>
Date:   Tue Nov 3 17:28:30 2020 +0100

    x86/insn: Add an insn_decode() API
    
    commit 93281c4a96572a34504244969b938e035204778d upstream.
    
    Users of the instruction decoder should use this to decode instruction
    bytes. For that, have insn*() helpers return an int value to denote
    success/failure. When there's an error fetching the next insn byte and
    the insn falls short, return -ENODATA to denote that.
    
    While at it, make insn_get_opcode() more stricter as to whether what has
    seen so far is a valid insn and if not.
    
    Copy linux/kconfig.h for the tools-version of the decoder so that it can
    use IS_ENABLED().
    
    Also, cast the INSN_MODE_KERN dummy define value to (enum insn_mode)
    for tools use of the decoder because perf tool builds with -Werror and
    errors out with -Werror=sign-compare otherwise.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Masami Hiramatsu <mhiramat@kernel.org>
    Link: https://lkml.kernel.org/r/20210304174237.31945-5-bp@alien8.de
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 76c513c87f599bc013c582522323a1b117b8f501
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Feb 22 13:34:40 2021 +0100

    x86/insn: Add a __ignore_sync_check__ marker
    
    commit d30c7b820be5c4777fe6c3b0c21f9d0064251e51 upstream.
    
    Add an explicit __ignore_sync_check__ marker which will be used to mark
    lines which are supposed to be ignored by file synchronization check
    scripts, its advantage being that it explicitly denotes such lines in
    the code.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Reviewed-by: Masami Hiramatsu <mhiramat@kernel.org>
    Link: https://lkml.kernel.org/r/20210304174237.31945-4-bp@alien8.de
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit a3d96c74395e162e880515d711ab96f5959856ec
Author: Borislav Petkov <bp@suse.de>
Date:   Mon Nov 2 18:47:34 2020 +0100

    x86/insn: Rename insn_decode() to insn_decode_from_regs()
    
    commit 9e761296c52dcdb1aaa151b65bd39accb05740d9 upstream.
    
    Rename insn_decode() to insn_decode_from_regs() to denote that it
    receives regs as param and uses registers from there during decoding.
    Free the former name for a more generic version of the function.
    
    No functional changes.
    
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lkml.kernel.org/r/20210304174237.31945-2-bp@alien8.de
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit fd80da64cffe952cfd71c1c60085ad2bad7ecb63
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Mar 11 15:23:12 2021 +0100

    x86/alternative: Use ALTERNATIVE_TERNARY() in _static_cpu_has()
    
    commit 2fe2a2c7a97c9bc32acc79154b75e754280f7867 upstream.
    
    _static_cpu_has() contains a completely open coded version of
    ALTERNATIVE_TERNARY(). Replace that with the macro instead.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lkml.kernel.org/r/20210311142319.4723-8-jgross@suse.com
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 341e6178c1cf6225e085de9eaba6216d624d641e
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Mar 11 15:23:11 2021 +0100

    x86/alternative: Support ALTERNATIVE_TERNARY
    
    commit e208b3c4a9748b2c17aa09ba663b5096ccf82dce upstream.
    
    Add ALTERNATIVE_TERNARY support for replacing an initial instruction
    with either of two instructions depending on a feature:
    
      ALTERNATIVE_TERNARY "default_instr", FEATURE_NR,
                          "feature_on_instr", "feature_off_instr"
    
    which will start with "default_instr" and at patch time will,
    depending on FEATURE_NR being set or not, patch that with either
    "feature_on_instr" or "feature_off_instr".
    
     [ bp: Add comment ontop. ]
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Acked-by: Peter Zijlstra (Intel) <peterz@infradead.org>
    Link: https://lkml.kernel.org/r/20210311142319.4723-7-jgross@suse.com
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0c4c698569962d32b76ea8ae13334c81ea647be0
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Mar 11 15:23:10 2021 +0100

    x86/alternative: Support not-feature
    
    commit dda7bb76484978316bb412a353789ebc5901de36 upstream.
    
    Add support for alternative patching for the case a feature is not
    present on the current CPU. For users of ALTERNATIVE() and friends, an
    inverted feature is specified by applying the ALT_NOT() macro to it,
    e.g.:
    
      ALTERNATIVE(old, new, ALT_NOT(feature));
    
    Committer note:
    
    The decision to encode the NOT-bit in the feature bit itself is because
    a future change which would make objtool generate such alternative
    calls, would keep the code in objtool itself fairly simple.
    
    Also, this allows for the alternative macros to support the NOT feature
    without having to change them.
    
    Finally, the u16 cpuid member encoding the X86_FEATURE_ flags is not an
    ABI so if more bits are needed, cpuid itself can be enlarged or a flags
    field can be added to struct alt_instr after having considered the size
    growth in either cases.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lkml.kernel.org/r/20210311142319.4723-6-jgross@suse.com
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit c9cf908b89ca3b5aa6563181bf78764ac1ab793e
Author: Juergen Gross <jgross@suse.com>
Date:   Thu Mar 11 15:23:06 2021 +0100

    x86/alternative: Merge include files
    
    commit 5e21a3ecad1500e35b46701e7f3f232e15d78e69 upstream.
    
    Merge arch/x86/include/asm/alternative-asm.h into
    arch/x86/include/asm/alternative.h in order to make it easier to use
    common definitions later.
    
    Signed-off-by: Juergen Gross <jgross@suse.com>
    Signed-off-by: Borislav Petkov <bp@suse.de>
    Link: https://lkml.kernel.org/r/20210311142319.4723-2-jgross@suse.com
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 5f93d900b9d33b0d5f7e1a7e455f26aab86875c5
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Thu Jan 21 15:29:29 2021 -0600

    x86/xen: Support objtool vmlinux.o validation in xen-head.S
    
    commit f4b4bc10b0b85ec66f1a9bf5dddf475e6695b6d2 upstream.
    
    The Xen hypercall page is filled with zeros, causing objtool to fall
    through all the empty hypercall functions until it reaches a real
    function, resulting in a stack state mismatch.
    
    The build-time contents of the hypercall page don't matter because the
    page gets rewritten by the hypervisor.  Make it more palatable to
    objtool by making each hypervisor function a true empty function, with
    nops and a return.
    
    Cc: Juergen Gross <jgross@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lore.kernel.org/r/0883bde1d7a1fb3b6a4c952bc0200e873752f609.1611263462.git.jpoimboe@redhat.com
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit b626e17c11f58d49b01bd8bcdf0e0ec11570b6df
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Thu Jan 21 15:29:28 2021 -0600

    x86/xen: Support objtool validation in xen-asm.S
    
    commit cde07a4e4434ddfb9b1616ac971edf6d66329804 upstream.
    
    The OBJECT_FILES_NON_STANDARD annotation is used to tell objtool to
    ignore a file.  File-level ignores won't work when validating vmlinux.o.
    
    Tweak the ELF metadata and unwind hints to allow objtool to follow the
    code.
    
    Cc: Juergen Gross <jgross@suse.com>
    Reviewed-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lore.kernel.org/r/8b042a09c69e8645f3b133ef6653ba28f896807d.1611263462.git.jpoimboe@redhat.com
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3116dee2704bfb3713efa3637a9e65369d019cc4
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Thu Jan 21 15:29:24 2021 -0600

    objtool: Combine UNWIND_HINT_RET_OFFSET and UNWIND_HINT_FUNC
    
    commit b735bd3e68824316655252a931a3353a6ebc036f upstream.
    
    The ORC metadata generated for UNWIND_HINT_FUNC isn't actually very
    func-like.  With certain usages it can cause stack state mismatches
    because it doesn't set the return address (CFI_RA).
    
    Also, users of UNWIND_HINT_RET_OFFSET no longer need to set a custom
    return stack offset.  Instead they just need to specify a func-like
    situation, so the current ret_offset code is hacky for no good reason.
    
    Solve both problems by simplifying the RET_OFFSET handling and
    converting it into a more useful UNWIND_HINT_FUNC.
    
    If we end up needing the old 'ret_offset' functionality again in the
    future, we should be able to support it pretty easily with the addition
    of a custom 'sp_offset' in UNWIND_HINT_FUNC.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lore.kernel.org/r/db9d1f5d79dddfbb3725ef6d8ec3477ad199948d.1611263462.git.jpoimboe@redhat.com
    [bwh: Backported to 5.10:
     - Don't use bswap_if_needed() since we don't have any of the other fixes
       for mixed-endian cross-compilation
     - Adjust context]
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 53e89bc78e4351924a1a1474683d47a00c2633f2
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Thu Jan 21 15:29:22 2021 -0600

    objtool: Assume only ELF functions do sibling calls
    
    commit ecf11ba4d066fe527586c6edd6ca68457ca55cf4 upstream.
    
    There's an inconsistency in how sibling calls are detected in
    non-function asm code, depending on the scope of the object.  If the
    target code is external to the object, objtool considers it a sibling
    call.  If the target code is internal but not a function, objtool
    *doesn't* consider it a sibling call.
    
    This can cause some inconsistencies between per-object and vmlinux.o
    validation.
    
    Instead, assume only ELF functions can do sibling calls.  This generally
    matches existing reality, and makes sibling call validation consistent
    between vmlinux.o and per-object.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lore.kernel.org/r/0e9ab6f3628cc7bf3bde7aa6762d54d7df19ad78.1611263461.git.jpoimboe@redhat.com
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 3e674f26528931c6a0f1bc7aa29445b45fdfd62d
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Thu Jan 21 15:29:20 2021 -0600

    objtool: Support retpoline jump detection for vmlinux.o
    
    commit 31a7424bc58063a8e0466c3c10f31a52ec2be4f6 upstream.
    
    Objtool converts direct retpoline jumps to type INSN_JUMP_DYNAMIC, since
    that's what they are semantically.
    
    That conversion doesn't work in vmlinux.o validation because the
    indirect thunk function is present in the object, so the intra-object
    jump check succeeds before the retpoline jump check gets a chance.
    
    Rearrange the checks: check for a retpoline jump before checking for an
    intra-object jump.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Link: https://lore.kernel.org/r/4302893513770dde68ddc22a9d6a2a04aca491dd.1611263461.git.jpoimboe@redhat.com
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 917a4f6348d94d9a3c20d78c800dd4715825362d
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Fri Dec 18 14:26:21 2020 -0600

    objtool: Support stack layout changes in alternatives
    
    commit c9c324dc22aab1687da37001b321b6dfa93a0699 upstream.
    
    The ORC unwinder showed a warning [1] which revealed the stack layout
    didn't match what was expected.  The problem was that paravirt patching
    had replaced "CALL *pv_ops.irq.save_fl" with "PUSHF;POP".  That changed
    the stack layout between the PUSHF and the POP, so unwinding from an
    interrupt which occurred between those two instructions would fail.
    
    Part of the agreed upon solution was to rework the custom paravirt
    patching code to use alternatives instead, since objtool already knows
    how to read alternatives (and converging runtime patching infrastructure
    is always a good thing anyway).  But the main problem still remains,
    which is that runtime patching can change the stack layout.
    
    Making stack layout changes in alternatives was disallowed with commit
    7117f16bf460 ("objtool: Fix ORC vs alternatives"), but now that paravirt
    is going to be doing it, it needs to be supported.
    
    One way to do so would be to modify the ORC table when the code gets
    patched.  But ORC is simple -- a good thing! -- and it's best to leave
    it alone.
    
    Instead, support stack layout changes by "flattening" all possible stack
    states (CFI) from parallel alternative code streams into a single set of
    linear states.  The only necessary limitation is that CFI conflicts are
    disallowed at all possible instruction boundaries.
    
    For example, this scenario is allowed:
    
              Alt1                    Alt2                    Alt3
    
       0x00   CALL *pv_ops.save_fl    CALL xen_save_fl        PUSHF
       0x01                                                   POP %RAX
       0x02                                                   NOP
       ...
       0x05                           NOP
       ...
       0x07   <insn>
    
    The unwind information for offset-0x00 is identical for all 3
    alternatives.  Similarly offset-0x05 and higher also are identical (and
    the same as 0x00).  However offset-0x01 has deviating CFI, but that is
    only relevant for Alt3, neither of the other alternative instruction
    streams will ever hit that offset.
    
    This scenario is NOT allowed:
    
              Alt1                    Alt2
    
       0x00   CALL *pv_ops.save_fl    PUSHF
       0x01                           NOP6
       ...
       0x07   NOP                     POP %RAX
    
    The problem here is that offset-0x7, which is an instruction boundary in
    both possible instruction patch streams, has two conflicting stack
    layouts.
    
    [ The above examples were stolen from Peter Zijlstra. ]
    
    The new flattened CFI array is used both for the detection of conflicts
    (like the second example above) and the generation of linear ORC
    entries.
    
    BTW, another benefit of these changes is that, thanks to some related
    cleanups (new fake nops and alt_group struct) objtool can finally be rid
    of fake jumps, which were a constant source of headaches.
    
    [1] https://lkml.kernel.org/r/20201111170536.arx2zbn4ngvjoov7@treble
    
    Cc: Shinichiro Kawasaki <shinichiro.kawasaki@wdc.com>
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit e9197d768f976199a2356842400df947b4007377
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Fri Dec 18 14:19:32 2020 -0600

    objtool: Add 'alt_group' struct
    
    commit b23cc71c62747f2e4c3e56138872cf47e1294f8a upstream.
    
    Create a new struct associated with each group of alternatives
    instructions.  This will help with the removal of fake jumps, and more
    importantly with adding support for stack layout changes in
    alternatives.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 1d516bd72a68e4e610d8e3b5ad99e25807a85947
Author: Josh Poimboeuf <jpoimboe@kernel.org>
Date:   Thu Dec 17 15:02:42 2020 -0600

    objtool: Refactor ORC section generation
    
    commit ab4e0744e99b87e1a223e89fc3c9ae44f727c9a6 upstream.
    
    Decouple ORC entries from instructions.  This simplifies the
    control/data flow, and is going to make it easier to support alternative
    instructions which change the stack layout.
    
    Signed-off-by: Josh Poimboeuf <jpoimboe@redhat.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit dd87aa5f610be44f195cf5a99b7bc153faf30a3d
Author: Uros Bizjak <ubizjak@gmail.com>
Date:   Wed Dec 30 16:26:57 2020 -0800

    KVM/nVMX: Use __vmx_vcpu_run in nested_vmx_check_vmentry_hw
    
    commit 150f17bfab37e981ba03b37440638138ff2aa9ec upstream.
    
    Replace inline assembly in nested_vmx_check_vmentry_hw
    with a call to __vmx_vcpu_run.  The function is not
    performance critical, so (double) GPR save/restore
    in __vmx_vcpu_run can be tolerated, as far as performance
    effects are concerned.
    
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Sean Christopherson <seanjc@google.com>
    Reviewed-and-tested-by: Sean Christopherson <seanjc@google.com>
    Signed-off-by: Uros Bizjak <ubizjak@gmail.com>
    [sean: dropped versioning info from changelog]
    Signed-off-by: Sean Christopherson <seanjc@google.com>
    Message-Id: <20201231002702.2223707-5-seanjc@google.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>

commit 0ca2ba6e4d139da809061a25626174f812303b7a
Author: Uros Bizjak <ubizjak@gmail.com>
Date:   Thu Oct 29 15:04:57 2020 +0100

    KVM/VMX: Use TEST %REG,%REG instead of CMP $0,%REG in vmenter.S
    
    commit 6c44221b05236cc65d76cb5dc2463f738edff39d upstream.
    
    Saves one byte in __vmx_vcpu_run for the same functionality.
    
    Cc: Paolo Bonzini <pbonzini@redhat.com>
    Cc: Sean Christopherson <sean.j.christopherson@intel.com>
    Signed-off-by: Uros Bizjak <ubizjak@gmail.com>
    Message-Id: <20201029140457.126965-1-ubizjak@gmail.com>
    Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
    Signed-off-by: Ben Hutchings <ben@decadent.org.uk>
    Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
